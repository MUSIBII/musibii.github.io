<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[网络编程(五)]]></title>
    <url>%2F2018%2F11%2F10%2F%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B-%E4%BA%94%2F</url>
    <content type="text"><![CDATA[前言在上一篇文章中我们学习了 基于 TCP 套接字的服务端和客户端通信,并解决了粘包的问题,解决粘包问题的思路很简单,就是确保接受方能够把数据收取干净,发多少,就收多少. 出现粘包的问题:原因有两个,一个是接收数据量少于发送数据量;一个是因为为了优化 TCP 的传输效率,使用了 Nagle算法,当客户端连续发送时间间隔很短的两个数据包时,在未确认数据发送的时候让发送器把数据送到系统缓存里.任何数据随后继续直到得到明显的数据确认或者直到攒到了一定数量的数据了再发包. 这是不可避免的,为了优化传输效率,尽量发送大块数据,避免网络中充斥的许多小数据块.知道了解决方法,那么避免粘包就很简单了,只需要在每次发送数据之前先发送真实数据的长度,然后接收方可以根据收到的真实长度收取数据了. SOCKET使用SOCKET AF_INET套接字主要有两种协议,现在来看 UDP 协议是如何进行网络通信的. 基于 UDP 连接的套接字tcp 是无连接,不稳点的套接字,但是传输效率较高,所以在某些应用上如实时直播,游戏, DNS 服务器,DHCP 服务器等等. 服务端 12345678910from socket import *serverSock = socket(AF_INET, SOCK_DGRAM)serverSock.bind(('', 8080))while True: data, client_addr = serverSock.recvfrom(1024) print(data) serverSock.sendto(data.upper, client_addr)serverSock.close() 客户端 123456789from socket import *clientSock = socket(AF_INET, SOCK_DGRAM)while True: msg = input('&gt;&gt;&gt;').strip() clientSock.sendto(msg.encode('utf-8'), ('', 8080)) data, server_addr = clientSock.recvfrom(1024) print(data) 当我们连续开多个客户端和服务端通信的时候,没有出现阻塞的情况,发出去的消息都可以收回来,这是因为 udp 是无连接的套接字,不用关注一个连接,只要你给我发消息拿到了发送方的 ip 和端口,那么就可以直接和你通信,而且不像 TCP 那样必须先启动服务端才可以, udp 在发送数据的时候,服务端没有启动也可以发送过去,只不过是发到了对方的系统缓存中. 那么 udp 可以实现多个客户端同时和客户端通信吗? 之前几个客户端可以同时和服务端通信是因为服务端的处理能力很大,看起来是同时通信一样,但是如果把客户端加到 1w, 甚至更多就会感觉到明显的时间差了. 那么如何可以实现真正的并发呢?关键点就在一个通信循环和连接循环互相不干扰,不用因为 i/o 堵塞而耽搁另一个循环要做的事. Socketserver 模块实现并发在这里 python 有一个模块为 socketserver 可以实现真正的并发. 基于 TCP 协议的并发服务端 123456789101112131415161718import sockerserverclass MyTCPhandler(socketserver.BaseRequestHandler): def handler(self): while True: try: data = self.request.recv(1024) if len(data) == 0: break print('--&gt;收到客户端的消息:', data) self.request.send(data.upper()) except ConnectResetError: break self.request.close() if __name__ == '__main__': serverSock = socketserver.ThreadingTCPServer(('127.0.0.1', 8081), MyTCPhandler) serverSock.serve_forever() # 和客户端进行连接 客户端 123456789101112from socket import *clientSock = socket(AF_INET, SOCK_STREAM)clientSock.connect(('127.0.0.1', 8081))# 通信循环while True: clientSock.send(b'hello') data = clientSock.recv(1024) print(data) clientSock.close() 这样就解决了 TCP 不能实现并发的问题了. 基于 UDP 协议的并发服务端 12345678910import socketserverclass MyUDPhandler(socketserver.BaseRequestHandler): def handler(self): data, serverSock = self.request serverSock.sendto(data.upper(), self.client_address) if __name__ == '__main__': server = socketserver.ThreadingUDPServer(('127.0.0.1', 8081), MyUDPhandler) server.serve_forever() 客户端 12345678from socket import *clientSock = socket(AF_INET, SOCK_DGRAM)while True: clientSock.sendto(b'hello', ('127.0.0.1', 8081)) data, server_addr = client.recvfrom(1024) print(data) 这就是 UDP 实现并发的模板. 总结到此,网络编程终于告一段落了,其实我写的是网络编程里面极少的也是较为重要的一部分,还有很多底层协议没了解,像 ping 服务器时发送的 ICMP 包,还有很多,不过我觉得了解了这些其实也就了解了互联网工作的基本方式,其余的待有时间了再来学习. 如有不对的地方,欢迎指正.]]></content>
      <categories>
        <category>网络编程</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[网络编程(四)]]></title>
    <url>%2F2018%2F11%2F09%2F%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B-%E5%9B%9B%2F</url>
    <content type="text"><![CDATA[前言经过之前三篇文章的学习我们大致了解了互联网是如何基于五层协议进行通信了,由应用层产生数据,然后进行封装,依次经过传输层,网络层,数据链路层的封装最后由物理层发送电信号进行数据的传输,在接收端首先由物理层接收到字节型的数据,然后拆包,验证 MAC 地址, IP 地址和端口,最后由目标应用获取数据并解码出来. 那么为了使用 TCP 协议建立连接,不用去管什么三次握手四次挥手以及数据到底是怎么在互联网中传输的,在应用层和传输层虚拟出一个抽象层,叫 socket( 套接字)层,这是一个模块为我们封装好了很多底层的协议,以便于我们只关注与实际的数据传输,而不用关系底层的实现. 所以我们就直接使用套接字和网络通信进行交互. socketsocket是什么socket是应用层与 TCP/IP协议族通信的中间软件抽象层,它是一组接口.在设计模式中, socket 就是一个模块,它把复杂的 TCP/IP 协议族隐藏在 socket 接口后面,对用户来说,一组简单的接口就是全部,让 socket 去组织数据,以符合指定的协议. 也有人说, socket 其实就是 ip 和 port 的组合, ip 用来标识互联网中的一台主机的位置,而 port 是用来标识这台机器上的一个应用程序, ip 地址是配置到网卡的,而 port 是应用程序开启的,这样 ip 和 port 就标识了互联网中独一无二的一个应用程序. 套接字发展史即分类套接字起源于20世纪70年代加利福尼亚大学伯克利分校版本的 Unix, 即 BSD Unix. 因此,有时人们也把套接字称为’伯克利套接字’或’ BSD 套接字’.一开始,套接字被设计用在同一台主机上的多个应用程序之间的通信.这也被称之为进程间通信或 IPC(inter-process communication).套接字有两大家族,分别是基于文件型和基于网络型.我们主要学习基于网络型的套接字. 基于文件类型的套接字家族: 套接字家族名字: AF_UNIX UNIX 哲学为一切皆文件(其实也不是所有的),基于文件的套接字调用的就是底层的文件系统来取数据,两个套接字进程运行在同一机器,可以通过访问同一个文件系统间接完成通信. 基于网络类型的套接字家族: 套接字家族名字: AF_INET 基于网络也就是 OSI 协议进行数据通信 套接字工作流程其实就跟打电话很像,有拨号,接电话,通信,挂电话 首先由服务端初始化一个套接字对象,然后与本机的某个大于1023的端口绑定( bind),接着对该端口进行监听(listen),调用 accept 接口阻塞等待客户端的连接.如果在这时客户端初始化一个套接字对象,然后连接(connect)服务端的 ip 和port,如果连接成功,这时客户端与服务端的连接就建立成功了. 这时候可能有人再问了,三次握手呢? 当客户端 connect 服务端的时候就说明三次握手开始了,如果服务端 accept 有返回值,那么就说明三次握手成功.(可以使用 wireshark 进行抓包分析)wireshark 教程 TCP 连接建立成功后客户端和服务端就可以进行数据交互了.客户端发送数据请求,服务端接收请求并处理请求,然后把回应数据发送给客户端,客户端读取数据,最后关闭连接,一次通信结束. SOCKET使用套接字服务端通用使用方法from socket import * sct = socket(socket_family, socket_type, protocal=0) socket_family 可以为AF_UNIX 或 AF_INET,socket_type 可以是 SOCK_STREAM 或 SOCK_DGRAM.protocol 一般不填,缺省值为0. 获取 tcp/ip 套接字 tcpSock = socket(AF_INET, SOCK_STREAM) 绑定 ip port tcpSock.bind((&#39;&#39;, 8080)) 开始监听 tcpSock.listen(5) 被动接受 TCP 客户端连接(阻塞式) tcpSock.accept() 获取 udp/ip 套接字 udpSock = socket(AF_UNIX, SOCK_DGRAM) 绑定 ip port udpSock.bind((&#39;&#39;, 8081)) 套接字客户端通用方法连接服务端主动初始化 TCP 服务器连接 tcpSock.connect((&#39;&#39;, 8080)) 公共用途的套接字函数sock.recv() 接收 TCP 数据 sock.send() 发送 TCP 数据( send 在待发送数据量大于已端缓存区剩余空间时,数据将会丢失) sock.sendall() 发送完整的 TCP 数据(本质就是循环调用 send,sendall 在待发送数据量大于已端缓存区剩余空间时,数据不丢失,循环调用 send 知道发完) sock.recvfrom() 接收 UDP 数据 sock.sendto() 发送 UDP 数据 sock.getpeername() 连接到当前套接字的远端地址 sock.getsockname() 获取当前套接字的地址 sock.getsockopt() 返回指定套接字的参数 sock.setsockopt() 设置指定套接字的参数 sock.close() 关闭套接字 基于 TCP 连接的套接字tcp 是基于连接的,必须先启动服务端,然后再启动客户端去连接服务端 tcp 服务端 12345678910111213141516171819from socket import *# 创建tcp套接字对象serverSock = socket(AF_INET, SOCK_STREAM)# 绑定 ip 和端口serverSock.bind(('', 8080))# 监听连接serverSock.listen(5)# 被动等待客户端的连接,如果有客户端连接会返回一个用于和客户端通信的套接字以及客户端的地址conn, addr = serverSock.accept()# 接收客户端的数据data = conn.recv(1024)# 给客户端返回数据conn.send(data2) tcp 客户端 123456789101112131415161718from socket import *# 创建客户端套接字对象clientSock = socket(AF_INET, SOCK_STREAM)# 连接服务器clientSock.connect(('', 8080))# 发送数据到服务端data = input('&gt;&gt;&gt;').strip()clientSock.send(data.encode('utf-8'))# 接收服务端的数据data = clientSock.recv(1024)print(data.decode('utf-8'))# 关闭客户端套接字clientSock.close() 基于 TCP 的通信循环套接字在上个版本中,服务端和客户端进行了一次通信就关闭了,很明显和实际应用不符合,所以加上通信循环,使得客户端可以和服务端进行多次通信. 服务端必须满足三点要求: 绑定一个固定的 ip 和 port 一直对外提供稳定的服务 能够支持并发(学了多进程多线程可以支持) 服务端 1234567891011121314151617181920212223from socket import *serverSock = socket(AF_INET, SOCK_STREAM)serverSock.bind(('', 8081))serverSock.listen(5)conn, addr = serverSock.accept()# 通信循环while True: try: data = conn.recv(1024) if len(data) == 0:break # 针对 linux 系统 print('--&gt;收到客户端消息:', data) conn.send(data.upper()) except ConnectionResetError: breakconn.close()serverSock.close()# 加上异常处理是因为当客户端异常断开连接时,服务端会报错 客户端 12345678910111213from socket import *clientSock = socket(AF_INET, SOCK_STREAM)client.connect(('', 8081))# 通信循环while True: msg = input('&gt;&gt;&gt;:').stript() clientSock.send(msg.encode('utf-8')) data = clientSock.recv(1024) print(data)clientSock.close() 基于 TCP 的连接循环通信循环套接字在上一个版本中解决了客户端重复发消息的问题,但是作为一个服务端不可能只为一个客户提供服务,所以服务端必须可以接收多个连接(并发),这里实现的是伪并发. 服务端 12345678910111213141516171819202122from socket import *serverSock = socket(AF_INET, SOCK_STREAM)serverSock.bind(('', 8082))serverSock.listen(5)# 连接循环while True: conn, addr = serverSock.accept() print(conn) # 通信循环 while True: try: data = conn.recv(1024) if len(data) == 0: break print('--&gt;收到客户端的消息:', data) conn.send(data.upper()) except ConnectionResetError: break conn.close()serverSock.close() 客户端 12345678910111213from socket import *clientSock = socket(AF_INET, SOCK_STREAM)client.connect(('', 8081))# 通信循环while True: msg = input('&gt;&gt;&gt;:').stript() clientSock.send(msg.encode('utf-8')) data = clientSock.recv(1024) print(data)clientSock.close() 至此一个可以接受多个客户端连接的 C/S 通信程序就完成了,不过服务端连接了一个客户端,那么只能为这个客户端服务,只有等这个客户端断开连接才可以连接其他的客户端. TCP 套接字的参数理解在写服务端代码的时候,发现绑定的地方的 ip 我用了空的字符串,这表示是绑定到本机的,也可以用127.0.0.1来代替,然后还有一个参数为 listen, 里面填的5. 在启动一个服务端时,服务端就会进入 LISTEN 状态,表示监听客户端的连接,那么这个5就表示可以监听5个连接,在套接字里面有个名词叫半连接池,就是说启动服务端时,就自动开启一个半连接池,当客户端连接服务端的时候,表示一个半连接进入半连接池了,然后操作系统就从半连接池取出这个连接,开始处理这个连接,那么后来的连接也是放进这个半连接池里,因为填的5,所以加上服务端处理的那个,一共可以连接6个(处理一个),那么之后的客户端连接都会被服务端拒绝连接,只有等之前处理的或者是半连接池里的少了一个才可以连接上服务端. 那么这个半连接发生在 TCP 三次握手的第几次握手呢?发生在客户端 connect 的时候,也就是第一次握手的时候,第一次握手成功,客户端连接就进入了半连接池,那么等服务端 accept 的时候,就说明三次握手连接成功. 目前我们实现了一个不太完美的 C/S 程序,那么有什么办法可以让服务端既可以连接多个客户端,又可以同时为它们服务呢?答案是让连接循环和通信循环放在两个 py 文件里面. 模拟 SSH 实现远程执行命令结合之前学习的模块 subprocess, 可以执行传过来的命令参数,在命令行中.那么我们使用客户端传送命令,在服务端运行 subprocess 执行命令,并把得到的结果传过去. 服务端 1234567891011121314151617181920212223242526from socket import *import subprocessserverSock = socket(AF_INET, SOCK_STREAM)serverSock.bind(('', 8085))server.listen(5)while True: conn, addr = serverSock.accept() while True: try: cmd = conn.recv(1024) if len(cmd): break obj = subprocess.Popen(cmd.decode('utf-8'), shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE) stdout = obj.stdout.read() stderr = obj.stderr.read() print(len(stdout) + len(stderr)) conn.send(stdout+stderr) except ConnectionResetError: break conn.close()serverSock.close() 客户端 123456789101112131415from socket import *clientSock = socket(AF_INET, SOCK_STREAM)clientSock.connect(('', 8085))while True: cmd = input('&gt;&gt;&gt;').strip() if len(cmd) == 0: continue client.send(cmd.encode('utf-8')) client.send(cdm.encode(;utf-8)) cmd_res = clientSock.recv(1024) print(cmd_res.decode('utf-8'))clientSock.close() 结果表明当服务端发送的数据大于1024时,客户端一次收取数据量会收不完整,那么当你下次发送命令的时候,服务端回过来的数据会和上次未收完的数据粘在一起,这是一种粘包情况. 有时候命名关闭服务端了,重启服务端是会出现这种问题是因为当TCP主动关闭连接一方将继续等待一定时间,这是 TCP 连接状态中的 TIME_WAIT 状态,该状态的作用是用来重发可能丢失的 ACK 报文,其二当一个服务器断开连接时,该端口可能还会重复使用,那么该端口就不能被其他的应用使用. Nagle 算法1 Nagle 算法规则 当客户端连续发送时间间隔很短的两个数据包时,因为 TCP 协议为了优化传输效率和较少资源浪费,内部使用一种Nagle 的算法.Nagle 算法通常会在 TCP 程序里添加两行代码,在未确认数据发送的时候让发送器把数据送到系统缓存里.任何数据随后继续直到得到明显的数据确认或者直到攒到了一定数量的数据了再发包. TCP/IP 协议中,无论发送多少数据,总是要在数据前面加上协议头,同时,对方收到数据,也需要发送 ACK 表示确认.为了尽可能的利用网络带宽, TCP 总是希望尽可能的发送足够大的数据.(一个连接会设置 MSS 参数,因此, TCP/IP 希望每次都能以 MSS 尺寸的数据块来发送数据).Nagle 算法就是为了尽可能发送大块数据,避免网络中充斥着许多小数据块. Nagle 算法的基本定义时任意时刻,最多只能有一个未被确认的小段.所谓小段,指的是小于 MSS 尺寸的数据块,所谓未被确认,是指一个数据块发出后,没有收到对方的 ACK 确认数据已被收到. Nagle 算法的规则: 如果包长度达到 MSS, 则允许发送; 如果该包含有 FIN, 则允许发送; 设置了 TCP_NODELAY 选项,则允许发送; 未设置 TCP_CORK 选项时,如所有发出去的小数据包(包长度小于 MSS)均被确认,则允许发送; 上述条件都未满足,但发生了超时(一般为200ms),则立即发送. Nagle 算法只允许一个未被 ACK确认的包存在于网络,它并不管包的大小,因此它事实上就是一个扩展的停-等协议,只不过它是基于包停-等的,而不是基于字节停-等的. Nagle 算法完全由 TCP 协议的 ACK 机制决定,这会带来一些问题,比如如果对端 ACK 回复很快的话, Nagle 事实上不会拼接太多的数据包,虽然避免了网络拥塞,网络总体的利用率依然很低. Nagle 算法是 silly window syndrome(SWS)预防算法的一个半集.SWS 算法预防发送少量的数据, Nagle 算法是其在发送方的实现,而接收方要做的是不要通告缓冲空间的很小增长,不通知小窗口,除非缓冲区空间有显著地增长.这里显著地增长定义为完全大小的段( MSS)或增长到大于最大窗口的一半. 注意：BSD的实现是允许在空闲链接上发送大的写操作剩下的最后的小段，也就是说，当超过1个MSS数据发送时，内核先依次发送完n个MSS的数据包，然后再发送尾部的小数据包，其间不再延时等待。（假设网络不阻塞且接收窗口足够大） 举个例子，client端调用socket的write操作将一个int型数据（称为A块）写入到网络中，由于此时连接是空闲的（也就是说还没有未被确认的小段），因此这个int型数据会被马上发送到server端，接着，client端又调用write操作写入‘\r\n’（简称B块），这个时候，A块的ACK没有返回，所以可以认为已经存在了一个未被确认的小段，所以B块没有立即被发送，一直等待A块的ACK收到（大概40ms之后），B块才被发送。 这里还隐藏了一个问题，就是A块数据的ACK为什么40ms之后才收到？这是因为TCP/IP中不仅仅有nagle算法，还有一个TCP确认延迟机制 。当Server端收到数据之后，它并不会马上向client端发送ACK，而是会将ACK的发送延迟一段时间（假设为t），它希望在t时间内server端会向client端发送应答数据，这样ACK就能够和应答数据一起发送，就像是应答数据捎带着ACK过去。在我之前的时间中，t大概就是40ms。这就解释了为什么’\r\n’（B块）总是在A块之后40ms才发出。 当然，TCP确认延迟40ms并不是一直不变的，TCP连接的延迟确认时间一般初始化为最小值40ms，随后根据连接的重传超时时间（RTO）、上次收到数据包与本次接收数据包的时间间隔等参数进行不断调整。另外可以通过设置TCP_QUICKACK选项来取消确认延迟。 2. TCP_NODELAY 选项 默认情况下，发送数据采用Nagle 算法。这样虽然提高了网络吞吐量，但是实时性却降低了，在一些交互性很强的应用程序来说是不允许的，使用TCP_NODELAY选项可以禁止Nagle 算法。 此时，应用程序向内核递交的每个数据包都会立即发送出去。需要注意的是，虽然禁止了Nagle 算法，但网络的传输仍然受到TCP确认延迟机制的影响。 3. TCP_CORK 选项 所谓的CORK就是塞子的意思，形象地理解就是用CORK将连接塞住，使得数据先不发出去，等到拔去塞子后再发出去。设置该选项后，内核会尽力把小数据包拼接成一个大的数据包（一个MTU）再发送出去，当然若一定时间后（一般为200ms，该值尚待确认），内核仍然没有组合成一个MTU时也必须发送现有的数据（不可能让数据一直等待吧）。 然而，TCP_CORK的实现可能并不像你想象的那么完美，CORK并不会将连接完全塞住。内核其实并不知道应用层到底什么时候会发送第二批数据用于和第一批数据拼接以达到MTU的大小，因此内核会给出一个时间限制，在该时间内没有拼接成一个大包（努力接近MTU）的话，内核就会无条件发送。也就是说若应用层程序发送小包数据的间隔不够短时，TCP_CORK就没有一点作用，反而失去了数据的实时性（每个小包数据都会延时一定时间再发送）。 4. Nagle算法与 CORK算法区别 Nagle算法和CORK算法非常类似，但是它们的着眼点不一样，Nagle算法主要避免网络因为太多的小包（协议头的比例非常之大）而拥塞，而CORK算法则是为了提高网络的利用率，使得总体上协议头占用的比例尽可能的小。如此看来这二者在避免发送小包上是一致的，在用户控制的层面上，Nagle算法完全不受用户socket的控制，你只能简单的设置TCP_NODELAY而禁用它，CORK算法同样也是通过设置或者清除TCP_CORK使能或者禁用之，然而Nagle算法关心的是网络拥塞问题，只要所有的ACK回来则发包，而CORK算法却可以关心内容，在前后数据包发送间隔很短的前提下（很重要，否则内核会帮你将分散的包发出），即使你是分散发送多个小数据包，你也可以通过使能CORK算法将这些内容拼接在一个包内，如果此时用Nagle算法的话，则可能做不到这一点。 TCP 粘包问题在上面的 TCP 服务端和客户端收数据的时候填的都是1024字节,表示一次从操作系统的缓存区域收取最大1024字节的数据,当一次发送数据量小于1924字节的时候每次都可以把数据收取干净,这当然是没问题的,但是如果数据量大于1024呢?会发生什么现象.会发生粘包, 上述代码显示了第一中粘包情况,就是一方收取的数据量小于缓存中的数据量,造成粘包,另外一种是由于 Nagle算法导致的,当客户端连续发送两个数据量较小的包时,算法会将这两个一起发送造成粘包. 第二种粘包例子: 1234567891011121314151617181920212223# 服务端from socket import *import subprocessserverSock = socket(AF_INET, SOCK_STREAM)serverSock.bind(('', 8086))serverSock.listen(5)conn, addr = serverSock.accept()data1 = conn.recv(5)print('第一次收:', data1)data2 = conn.recv(5)print('第二次收:', data2)data3 = conn.recv(10)print('第三次收:', data3)data4 = conn.recv(5)print('第四次收:', data4)# 粘包问题是 tcp 协议流式传输数据的方式导致的# 如何解决粘包问题:接收端能够精确地收干净每个数据包没有任何残留 1234567891011# 客户端from socket import *clientSock = socket(AF_INET, SOCK_STREAM)clientSock.connect(('', 8086))# tcp 协议会将数据量较小且发送时间间隔的数据合并成一个包发送clientSock.send(b'hello')clientSock.send(b'world')clientSock.send(b'musibii')clientSock.send(b'1') 12345# 运行结果第一次收: b'hello'第二次收: b'world'第三次收: b'musibii1'第四次收: b'' 可以看出当两次发包间隔时间较短且数据量较少时,会当成一个包发送出去. 那么怎么解决粘包问题呢? 一是因为数据量太大收取不完全导致的,二是因为两次发包间隔时间较短且数据量较小导致的,导致收取的一方将两次数据一次性收取完成. 解决办法一还是以模拟 ssh 远程执行命令的代码作为例子: 首先根本原因是收取的一方不知道到底应该收取多少数据量导致的,那么我们在每次发包之前将数据的长度发过去,然后在发送真实数据,接收端先接收到真实数据的长度大小,然后依据真实数据长度大小来收包不就完美解决了吗. 看实例: 服务端 123456789101112131415161718192021222324252627282930313233from socket import *import subprocessimport struct # 该模块专门用来处理字节的数据类型serverSock = socket(AF_INET, SOCK_STREAM)serverSock.bind(('', 8088))serverSock.listen(5)while True: conn, addr = serverSock.accept() while True: try: cmd = conn.recv(1024) if len(cmd) == 0: break obj = subprocess.Popen(cmd.decode('utf-8'), shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE) stdout = obj.stdout.read() stderr = obj.stderr.read() print(len(stdout) + len(stderr)) data_len = len(stdout) + len(stderr) # 1. 先制作固定长度的报头 header = struct.pack('i', data_len) # i表示转 int 型 # 2. 发送报头 conn.send(header) # 3. 发送真实数据 conn.send(stdout) conn.send(stderr) except ConnectionResetError: break conn.close()serverSock.close() 客户端 1234567891011121314151617181920212223from socket import *import structclientSock = socket(AF_INET, SOCK_STREAM)clientSock.connect(('', 8088))while True: cmd = input('&gt;&gt;&gt;').strip() if len(cmd) == 0: continue clientSock.send(cmd.encode('utf-8')) # 1. 先收报头,从报头里解出真实数据长度 header = clientSock.recv(1024) total_size = struct.unpack('i', header)[0] # 2. 接收真实数据 cmd_res = b'' recv_size = 0 while recv_size &lt; total_size: data = clientSock.recv(1024) recv_size += len(data) cmd_res += data print(cmd_res.decode('utf-8'))clientSock.close() 可以看出来,数据可以收干净了,所以目前来讲是不存在粘包问题的,但是问题又来了,在实际应用中,想要传输的数据如果很大怎么办?这种办法也可以行得通吗? 当我把要传输的数据大小调大时: 123# demoimport structdata_len = struct.pack('1', 1111111111111111111) 运行结果 这说明 struct 转化 int 类型的时候是有大小限制的,数字太大的转不了,那么 struct 还有一个类型表示长整形的为 q, 来试试看. 123# demoimport structdata_len = struct.pack('q', 11111111111) 运行结果 可以看出来是可以转的,转成了8个字节,那么如果数字在大一点呢,总归有一个不能转的数字,那么这就不是最好的解决办法. 解决办法二我们只想接收端接收到真实的数据长度就可以了,那么可不可以用一个容器把真实数据长度保存然后通过转化传输出去呢. 这就是在自己开发一款 C/S 程序时需要考虑的问题了,涉及到数据传输的话就需要自定义报头了.报头就是可以将真实数据的一些信息保存起来,先于真实数据发送出去 自定义报头 123456789101112131415import structimport jsonheader_dic = &#123; 'filename': 'musibii.jpg', 'md5': '165069c8f668edb6b48f208f7a5c6a00', 'total_size': 11111111111111111111111111111111111111&#125;header_json = json.dumps(header_dic)header_bytes = header_json.encode('utf-8')print(len(header_bytes), header_bytes)data_bytes_len = struct.pack('i', len(header_bytes))print(data_bytes_len,len(data_bytes_len)) 运行结果 可以看出来,通过这种方法可以把数据量很大的东西发送给客户端. 具体解决办法 服务端 123456789101112131415161718192021222324252627282930313233343536373839404142434445from socket import *import json,structserverSock = socket(AF_INET, SOCK_STREAM)serverSock.bind(('', 9090))serverSock.listen(5)while True: conn, addr = serverSock.accept() while True: try: data = conn.recv(1024) if len(data) == 0: break obj = subprocess.Popen(data.decode('utf-8'), shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE) stdout = obj.stdout.read() stderr = obj.stderr.read() data_bytes_len = len(stdout) + len(stderr) # 1. 先制作报头 header_dic = &#123; 'filename': 'musibii.jpg', 'md5': '165069c8f668edb6b48f208f7a5c6a00', 'total_size': data_bytes_len &#125; header_json = json.dumps(header_dic) header_bytes = header_json.encode('utf-8') # 2. 先发送4个 bytes 的字典转化后的字节 conn.send(struct.pack('i', len(header_bytes))) # 3. 发送完整报头 conn.send(header_bytes) # 4. 发送真实数据 conn.send(stdout) conn.send(stderr) except ConnectionResetError as e: print(e) break conn.close()serverSock.close() 客户端 12345678910111213141516171819202122232425262728293031323334from socket import *import struct,jsonclientSock = socket(AF_INET, SOCK_STREAM)clientSock.connect(('', 9090))while True: cmd = input('&gt;&gt;&gt;').strip() if len(cmd) == 0: continue clientSock.send(cmd.encode('utf-8')) # 1. 先收4bytes 的服务端发过来的转化报头 header_size = struct.unpack('i', clientSock.recv(4))[0] # 2. 接收完整的报头,就是 header_dic header_bytes = clientSock.recv(header_size) # 3. 转化得到完整的报头字典 header_json = header_bytes.decode('utf-8') header_dic = json.loads(header_json) # 4. 根据 key 得到真实数据长度 total_size = header_dic['total_size'] # 5. 接受真正的数据 cmd_res = b'' recv_size = 0 while recv_size &lt; total_size: data = clientSock.recv(1024) recv_size += len(data) cmd_res += data print(cmd_res.decode('utf-8'))clientSock.close() 这个程序就加了两个步骤,在发送真实数据之前发送了4个字节的报头,然后发送了真是的报头数据. 首先在服务端定义报头(字典类型),由字典转为 json 格式,由 json 格式转为二进制,由 struct 转成四个字节的数据,客户端收到4个字节struct 转化的数据, unpack 成二进制, decode 为 json 格式的数据类型,然后反序列化成 python 字典类型,得到里面的真实数据长度.然后服务端发送真实数据,客户端循环接收真实数据. 到此,就完美的解决了粘包的问题.如有不对的地方,欢迎指正.]]></content>
      <categories>
        <category>网络编程</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[网络编程(三)]]></title>
    <url>%2F2018%2F11%2F07%2F%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B-%E4%B8%89%2F</url>
    <content type="text"><![CDATA[在之前两篇文章我们已经大概了解了互联网的工作原理,知道了一个数据包的诞生与结束中间经历的过程,那么在这篇博客我们将了解一个稳定可靠地 TCP 连接是怎么产生的,它的数据传送有什么优点和缺点? 该博客将重点介绍 传输层的 TCP 协议建立连接和断开连接的过程. UDP 因为不是可靠的连接所以就不重点介绍了. 介绍在传输层通常遵循的协议为 TCP 和 UDP协议,并且是基于端口运行的,但是两者为应用层提供不同的服务. TCP 提供的是一种稳定,可靠地字节流服务. 面向连接意味着两个使用 TCP 的应用在数据传送之前需要建立 TCP 连接.这一过程可以理解为打电话,先拨号,等待接通,然后稳定的通信. 那么 UDP 是无连接,不可靠的数据包服务,因为无连接,所以可能会产生丢包,但是效率却较高,因为不用对方发送确认包,所以 UDP 广泛应用与游戏,直播等软件. TCP 报文格式在网络编程(二)中已经知道 TCP是基于端口发送数据包的,所以会记录本机端口号和目的端口号,具体格式如下: 上图有几个重要的字段需要了解: 序 列号: seq 序号,占32位,用来标识从 TCP 源端向目的端发送的字节流,发送方的发送数据时对比进行标记; 确认号: ACK 序号,占32位,只有 ACK 标志位位1时,确认号字段才有效, ack=seq+1; 标志位:共6个,即 URG,ACK,PSH,RST,SYN,FIN 等,具体含义如下: URG: 紧急指针有效; ACK: 确认序号有效; PSH: 接收方应该尽快将报文交给应用层; RST: 重置连接; SYN: 发起一个新连接 FIN: 释放一个连接. 两个号码 Sequene number: 顺序号码 Acknowledge number: 确认号码 注意: 不要将确认序号 Ack 与标志位中的 ACK 搞混了; 确认方 ack=seq+1(不论哪方发送),两端才建立连接. 三次握手详解所谓的三次握手( Three-Way Handshake)即建立 TCP 连接,就是指建立一个 TCP 连接时,需要客户端和服务端发送三个包用来确认连接的建立.在套接字编程中,这一过程由客户端执行 connect 来主动触发,整个流程如下: 三次握手 第一次握手: 客户端发送 SYN 包( seq=x)的数据包到服务器,并进入 SYN_SEND 状态,等待服务器确认; 第二次握手: 服务器收到 SYN 包,必须确认客户端的 SYN(ACK=x+1),同时自己也发送一个 SYN 包(seq=y),即 SYN+ACK 包,此时服务器进入 SYN_RCVD 状态; 第三次握手: 客户端收到服务器的 SYN+ACK 包,向服务器发送确认包 ACK(ACK=y+1),此包发送完毕,客户端和服务端都进入 ESTABLISHED 状态,完成三次握手. 注意 握手过程传送的包不包含任何数据,三次握手完毕后,客户端与服务器才正式开始传送数据.理想状态下, TCP 连接建立.在通信双方中的任何一方主动关闭连接之前, TCP 连接都将被一直保持下去.(双方都可以主动断开连接) 四次挥手详解在建立 TCP 连接之后,客户端和服务端开始传输数据,因为这是双向连接,所以任一方都可以主动断开连接. 四次挥手 第一次挥手: 主动关闭方发送一个 FIN, 用来关闭主动方到被动方的数据传送,也就是主动关闭方告诉被动关闭方:我的数据传输已经完成了,不会再给你发送数据了(当然,在 FIN 包之前发送出去的数据,如果没有收到对应的 ACK 确认报文,主动关闭方依然会重发这些数据),但是此时主动关闭方还可以接收数据. 第二次挥手: 被动关闭方收到 FIN 包后,发送一个 ACK 给对方,确认序号为收到序号+1(与 SYN 相同,一个 FIN 占用一个序号). 第三次挥手: 被动关闭方发送一个 FIN, 用来关闭被动关闭方到主动关闭方的数据传送,也就是告诉主动关闭方,我的数据也发送完成,不会再给你发送数据了(但是在 FIN 发送之前发送的数据仍然需要主动关闭方发送确认包). 第四次挥手: 主动关闭方收到 FIn 后,发送一个 ACK 给被动关闭方,确认序号为收到序号+1,至此,完成四次挥手. TCP 状态转换图 CLOSED: 表示初始状态 LISTEN(服务器): 表示服务器的某个套接字处于坚挺状态,可以接受客户端的连接 YN_RCVD(服务器): 这个状态表示服务器接收到了客户端的 SYN 报文,在正常情况下,这个状态是服务端的 SOCKET 在建立 TCP 连接时的三次握手会话过程中的一个中间状态,很短暂,基本上用 netstat 是很难看到这种状态的,因此这种状态时,当收到客户端的 ACK 报文后,他会进入 ESTABLISHED 状态 SYN_SENT: 这个状态与 SYN_RCVD 相对应,当客户端SOCKET 执行 CONNECT 连接时,它首先发送 SYN 报文,因此也随机会进入 SYN_SENT, 并等待服务端发送三次连接中的第二个报文. SYN_SENT 表示客户端已发送 SYN 请求连接报文. ESTABLISHED: 表示连接已经建立 FIN_WAIT_1: 其实 FIN_WAIT_1和 FIN_WAIT_1状态的真正含义都是表示等待对方的 FIN 报文.而这两种状态的区别是: FIN_WAIT_1状态实际上是当SOCKET 在 ESTABLISHED 状态时,它想主动关闭连接,向对方发送了 FIN 报文,此时该 SOCKET 即进入到 FIN_WAIT_1状态.而当对方回应ACK 报文后,则进入到 FIN_WAIT_2状态,当然在实际的正常情况下,无论对方在何种情况,都应该回应 ACK 报文,所以 FIN_WAIT_1状态一般是不容易见到的,而 FIN_WAIT_2可以用 netstat 看到 FIN_WAIT_2: 实际上 FIN_WAIT_2状态下的 SOCKET, 表示半连接,也即有一方要求 CLOSE 连接,但另外还告诉对方,我暂时还有点数据需要传送,等会再关闭连接 TIME_WAIT: 表示收到了对方的 FIN 报文,并发送了 ACK 报文,就等2MSL 后即可回到 CLOSED 可用状态了(初始状态).如果 FIN_WAIT_1状态下,收到了对方同时带 FIN标志和 ACK 标志的报文时,可以直接进入到 TIME_WAIT 状态,而无需经过 FIN_WAIT_2状态 注意: MSL( 最大分段生存期)指明 TCP 报文在 internet 上最长生存时间,每个具体的 TCP 实现都必须选择一个确定的 MSL 值. RFC1122建议为2分钟,但 BSD 传统实现了采用30秒. TIME_WAIT 状态最大保持时间是2*MSL, 也就是1-4分钟. 结论: 在 TIME_WAIT 下等待2MSL, 只是为了尽最大努力保证四次握手正常关闭.确保老的报文段在网络中消失,不会影响新建立的连接. CLOSING: 这种状态比较特殊,实际情况中很少见.正常情况下,当你发送 FIN 报文后,按理来说应该先收到(或同时受到)对方的 ACK 报文,再收到对方的 FIN 报文.但是 CLOSING 状态表示你发送 FIN 报文后,并没有收到对方的 ACK报文,反而收到了对方的 FIN 报文.那么什么情况下会出现这种情况.那就是双方几乎在同时 close 一个 SOCKET 的时候,那么久出现了双方同时发送 FIN 报文的情况,也即会出现 CLOSING 状态,表示双方都正在关闭 SOCKET 连接. CLOSE_WAIT: 这种状态的含义其实是在表示等待关闭.当对方 close 一个 SOCKET 后发送 FIN 报文给自己,系统毫无疑问会回应一个 ACK 报文给对方,此时则进入 CLOSE_WAIT 状态.接下来就需要考虑是否还有数据需要发送给对方,如果没有的话,那么就可以 close 这个 SOCKET, 发送 FIN 报文给对方,也即关闭连接.所以在 CLOSE_WAIT 状态下,需要等待你去关闭连接 LAST_ACK: 它是被动关闭一方在发送 FIN 报文后,最后等待对方的 ACK 报文.当收到 ACK 报文后,也即可以进入到 CLOSED可用状态.( 初始状态) 补充: 默认情况下,当调用 close 时,如果发送缓冲中还有数据, TCP 会继续把数据发送完; 发送了 FIN 只是表示这端不能继续发送数据(应用层不能调用 send 发送),但是仍然可以接收数据; 应用层如何知道对端关闭?通常,在最简单的阻塞模型中,当你调用 recv 时,如果返回0,则表示对端关闭.在这个时候通常的做法就是也调用close, 那么会发送 FIN, 完成四次握手.如果不调用 close, 那么对端就会处于 FIN_WAIT_2状态,而本端则会处于 CLOSE_WAIT状态. 很多时候, TCP 连接的断开都是有 TCP 层自动进行,例如使用 CTRL_C 终止程序, TCP 连接依然会正常关闭. 问题: 为什么建立连接协议是三次握手,而关闭连接是四次挥手呢? 这是因为服务端的 LISTEN 状态下的 SOCKET 收到 SYN 的请求连接时,可以把 ACK和 SYN(ACK起应答作用,而 SYN 起同步作用)放在一个报文里一起发送.但是关闭连接时,当收到对方的 FIN 报文通知时,它仅仅表示对方没有数据发送了,但是另一方未必所有的数据 都全部发送完全了,所以可能不会立马关闭 SOCKET, 也即你可能还需要发送一些数据给对方之后,再发送 FIN 报文给对方表示你同意现在关闭连接了,所以这里的 ACK 报文和 FIN 报文是分开发送的. 为什么不能用两次握手进行连接? 在三次握手中,总共需要完成两个重要的功能,既要双方做好发送数据的准备工作(双方都知道彼此已经准备好),也要允许双方就初始序列号进行协商,这个序列号在握手过程中被发送和确认. 现在把三次握手改成仅需要两次握手,是可能会发生死锁的.考虑计算机客户端和服务端之间的通信,假定客户端给服务端发送一个连接请求分组,服务端收到了这个分组,并发送了确认应答分组.按照两次握手的协定,服务端认为链接已经成功的建立了,可以开始发送数据分组.可是,客户端在服务端的应答分组在传输中被丢失的情况下,将不会知道服务端是否已准备好,不知道服务端建立什么样的序列号,客户端甚至会怀疑服务端是否收到自己的连接请求分组.在这种情况下,客户端认为连接还未建立成功,将忽略服务端发来的任何数据分组,只等待连接确认应答分组.而服务端在发出的数据分组超时后,重复发送同样的数据分组,就形成了死锁. 为什么 TIME_WAIT 状态需要等2MSL 后才能返回到 CLOSED 状态? 什么是 MSL? MSL 即Maximum Segment Lifetime, 也就是报文最大生存时间.’MSL 是任何报文段被丢弃前在网络内的最长时间.’那么,2MSL 也就是这个时间的两倍,当 TCP 连接完成四个报文段的交换时,主动关闭的一方将继续等待一定时间(2-4)分钟,即使两端的应用程序结束. 为什么需要2MSL 呢. 第一,虽然双方都同意关闭连接了,而且握手的四个报文也都协调和发送完毕,按理可以直接回到 CLOSED 状态(就好比从 SYN_SEND 状态到 ESTABLISH 状态那样);但是因为对方处于 LAST_ACK 状态下的 SOCKET 可能会因为超时未收到 ACK 报文,而重发 FIN 报文,所以这个 TIME_WAIT 状态的作用就是用来重发可能丢失的 ACK 报文. 第二,报文可能会被混淆,意思是说其他时候的连接可能会被当做本次的连接. 当某个连接的一端处于 TIME_WAIT 状态时,该连接将不能再被使用.事实上,对于我们比较有现实意义的是,这个端口将不能再被使用.某个端口处于 TIME_WAIT(其实应该是这个连接) 状态时,这意味着这个 TCP 连接并没有断开(完全断开),那么.如果你 bind 这个端口,就会失败.对于服务器而言,如果服务器突然 crash 掉了,那么他将无法在2MSL 内重新启动,因为 bind 会失败.解决这个问题的一个方法就是设置 SOCKET 的 SO_REUSEADDR 选项.这个选项意味着可以重用一个地址. 当建立一个 TCP 连接时,服务端会继续用原有端口监听,同时用这个端口与客户端通信.而客户端默认情况下会使用一个随机端口与服务端的监听端口通信.有时候,为了服务端的安全性,我们需要对客户端进行验证,即限定某个 IP 的某个特定端口的客户端.客户端可以使用 bind 来使用特定的端口.对于服务端,当设置了 SO_REUSEADDR 选项时,它可以在2MSL 内启动并 listen成功.但是对于客户端,当使用 bind 并设置 SO_REUSEADDR 时,如果在2MSL 内启动,虽然 bind 会成功,但是在 windows 平台上 connect 会失败.而在 linux 是哪个不存在这个问题. 要解决 windows 平台的问题,可以设置 SO_LISTEN 选项. SO_LINGER 选项决定调用 close 时 TCP 的行为. SO_LINGER 涉及到 linger 结构体,如果设置结构体中 l_onoff 为非0,l_linger 为0,那么调用 close 时 TCP 连接会立刻断开, TCP 不会将发送缓冲中未发送的数据发送,而是立即发送一个 RST 报文给对方,这个时候 TCP 连接(关闭时)就不会进入 TIME_WAIT 状态.这样做虽然解决了问题,但是并不安全.通过以上方式设置 SO_LINGER 状态,等同于设置 SO_DONTLINGER 状态. 当 TCP 连接发生一些物理上的意外情况时,例如网线断开, linux 上的 TCP 实现会依然认为该连接有效,而 windows 则会在一定时间后返回错误信息.]]></content>
      <categories>
        <category>网络编程</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[网络编程(二)]]></title>
    <url>%2F2018%2F11%2F06%2F%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B-%E4%BA%8C%2F</url>
    <content type="text"><![CDATA[六 网络编程(一)总结首先对网络编程(一)做个总结:我们现在知道互联网通信其实就是发送数据包与接收数据包.电脑 A 向电脑 B 发送一个数据包, B 收到然后回复一个数据包,才实现了电脑之间的通信.数据包的结构,基本是下图的形式: 想要发送这个数据包需要知道两个地址: 对方的 MAC 地址 对方的 IP 地址 只有发送方知道这两个地址,数据包才可以准确的发送到接收方.之前已经了解,单纯的 MAC 地址是有局限性的,就是只能在一个局域网内通过MAC 地址通信,如果两台计算机不在一个局域网,那么只能发送给网关( gateway),由网关走路由协议发送给对方. 上图中,1号狄电脑想要个4号电脑通信.首先需要知道对方电脑的 IP 和子网掩码,然后通过 ARP 协议计算出自己和对方的网络号,然后判断是否处于同一个局域网,不是的话,1号电脑将数据包发给网关 A. 网关 A 通过路由协议,发现4号电脑位于网络 B, 又把数据包发给网关 B, 网关 B 再转发给4号电脑. 1号电脑想要把数据包发给网关 A, 首先必须知道网关 A 的 MAC 地址.所以,数据包的目标地址,实际上分为两种情况: 场景 数据报地址 同一个局域网 对方的 MAC 地址,对方的 IP 地址 非同一个局域网 网关的 MAC 地址,对方的 IP 地址 发送数据包之前,电脑必须判断对方与自己是否处于同一个局域网,然后选择相应的处理方式来发送数据包. 四 首次联网相关设置一 静态IP 设置当我们购买了一台新电脑时,插上网线,开机,这时候电脑能够上网吗?说到这想到我大二干的一件蠢事,那时候不知道路由器的工作原理,以为买了路由器就可以连无线网上网了,然后兴冲冲在网上买了一个路由器,收到货之后插上电,插上网线,发现 WiFi 倒是出现了,可是连上却没有反应,然后我就想啊,不对啊怎么连不上网?之后我想明白了,我 TM 的根本就没装宽带,哪来的网.好在那个路由器也没闲着,终于在去年服役了… 当购买的新电脑连上网线时,通常需要做一些设置,一般现在都会自动设置 IP, 子网掩码 DNS 服务器啦,但是也有有手动设置的,一般会设置四个参数: 本机 IP 地址 子网掩码 网关 IP 地址 DNS IP 地址 看看 linux 系统的设置 这四个参数缺一不可,由于这是给定的,计算机每次开机都会分到同样的 IP 地址,所以这种情况称为静态 IP 地址上网. 但是这样的设置比较专业,而且不够灵活.所以大多数用户使用动态 IP 地址上网. 二 动态 IP 地址上网所谓动态 IP 地址,值得是计算机开机后,会由服务器自动分配一个 IP 地址,不需要人为设置.使用的协议为 动态主机设置协议(Dynamic Host Configuration Protocol，DHCP) 协议,是一个局域网的网络协议,使用 UDP协议工作,主要有两个用途: 用于内部网或网络服务供应商自动分配 IP 地址给用户; 用于内部网管理员作为对所有计算机作中央管理的手段. 这个协议规定,每一个局域网中,有一台计算机负责管理本网络的所有 IP 地址,它叫做DHCP 服务器.新的计算机加入网络,首先必须向 DHCP 服务器发送一个 DHCP 请求数据包,申请 IP 地址和相关的网络参数. 前面说过,如果两台计算机在同一个局域网,必须知道对方的 MAC 地址和 IP 地址,才能发送数据包.但是新加入的计算机并不知道这两个地址,怎么发送数据包呢?这就是 DHCP 的功劳了. 三 DHCP 协议首先, DHCP 是应用层协议,建立在 UDP 之上的,数据包是这样的: 最前面的以太网标头,设置发送方(本机)的 MAC 地址和接收方( DHCP)的 MAC 地址.前着就是本机网卡的 MAC 地址,后者这时候并不知道,就填入一个广播地址:FF-FF-FF-FF-FF-FF.这个地址是具有特殊意义的MAC 地址. 后面的 IP 标头,设置发送方的 IP 地址和接收方的 IP地址.这时候,对于这两者,本机都不知道.于是发送方的 IP 地址就设为0.0.0.0,接收方得 IP 地址设为255.255.255.255. 最后的 UDP 标头,设置发送方的端口和接收方的端口.这一部分是 DHCP 协议规定好的,发送方为68端口,接收方为67端口. 数据包内容构造完成后,就可以发包了.以太网是基于广播方式发送的,同一个局域网的每个计算机都会收到这个数据包.因为接收方的 MAC 地址是FF-FF-FF-FF-FF-FF,看不出是发给谁的,所以每台计算机收到数据包后都会进行拆包才能确定是不是发给自己的.当看到发送方 IP 地址为0.0.0.0,接收方是255.255.255.255时, DHCP 服务器知道,哦,原来这个包是发给我的,所以其他的计算机就可以丢弃这个包了. 于是 DHCP 服务器读取数据包内容,分配好 IP 地址,发送一个 DHCP 响应数据包.这个是数据包的结构和上面是类似的,以太网标头的 MAC 地址是双方的网卡地址, IP 标头的 IP 地址是 DHCP 副武器的 IP 地址(发送方)和255.255.255.255(接收方),UDP 标头的端口是67(发送方)和68(接收方),分配给请求端的 IP 地址和本网络的具体参数则包含在 Data 部分. 新加入的计算机收到这个响应包,于是就知道了自己的 IP 地址,子网掩码,网关地址和DNS 服务器地址. 四 小结这是联网的第一步,不管是静态 IP 地址还是动态 IP 地址,想要连上互联网,需要确定这四个参数: 本机 IP 地址 子网掩码 网关 IP 地址 DNS IP 地址 只有这四个参数确定了,才可以愉快的进行网络冲浪.那么当我们访问网页的时候,互联网协议是如何工作的呢? 五 访问网页一 本机参数假定经过上一节的步骤,用户设置好了自己的网络参数: IP 地址:192.168.2.238 子网掩码:255.255.255.0 路由器(网关地址):192.168.2.1 DNS 服务器:192.168.2.1 打开浏览器访问谷歌,在地址栏输入 www.google.com,这意味着,浏览器向 google 发送一个网页请求的数据包. 二 DNS 协议我们知道,向谷歌发送一个数据包,必须要知道对方的 IP 地址.但是现在只知道一个网址,并不知道它的 IP 地址. DNS 协议可以帮助我们,将这个网址转换成 IP 地址,已经知道我们的 DNX 服务器为192.168.2.1,于是向这个地址发送一个 DNS 数据包(53端口). 然后, DNS 服务器作出相应,告诉我们谷歌的地址是174.36.196.242.于是我们知道了对方的 IP 地址. 三 子网掩码接下来需要判断该 IP地址和本机是否处于同一个局域网,这就需要子网掩码来进行 AND 位运算. 已知子网掩码是255.255.255.0,本机用子网掩码和自己的 IP地址192.168.2.238,做一个二进制的 AND 运算,计算结果为192.168.2.0,然后对谷歌的 IP 地址也做一个 AND 运算,计算结果为174.36.196.0.两个结果不相等,所以结论是谷歌与本机不在一个局域网. 因此我们想要和谷歌通信的话需要通过网关转发,网关地址为192.168.2.1,也就是所接收方得 MAC 地址是网关的 MAC 地址. 四 应用层协议浏览网页用的是 HTTP/HTTPS 协议,这两种协议的数据构造差不多: HTTP部分的内容,类似下面这样: 假定这个部分的长度为4960字节,它会被嵌在 TCP 数据包中. 五 TCP 协议TCP 数据包需要设置端口,接收方( Google)的 HTTPS默认是443,发送方(本机)的端口是一个随机生成的1024-65535之间的整数,假定为51775. TCP 数据包的标头长度为20字节,加上嵌入 HTTPS 的数据包,总长度为4980字节. 六 IP 协议然后, TCP 数据包再嵌入 IP 数据包.IP 数据包需要设置双方的 IP地址,这是已知的,发送方是192.168.2.238(本机),接收方为174.36.196.242( Google). IP 数据包的标头长度为20字节,加上嵌入的 TCP 数据包,总长度变为5000字节. 七 以太网协议最后, IP地址数据包嵌入以太网数据包.以太网数据包需要设置双方的 MAC 地址,发送方为本机的网卡 MAC 地址,接收方为网关192.168.2.1的 MAC 地址(通过 ARP 协议获得) 本机的 MAC 地址: 网关的 MAC 地址: 以太网数据包的数据部分,最大长度为1500字节,而现在的 IP 数据包长度为5000字节.因此, IP 数据包必须分割成四个包.因为每个包都有自己的标头(20字节),所以四个包的 IP 数据包的长度分别为1500,1500,1500,560. 八 服务端响应经过多个网关的转发, google 服务器收到了四个以太网数据包. 根据 IP 标头的序号, google 将四个包拼起来,取出完整的 TCP 数据包,然后读取里面的 HTTPS 请求,接着做出 HTTPS 响应,再用 TCP 协议回复一个数据包. 本机收到 HTTPS 响应以后,就可以将网页显示出来,完成以一次网络通信.]]></content>
      <categories>
        <category>网络编程</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[网络编程(一)]]></title>
    <url>%2F2018%2F11%2F02%2F%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B-%E4%B8%80%2F</url>
    <content type="text"><![CDATA[一 客户端/服务端架构 硬件 C/S 架构 软件 C/S 架构 互联网处处是 C/S 架构的 如一个网站就是服务端,浏览器是客户端( B/S 架构) 服务端需要遵循的原则: 服务端与客户端都需要有惟一的地址,但是服务端的地址必须固定/绑定 对外一直提供服务,需要稳定运行 服务端需要支持并发 网络 网络建立的目的是为了数据交互(通信) 如何实现通信: 1. 建立好底层的物理连接介质 2. 有一套统一的通信标准,称之为互联网协议 互联网协议:就是计算机界的标准语言 二 七层模型总览互联网的实现,总共可以分为七层.每一层都靠下一层的支持.用户接触的是第七层,也就是应用层.想要理解互联网协议,必须从最下层开始,自下而上理解每一层的功能. OSI 模型可以分为七层,五层,四层,其实都是一个道理,只不过合并了几层而已.从下而上分别为:物理层,数据链路层,网络层,传输层,会话层,表示层,应用层. 每层运行常见的物理设备: 三 tcp/IP 五层模型理解一般讲应用层,表示层,会话层并做应用层,从 tcp/IP 五层协议的角度来阐述每层的由来和功能,搞清楚了每层的主要协议也就理解了互联网通信的原理. 每层都运行特定的协议,越往上越靠近用户,越往下越靠近硬件. 一 物理层物理层也可以称之为实体层.电脑想要互相通信,第一件事先要把电脑连起来,可以用光缆,电缆等方式实现通信.这就叫实体层,它就是把电脑连接起来的物理手段.它主要规定了网络的一些电器特性.它的功能室基于电器特性发送高低电压(电信号),高电压对应数字1,低电压对应数字0. 二 数据链路层物理层单纯的传输电信号0和1没有任何意义,必须规定电信号多少位一组,每组什么意思. 数据链路层的功能:定义了电信号的分组方式,这就是数据链路层的功能,它在物理层的上方,确定了0和1的分组方式. 1 以太网协议早期的时候各个公司都有自己的分组方式,后来形成了统一的标准,即以太网协议 Ethernet. Ethernet 规定 一组电信号构成一个数据包,也叫数据帧 每一组数据帧分成:报头 head 和数据 data 两部分 报头包含数据包的一些说明项,比如发送者的源地址,接受者的源地址以及数据类型等等. 发送者/源地址: 6个字节 接受者/目标地址: 6个字节 数据类型: 6个字节 数据则是数据包的具体内容 数据包最短为46字节,最长为1500字节 所以一个数据帧的长度最短为64字节,最长1518字节,超过最大限制就分片发送. 2 mac 地址head 中包含的源地址和目标地址的由来: Ethernet 规定接入 Internet 的设备都必须具备网卡,发送端和接收端的地址便是指网卡的地址,即MAC 地址. mac 地址:每块网卡出厂时都被烧制上世界上一个惟一的MAC 地址,长度为48位2进制,通常由12位16进制数表示(前六位是厂商编号,后六位是流水线号) 装了好多次虚拟机,我现在也不知道那个是我的了… 3 广播定义MAC 地址只是第一步,在一部电脑第一次接入局域网的时候,是怎么知道它的MAC 地址的呢.在局域网内通信都是通过MAC 地址来发包收包的,只要知道了对方的MAC 地址才可以互相通信.这就要靠ARP(addres resolution protocol) 协议来获取MAC 地址了,那么 arp 协议是如何解析出对方的MAC 地址呢? 这里等到了网络层再来解释. 注意:以太网数据包必须知道接收方的MAC 地址,才能发包. 那么在同一个局域网内,知道了对方的MAC 地址,系统怎样才能把数据包准确送到接收方呢? 以太网采用了一种很’原始’的方式,它并不是直接把数据包发到接收方,而是向局域网内所有的计算机发送,让每台计算机自己拆包后判断自己是否为接收方(前提知道对方MAC 地址) 上图中,1号计算机向2号计算机发送一个数据包,局域网内其他的计算机都会收到这个包.他们读取数据包的报头,找到接收方得MAC 地址,然后与自身的MAC 地址相比较,如果两者相同,就接收这个包,做进一步的处理,不相同的话就丢弃这个数据包.这种发送方式叫’广播’. 有了数据包的定义,网卡的MAC 地址,广播的发送方式,数据链路层就可以在同一局域网内的计算机之间传送数据了. 三 网络层1 网络层的由来以太网协议,依靠MAC 地址发送数据,但这仅仅只能在同一个局域网内发送数据.理论上,依靠MAC 地址,是可以和全球任何一个MAC 地址发送数据的,因为MAC 地址是惟一的.但是这样做有一个致命的缺陷. 以太网依靠广播方式发送数据包,而广播就意味着每个人都要发送一份,那么全球这么多的计算机,在找到对方的MAC 地址之前都要发一份无疑会造成巨大的浪费,而且效率极低,而且局限在发送者的局域网.也就是说,如果两台计算机不在同一个局域网,广播是传不过去的.这种设计是合理的,否则的话互联网上每一台计算机都会收到所有包,那会引起灾难. 互联网可以想象成由无数个局域网组成的一个巨型网络,如果想要跨局域网通信必须找到另一种方式,能够区分哪些MAC 地址属于同一个局域网,哪些不属于同一个局域网.如果是同一个局域网的话,就采用广播发送(如何知道对方的MAC 地址),否则就采用’路由’的方式发送.(‘路由’的意思,就是指如何向不同局域网发送数据包) 这就导致了’网络层’的诞生.它的作用是引进一套新的地址,使得我们能够区分不同的计算机是否属于同一个局域网.这套地址叫做’网络地址’,简称’网址’. 于是,网络层出现以后,每台计算机有了两种地址,一种是MAC 地址,另一种是网络地址.两种地址之间没有任何联系,MAC 地址是绑定到网卡上的,网络地址则是由MAC 服务器分配的,当一台计算机第一次联网时,会向MAC 服务器发送一个包,然后MAC 服务器会分配好网络地址. 网络地址帮助我们确定计算机所在的局域网,MAC 地址则将数据包发送到该局域网中的目标MAC 地址.因此从逻辑上判断,必定是先处理网络地址,然后处理MAC 地址. 可以这样理解,互联网中的通信都是MAC 地址互相发送数据包,而网络地址是为了帮我们确认需要往哪个局域网里面的目标MAC 地址发送数据包,两者缺一不可. 2 IP 协议规定网络地址的协议,叫做 IP 协议.它定义的地址,称为 IP 地址. 目前,广泛采用的是 IP 协议第四版,简称 IPV4.这个版本规定,网络地址由32个二进制位组成. 可以看出我的 IP 地址为192.168.11.95,习惯上,用四段的十进制数表示 IP 地址,从0.0.0.0到255.255.255.255. IP 地址一般分为5类:A,B,C,D,E 类, D 和E 类为其他用途的. 可以看粗来 IP 地址是有限的,而且现在的 IPV4 地址已经分完了,以后使用的就是 IPV6了,据说世界上的每一粒沙子都有一个惟一的 IP 地址. 互联网上的每一台计算机,都会分配到一个 IP 地址.这个地址分为两部分,前一部分代表网络,后一部分代表主机.比如, 我的 IP 地址192.168.11.95,这是一个32位的地址,我的网络部分是前面24位192.168.11,那么主机号就是后8位.处于同一个局域网的电脑,它们 IP 地址的网络部分必定是相通的,也就是说192.168.11.95与192.168.11.49处于同一个局域网. 但是我们单纯从 IP 地址是无法判断网络部分的,我为什么知道我的 IP 地址的网络号?其实没有另外一个地址的话我也不知道的. 那么怎样从 IP 地址来判断计算机是否处于同一个局域网呢?这就是另外一个地址的作用了,也就是子网掩码. 所谓子网掩码,就是表示子网络特征的一个参数.它在形式上等同于 IP 地址,也是一个32位二进制数字,它的网络部分全为1,主机部分全部为0.比如我的 IP192.168.11.95,因为我的网络部分为前24位,那么我的子网掩码就是255.255.255.0. 知道了子网掩码,就可以判断,任意两个 IP 地址是否处于同一个局域网.方法是将两个 IP 地址与子网掩码分别进行 AND 运算(两个数位都为1,则为1,否则为0),然后比较结果是或否相同,如果相同,就表明处在同一个局域网,否则就不是,就需要通过路由协议发送数据包. IP 协议的作用主要有两个:一个是为每一台计算机分配 IP 地址,另一个是和子网掩码结合确定元 IP 与目标 IP 是否处于同一个局域网. 3 IP 数据包根据 IP 协议发送的数据,叫做 IP 数据包,不难想象,其中必定包括 IP 地址信息. 但是前面说过.以太网数据包只包含MAC 地址,并没有 IP 地址的位置.那么是否需要修改数据定义在添加一个位置呢? 我们可以直接把 IP 数据包放进以太网数据包的数据部分,因此完全不用修改以太网的规格.这就是互联网分层结构的好处:上层的变动完全不涉及下层的结构. 具体来说, IP 数据包也分为报头和数据两个部分 报头部分主要包括版本,长度, IP 地址等信息,数据部分则是 IP 数据包的具体内容.它放进以太网数据包后,以太网数据包就拥有了两个报头. IP 数据包的报头部分的长度为20到60个字节,整个数据包的总长度最大为65535字节.因此,理论上,一个 IP 数据包的数据部分,最长为65515字节,前面说过,以太网数据包的数据部分,最长为1500字节.因此,如果 IP 数据包超过了1500字节,它就需要分割成几个以太网数据包,分开发送. 4 ARP 协议从数据链路层和网络层我们知道,想要发送一个数据包,必须知道两个地址,一个是对方的 MAC 地址,另一个是对方的 IP 地址.通常情况下,对方的 IP 地址是已知的,但是不知道对方的 MAC 地址. 所以需要一种机制能够从 IP 地址得到 MAC 地址. 这里可以分为两种情况:第一种情况,如果两台主机不在同一个局域网,那么事实上没办法得到对方的 MAC 地址,只能把数据包传送到两个局域网连接处的网关’ gateway’,让网关去处理. 第二种情况,如果两台主机在同一个局域网,那么可以使用 ARP 协议,得到对方的 MAC 地址. ARP 协议也是发送一个数据包(包含在以太网数据包中),其中包含它索要查询主机的IP 地址,在对方 MAC 地址这个位置,填的是 FF:FF:FF:FF:FF:FF,表示这是一个广播地址.它所在局域网的每一台计算机都会收到这个数据包,从中取出IP地址，与自身的IP地址进行比较。如果两者相同，都做出回复，向对方报告自己的MAC地址，否则就丢弃这个包。 总之，有了ARP协议之后，我们就可以得到同一个子网络内的主机MAC地址，可以把数据包发送到任意一台主机之上了。 四 传输层1 传输层的由来有了MAC地址和IP地址，我们已经可以在互联网上任意两台主机上建立通信。 接下来的问题是，同一台主机上有许多程序都需要用到网络，比如，你一边浏览网页，一边与朋友在线聊天。当一个数据包从互联网上发来的时候，你怎么知道，它是表示网页的内容，还是表示在线聊天的内容？ 也就是说，我们还需要一个参数，表示这个数据包到底供哪个程序（进程）使用。这个参数就叫做”端口”（port），它其实是每一个使用网卡的程序的编号。每个数据包都发到主机的特定端口，所以不同的程序就能取到自己所需要的数据。 “端口”是0到65535之间的一个整数，正好16个二进制位。0到1023的端口被系统占用，用户只能选用大于1023的端口。不管是浏览网页还是在线聊天，应用程序会随机选用一个端口，然后与服务器的相应端口联系。 “传输层”的功能，就是建立”端口到端口”的通信。相比之下，”网络层”的功能是建立”主机到主机”的通信。只要确定主机和端口，我们就能实现程序之间的交流。因此，Unix系统就把主机+端口，叫做”套接字”（socket）。有了它，就可以进行网络应用程序开发了。 2 UDP 协议现在，我们必须在数据包中加入端口信息，这就需要新的协议。最简单的实现叫做UDP协议，它的格式几乎就是在数据前面，加上端口号。 UDP数据包，也是由”报头”和”数据”两部分组成。 “报头”部分主要定义了发出端口和接收端口，”数据”部分就是具体的内容。然后，把整个UDP数据包放入IP数据包的”数据”部分，而前面说过，IP数据包又是放在以太网数据包之中的，所以整个以太网数据包现在变成了下面这样： 3 TCP 协议UDP协议的优点是比较简单，容易实现，但是缺点是可靠性较差，一旦数据包发出，无法知道对方是否收到。 为了解决这个问题，提高网络可靠性，TCP协议就诞生了。这个协议非常复杂，但可以近似认为，它就是有确认机制的UDP协议，每发出一个数据包都要求确认。如果有一个数据包遗失，就收不到确认，发出方就知道有必要重发这个数据包了。 因此，TCP协议能够确保数据不会遗失。它的缺点是过程复杂、实现困难、消耗较多的资源。 TCP数据包和UDP数据包一样，都是内嵌在IP数据包的”数据”部分。TCP数据包没有长度限制，理论上可以无限长，但是为了保证网络的效率，通常TCP数据包的长度不会超过IP数据包的长度，以确保单个TCP数据包不必再分割。 五 应用层应用程序收到”传输层”的数据，接下来就要进行解读。由于互联网是开放架构，数据来源五花八门，必须事先规定好格式，否则根本无法解读。 “应用层”的作用，就是规定应用程序的数据格式。 举例来说，TCP协议可以为各种各样的程序传递数据，比如Email、WWW、FTP等等。那么，必须有不同协议规定电子邮件、网页、FTP数据的格式，这些应用程序协议就构成了”应用层”。 这是最高的一层，直接面对用户。它的数据就放在TCP数据包的”数据”部分。因此，现在的以太网的数据包就变成下面这样。 至此，整个互联网的五层结构，自下而上全部讲完了。这是从系统的角度，解释互联网是如何构成的.]]></content>
      <categories>
        <category>网络编程</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[异常处理]]></title>
    <url>%2F2018%2F11%2F01%2F%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86%2F</url>
    <content type="text"><![CDATA[异常之问 什么是异常? 异常就是程序运行时发生错误的信号(在程序出现错误时,则会产生一个异常,若程序没有处理它,则会抛出该异常,程序的运行也随之终止)在Python 中,错误触发的异常如下: Traceback 为异常的追踪信息 NameError 为异常的类型 name ‘a’ is not defined 为异常值 在 Python 中的错误分为两种: 语法错误:这种错误,通过不了 python 的语法检测,这种错误也捕捉不了,必须在程序执行前改正. 逻辑异常:语法没问题,通过了 Python的语法检测,但因为对 python 数据类型的错误使用导致出错. 异常的种类 在 Python 中不同的异常可以用不同的类型( python 中统一了类与类型,类型即类)去标识,一个异常标识一种错误. 常用异常: AttributeError 试图访问一个对象没有的属性 IOError 输入/输出异常;通常为无法打开文件 ImportError 无法引入模块或包;基本上是路径问题或名称错误 IndentationError 语法错误的子类;代码没有正确对其 IndexError 下标索引超出序列边界 KeyError 试图访问字典中不存在的键 KeyboardInterrupt 键盘终止,通常为 Ctrl+C 同时被按下 NameError 使用一个还未被赋予对象的变量 SyntaxError python 代码非法,代码不能编译 TypeError 传入对象类型与要求的不符合 UnboundLocalError 试图访问一个还未被赋值的局部变量,基本是由于另有一个同名的全局变量,导致你以为正在访问它 ValueError 传入一个调用者不期望的值,即使值得类型是正确的 更多异常: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748ArithmeticErrorAssertionErrorAttributeErrorBaseExceptionBufferErrorBytesWarningDeprecationWarningEnvironmentErrorEOFErrorExceptionFloatingPointErrorFutureWarningGeneratorExitImportErrorImportWarningIndentationErrorIndexErrorIOErrorKeyboardInterruptKeyErrorLookupErrorMemoryErrorNameErrorNotImplementedErrorOSErrorOverflowErrorPendingDeprecationWarningReferenceErrorRuntimeErrorRuntimeWarningStandardErrorStopIterationSyntaxErrorSyntaxWarningSystemErrorSystemExitTabErrorTypeErrorUnboundLocalErrorUnicodeDecodeErrorUnicodeEncodeErrorUnicodeErrorUnicodeTranslateErrorUnicodeWarningUserWarningValueErrorWarningZeroDivisionError 异常处理 为了保证程序的健壮性与容错性,即在遇到错误时程序不会崩溃,我们需要对异常进行处理.如果错误发生的条件是可预知的,需要用 if 进行处理:在错误发生之前进行预防;如果错误的发生条件不可预知,则需要用 try…except: 在错误发生之后进行处理. 12345# 基本语法try: 被检测的代码块except 异常类型: try 中一旦检测到异常,就执行这个位置的逻辑 几个栗子: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485# 异常类只能用来处理指定的异常情况,如果非指定异常则无法处理s1 = 'hello'try: int(s1)except IndexError as e: # 捕获异常失败,报错 print(e) # 多分支s1 = 'hello'try: int(s1)except IndexError as e: print(e)except KeyError as e: print(e)except ValueError as e: print(e)# 万能异常 Exceptions1 = 'hello'try: int(s1)except Exception as e: print(e) # 多分支异常与万能异常# 如果想要的效果是:无论出现什么异常,我们统一丢弃,或者使用同一段代码逻辑去处理它们,那么一个 Exception 就够了.# 如果想要对不同的异常使用不同的处理逻辑,那么就需要用到多分支异常.# 为了防止对异常类型判断错误,可以在多分支后面跟上 Exceptions1 = 'hello'try: int(s1)except IndexError as e: print(e)except KeyError as e: print(e)except ValueError as e: print(e)except Exception as e: print(e) # 异常的其他结构s1 = 'hello'try: int(s1)except IndexError as e: print(e)except KeyError as e: print(e)except ValueError as e: print(e)else: print('没有产生异常则执行')finally: print('无论异常与否,都会执行该代码') # 主动触发异常try: raise TypeError('类型错误')except Exception as e: print(e)# 自定义异常class ExceptionMusibii(BaseException): def __init__(self, msg): self.msg = msg def __str__(self): return self.msg try: raise ExceptionMusibii('类型错误')except ExceptionMusibii as e: print(e)# 断言: assert 条件assert 1 == 1assert 2 == 2# 总结:try...except# 1. 把错误处理和真正的工作分开来;# 2. 代码更易组织,更清晰,复杂的工作任务更容易实现;# 3. 代码更加健壮,不易崩溃. 什么时候用异常处理 只有在错误发生的条件无法预知的情况下才应该加上 try…except]]></content>
      <categories>
        <category>Python</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[热河]]></title>
    <url>%2F2018%2F10%2F31%2F%E7%83%AD%E6%B2%B3%2F</url>
    <content type="text"><![CDATA[《热河》 作词：李志 作曲：李志 热河路就像八十年代的金坛县 梧桐 垃圾 灰尘 和各式各样的杂货店 人们总是早早的离开 拉上卷帘门 在天黑前穿上毛衣 点一根烟 热河路有一家 开了好多年的理发店 不管剪什么样的发型 你只要付五块钱 老板和他的妹妹坐在椅子上 对着镜子一言不发 他们的老家 在身后 在岸边 在安徽全椒县 没有人在热河路谈恋爱 总有人在天亮时伤感 如果年轻时你没来过热河路 那你现在的生活是不是很幸福 纪念碑旁 有一家破旧的电影院 往北走五百米 就是南京火车西站 每天都有外地人 在直线和曲线之间迷路 气喘嘘嘘眼泪模糊 奔跑 跌倒 奔跑 秋林龙虾换了新的地方 32路还是穿过挹江门 高架桥拆了修了新的隧道 走来走去走不出我的盐仓桥 来到城市已经八百九十六天 热河路一直是相同的容颜 偶尔有干净的潘西路过 她不会说 你好再见 没有人在热河路谈恋爱 总有人在天黑时伤感 如果年轻时你来过热河路 那你现在是不是已经被他们淹没 没有新的衣服能让你爱恋 总有一种天气让我怀念 醒来或者吃饱又是一年 相遇然后分别就在一天 没有人在热河路谈恋爱 总有人在天黑时伤感 如果年轻时你来过热河路 那你现在是不是已经被他们淹没 没有新的衣服能让我爱恋 总有一种天气让我怀念 醒来或者吃饱又是一年 相遇然后分别就在一天]]></content>
      <categories>
        <category>Music</category>
      </categories>
      <tags>
        <tag>李志</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[沧海一声笑]]></title>
    <url>%2F2018%2F10%2F30%2F%E6%B2%A7%E6%B5%B7%E4%B8%80%E5%A3%B0%E7%AC%91%2F</url>
    <content type="text"><![CDATA[《沧海一声笑》 作词：黄霑 作曲：黄霑 沧海笑滔滔两岸潮 浮沉随浪记今朝 苍天笑纷纷世上潮 谁负谁胜出天知晓 江山笑烟雨遥 涛浪淘尽红尘俗事知多少 清风笑竟惹寂寥 豪情还剩了一襟晚照 苍生笑不再寂寥 豪情仍在痴痴笑笑 啦…啦…啦… ​ 记金庸大侠（查良镛） ​ 与夏梦同一天归西 ​ 2018年10月30日]]></content>
      <categories>
        <category>Music</category>
      </categories>
      <tags>
        <tag>None</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python 模块与包的导入问题]]></title>
    <url>%2F2018%2F10%2F27%2Fpython-%E6%A8%A1%E5%9D%97%E4%B8%8E%E5%8C%85%E7%9A%84%E5%AF%BC%E5%85%A5%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[类的内置方法]]></title>
    <url>%2F2018%2F10%2F25%2F%E7%B1%BB%E7%9A%84%E5%86%85%E7%BD%AE%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[类的内置方法都是继承object基类的,内置方法通常为双下划线的方法,比如__init__方法,而类的内置方法也叫做魔术方法,因为太强大了. 在介绍魔术方法之前先看一些判断对象和类的继承关系的方法: isinstance(obj, A_tuple):判断某个对象是否属于某一个集合类的对象 issubclass(x, A_tuple): 判断某个类是否是某一个集合类的子类 1 __str__方法会在对象被打印的时候自动触发,然后将返回值当做打印的结果 使用例子: 123456789101112class People: de __init__(self, name, age): self.name = name self.age = age def __str__(self): return '&lt;%s : %s&gt;' % (self.name, self.age) peo = People('musibii', 18)print(peo) # print(peo.__str__())# 运行结果&lt;musibii : 18&gt; 2 __del__方法会在对象被删除时自动触发执行,用来在对象被删除前回收资源 使用例子: 123456789101112class Bar: def __init__(self, x, y, filepath): self.x = x self.y = y self.f = open(filepath, 'r', encoding='utf-8') def __del__(self): # 写回收系统资源相关的代码 self.f.close() obj = Bar(10, 20)del obj 未完待续]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>面向对象</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[通过字符串来操作类或对象的属性]]></title>
    <url>%2F2018%2F10%2F25%2F%E9%80%9A%E8%BF%87%E5%AD%97%E7%AC%A6%E4%B8%B2%E6%9D%A5%E6%93%8D%E4%BD%9C%E7%B1%BB%E6%88%96%E5%AF%B9%E8%B1%A1%E7%9A%84%E5%B1%9E%E6%80%A7%2F</url>
    <content type="text"><![CDATA[通过字符串来查看获取修改删除类或对象的属性的使用场景为获取用户的输入,因为得到的值都是字符串类型,那么就可以直接通过字符串来操作属性而不用把字符串修改为可以通过句点法访问的形式了. 那么有四个方法可以通过字符串来操作属性: hasattr:是否具有该属性,返回布尔值 getattr:获取属性值,没有该属性的话会报错,设置一个默认值 None setattr:修改属性值, 有就修改,没有就添加 delattr:删除属性,有就删除,没有会报错,应该加个判断 一 hasattr方法查看源码可知: 1234567def hasattr(*args, **kwargs): # real signature unknown """ Return whether the object has an attribute with the given name. This is done by calling getattr(obj, name) and catching AttributeError. """ pass 翻译过来就是:返回对象是否具有给定名称的属性。这是通过调用getattr函数和捕获AttributeError错误来完成的. 使用例子 1234567class Foo: def __init__(self, name, age): self.name = name self.age = age def tell_info(self): print('%s : %s' % (self.name, self.age)) 123456789# hasattrobj = Foo('musibii', 18)print(hasattr(obj, 'name'))print(hasattr(obj, 'age'))print(hasattr(obj, 'gender'))# 运行结果TrueTrueFalse 二 getattr方法查看源码可知: 123456789def getattr(object, name, default=None): # known special case of getattr """ getattr(object, name[, default]) -&gt; value Get a named attribute from an object; getattr(x, 'y') is equivalent to x.y. When a default argument is given, it is returned when the attribute doesn't exist; without it, an exception is raised in that case. """ pass 实际该方法是调用的传入对象的魔术方法__getattribute__,查看object的源码,从魔术方法__getattribute__的注释发现’’’return getattr(self, name)’’’,当对对象调用getattr方法是,就会触发__getattribute__方法.只有对象具有__getattribute__魔术方法,才可以使用getattr方法,一般来说除非定义类的时候改写了该方法,有不同的结果. 使用例子 12345678# getattrprint(getattr(obj, 'name'))print(getattr(obj, 'age'))print(getattr(obj, 'gender', None)) # 如果没有要获取的属性的话,应该定义默认值,否则会报错# 运行结果musibii18None 三 setattr方法查看源码可知: 1234567def setattr(x, y, v): # real signature unknown; restored from __doc__ """ Sets the named attribute on the given object to the specified value. setattr(x, 'y', v) is equivalent to ``x.y = v'' """ pass 设置所给对象的属性一个给定的值. 和getattr一样,该方法传入的对象需要有__setattr__魔术方法才可以调用getattr方法. 使用例子: 1234567891011# setattrprint(obj.__dict__)setattr(obj, 'name', 'maffia')print(obj.__dict__)setattr(obj, 'gender', 'male')print(obj,__dict__)# 运行结果&#123;'name': 'musibii', 'age': 18&#125;&#123;'name': 'maffia', 'age': 18&#125;&#123;'name': 'maffia', 'age': 18, 'gender': 'male'&#125;# 如果设置的属性对象里面没有的话会新增属性 四 delattr方法查看源码可知: 1234567def delattr(x, y): # real signature unknown; restored from __doc__ """ Deletes the named attribute from the given object. delattr(x, 'y') is equivalent to ``del x.y'' """ pass 从所给对象删除属性. 和getattr一样,该方法传入的对象需要有__delattr__魔术方法才可以调用delattr方法. 使用例子: 12345# delattr# 删除属性的时候,如果没有所给的属性名,那么会报错,所以在使用delattr的时候加上if判断delattr(obj, 'gender')if hasattr(obj, 'xxx'): delattr(obj, 'xxx')]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>面向对象</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[类方法之绑定方法和非绑定方法]]></title>
    <url>%2F2018%2F10%2F25%2F%E7%B1%BB%E6%96%B9%E6%B3%95%E4%B9%8B%E7%BB%91%E5%AE%9A%E6%96%B9%E6%B3%95%E5%92%8C%E9%9D%9E%E7%BB%91%E5%AE%9A%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[在类中定义的函数总共可以分为两大类: 绑定方法 绑定方法 特殊之处:绑定给谁就应该由谁来调用,谁来调用就会将谁当做第一个参数自动传入 绑定给对象的方法:在类中定义函数没有被任何装饰器装饰的情况下,默认就是绑定对象的. 绑定给类的方法:为类中定义函数添加一个classmethod装饰器,就是绑定给类的. 非绑定方法 特殊之处:非绑定方法就是一个普通函数,既不与类绑定又不与对象绑定,意味着类和对象都可以调用,但是无论谁来调用都是一个普通函数,没有自动传值的效果. 非绑定方法:为类中定义函数添加一个staticmethod装饰器,就是非绑定方法. 类中的绑定方法通常来说是默认给对象是用的,加了classmethod装饰器才是给类使用的,那么这三种方法的使用场景是什么呢? 默认绑定给对象的没什么好说的, 绑定给类的方法:一般用来自动实例化对象(传入某些特殊的配置文件对象), 非绑定方法:非绑定方法不用传入对象,也不用传入类,用在单纯的返回或得到某些值. 123456789101112131415161718192021222324252627282930313233343536373839404142class Foo: def func1(self): print('func1', self) @classmethod def func2(cls): print('func2', cls) @staticmethod def func3(x, y): print('func3', x, y) obj = Foo()# 绑定给对象的方法# 绑定给对象的,应该由对象来调用obj.func1()print(obj)# 运行结果func1 &lt;__main__.Foo object at 0x107e8c6d8&gt;&lt;__main__.Foo object at 0x107e8c6d8&gt;# 绑定给类的方法# 绑定给类的方法应该由类来调用print(Foo.func2)print(obj.func2) # 由对象来调用的结果一样# 运行结果&lt;bound method Foo.func2 of &lt;class '__main__.Foo'&gt;&gt;&lt;bound method Foo.func2 of &lt;class '__main__.Foo'&gt;&gt;# 非绑定方法print(obj.func3)print(Foo.func3)obj.func3(1, 2)obj.func3(1, 2)# 运行结果&lt;function Foo.func3 at 0x1063e3bf8&gt;&lt;function Foo.func3 at 0x1063e3bf8&gt;func3 1 2func3 1 2 实际使用的例子:主要是绑定给类的使用场景; 123# settings.pyIP='1.1.2.2'PORT=3306 1234567891011121314151617181920212223242526272829303132333435# main.pyimport settingsclass MySQL: def __init__(self, ip, port): self.id = self.creat_id() self.ip = ip self.port = port def tell_info(self): print('&lt;%s : %s : %s' % (self.id, self.ip, self.port)) @staticmethod def creat_id(self): import uuid return uuid.uuid4() @classmethod def from_conf(cls): return cls(settings.IP, settings.PORT) obj = MySQL('1.1.1.1', 3306)obj.tell_info()# 运行结果&lt;86044651-cea8-4d93-99dc-46a02e169d6d : 1.1.1.1 : 3306&gt;a = obj.from_conf() # 产生一个新的对象a.tell_info()# 运行结果&lt;efec5e5f-4bfc-4534-8e60-940824532506 : 1.1.1.2 : 3306&gt;obj1 = MySQL.from_conf()obj1.tell_info()# 运行结果&lt;9463911a-ebcf-416a-9332-54282f3f3cba : 1.1.1.2 : 3306&gt;]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>面向对象</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[装饰器的进一步学习]]></title>
    <url>%2F2018%2F10%2F24%2F%E8%A3%85%E9%A5%B0%E5%99%A8%E7%9A%84%E8%BF%9B%E4%B8%80%E6%AD%A5%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[今天在调用被装饰器装饰的函数的时候实际调用函数返回的值和自己预想的不一样,经过朋友的指点发现问题在返回被装饰器装饰的函数的运行结果上. 12345678910111213141516def auth_login(func): def wrapper(*args, **kwargs): func(*args, **kwargs) return wrapper@auth_logindef paymoney(total): if total &gt; 0: return True else: return False if paymoney(10): print('数额充足')else: print('数额不足') 这个简单的装饰器应该很容易分析出结果,预想中的结果应该是打印:数额充足,然而结果却是什么都没打印,其实是因为装饰器有问题,因为并没有把被装饰的函数运行结果返回,那么装饰器的运行结果就为None,自然什么都不会打印. 正确的装饰器如下: 12345def auth_login(func): def wrapper(*args, **kwargs): res = func(*args, **kwargs) return res return wrapper]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>发现</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[类的三大特性之多态]]></title>
    <url>%2F2018%2F10%2F24%2F%E7%B1%BB%E7%9A%84%E4%B8%89%E5%A4%A7%E7%89%B9%E6%80%A7%E4%B9%8B%E5%A4%9A%E6%80%81%2F</url>
    <content type="text"><![CDATA[多态三问 什么是多态? 多态指的是同一种事物的多种形态,举个例子:每个人都会睡觉,但是每个人的睡觉姿势,睡眠质量都不一样,再说,每个人的祖宗都是猿类,但是现在几乎没有一模一样的两个人,有句话说世界上没有两片相同的叶子,这就是多态,这也是为什么这个世界多姿多彩,因为我们一样,我们也不一样. 为何要用多态? 我觉得不是用不用多态的问题,python的哲学是一切皆对象,那么对象其实可以想象成现实生活中的个体,这就自然而然有了多态的概念了,多个对象的某一个相同的方法,却有不一样的表现形式.那么在Python中怎么定义多态呢? 123456789101112131415import abcclass Animal(metaclass=abc.ABCMeta): @abc.abstractmethod def speak(self): pass # Animal() 父类不能实例化,因为父类本身就是用来制定标准的# speak方法被一个装饰装饰了,意味着只要是继承Animal类的子类都必须实现speak方法,强制实行的class People(Animal): def speak(self): pass #只有这样,才可以继承Animal类 python是一门自由度很高的语言,几乎没有什么强制要做的事情,这有好处也有坏处.好处是一门语言越自由那么开发者的创新性就越强,所以才有了越来越多的第三方库,使得python的生态环境愈发完善,像著名的requests库,唯一的一个非转基因的python HTTP库,人类可以安全享用.(扯远了…),越来越多的开发者使用python,开发新的特性和新的库,那么坏处就是python很自由,所以没有什么标准,你可以有你的标准,我可以有我的标准,按理说python是不禁止的,那么怎么解决这个问题呢? python的开发者都约定成俗的执行一些事情,比如常量全大写,函数名小写或者加下划线,类呢,就使用驼峰法命名,那么我们一看到变量名就可以知道这是个什么类型的变量了,同理,在python的类中,也约定成俗了用同样的名字改写自己的方法,查看基类object的源码可知: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110class object: """ The most base type """ def __delattr__(self, *args, **kwargs): # real signature unknown """ Implement delattr(self, name). """ pass def __dir__(self): # real signature unknown; restored from __doc__ """ __dir__() -&gt; list default dir() implementation """ return [] def __eq__(self, *args, **kwargs): # real signature unknown """ Return self==value. """ pass def __format__(self, *args, **kwargs): # real signature unknown """ default object formatter """ pass def __getattribute__(self, *args, **kwargs): # real signature unknown """ Return getattr(self, name). """ pass def __ge__(self, *args, **kwargs): # real signature unknown """ Return self&gt;=value. """ pass def __gt__(self, *args, **kwargs): # real signature unknown """ Return self&gt;value. """ pass def __hash__(self, *args, **kwargs): # real signature unknown """ Return hash(self). """ pass def __init_subclass__(self, *args, **kwargs): # real signature unknown """ This method is called when a class is subclassed. The default implementation does nothing. It may be overridden to extend subclasses. """ pass def __init__(self): # known special case of object.__init__ """ Initialize self. See help(type(self)) for accurate signature. """ pass def __le__(self, *args, **kwargs): # real signature unknown """ Return self&lt;=value. """ pass def __lt__(self, *args, **kwargs): # real signature unknown """ Return self&lt;value. """ pass @staticmethod # known case of __new__ def __new__(cls, *more): # known special case of object.__new__ """ Create and return a new object. See help(type) for accurate signature. """ pass def __ne__(self, *args, **kwargs): # real signature unknown """ Return self!=value. """ pass def __reduce_ex__(self, *args, **kwargs): # real signature unknown """ helper for pickle """ pass def __reduce__(self, *args, **kwargs): # real signature unknown """ helper for pickle """ pass def __repr__(self, *args, **kwargs): # real signature unknown """ Return repr(self). """ pass def __setattr__(self, *args, **kwargs): # real signature unknown """ Implement setattr(self, name, value). """ pass def __sizeof__(self): # real signature unknown; restored from __doc__ """ __sizeof__() -&gt; int size of object in memory, in bytes """ return 0 def __str__(self, *args, **kwargs): # real signature unknown """ Return str(self). """ pass @classmethod # known case def __subclasshook__(cls, subclass): # known special case of object.__subclasshook__ """ Abstract classes can override this to customize issubclass(). This is invoked early on by abc.ABCMeta.__subclasscheck__(). It should return True, False or NotImplemented. If it returns NotImplemented, the normal algorithm is used. Otherwise, it overrides the normal algorithm (and the outcome is cached). """ pass __class__ = None # (!) forward: type, real value is '' __dict__ = &#123;&#125; __doc__ = '' __module__ = '' 这里面的双下划线的方法,是基类已经定义好了的方法,那么继承基类的类,如果没有就用我的,如果有的话,你也用相同的名字,这样的话不管什么对象,都有同样的方法执行类似的事情,这就是多态,这也是python语言的魅力. 具体点来说,像linux的哲学是一切皆文件,那么通常来说文件只有两个属性,读和写,那么linux已经把各种复杂的方法封装为了读和写两个方法,那么就算我们不了解linux里面的某些硬件,我们也可以使用同样的方法来操作硬件.]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>面向对象</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[类的三大特性之封装]]></title>
    <url>%2F2018%2F10%2F24%2F%E7%B1%BB%E7%9A%84%E4%B8%89%E5%A4%A7%E7%89%B9%E6%80%A7%E4%B9%8B%E5%B0%81%E8%A3%85%2F</url>
    <content type="text"><![CDATA[封装三问 什么是封装? 装指的是把属性装进一个容器 封指的是隐藏的意思,但是这种隐藏是对外不对内的 为什么要封装? 封装不是单纯意义的隐藏; ​ 封装数据的目的:将数据属性封装起来,类外部的使用就无法直接操作该数据属性 ​ 想要在内部操作属性的话需要在类内部提供一个接口给使用者,类的设计者可以在接口之上附加任意逻辑,从而严格控制使用者对属性的操作 ​ 封装函数属性的目的:隔离复杂度 如何封装? 只需要在属性前加上__开头,该属性就会被隐藏起来,该隐藏具备的特点: 1. 只是一种语法意义上的变形,即__开头的属性会在检测语法时发生变形,变为\_类名\_\_属性名; 2. 这种隐藏是对外不对内的,因为在类内部检测语法时所有的代码统一都发生变形; 3. 这种变形只在检测语法时发生一次,在类定义之后新增的__开头的属性并不会发生变形; 4. 如果父类不想让子类覆盖自己的属性,可以在属性前加上__开头. 一 封装的意图一 封装数据属性的真实意图123456789101112131415161718192021222324252627282930313233343536# coding: utf-8# @Time : 2018/10/24 6:39 PM# @Author : MUSIBII# @Email : shaozuanzuan@gmail.com# @File : 封装数据属性的真实意图.pyclass People: def __init__(self, name, age): self.__name = name self.__age = age def tell_info(self): print('name: %s age:%s' % (self.__name, self.__age)) def set_info(self, new_name, new_age): if type(new_name) is not str: print('名字必须是str类型') return if type(new_age) is not int: print('年龄必须是int类型') return self.__name = new_name self.__age = new_age def clear_info(self): del self.__name del self.__ageobj = People('musibii', 18)obj.tell_info()obj.set_info('maffia', 23) 二 封装函数属性的真实意图123456789101112131415161718192021222324252627282930313233# coding: utf-8# @Time : 2018/10/24 6:53 PM# @Author : MUSIBII# @Email : shaozuanzuan@gmail.com# @File : 封装函数属性的真实意图.pyclass ATM: def __card(self): print('插卡') def __auth(self): print('用户认证') def __input(self): print('输入提取金额') def __print_bill(self): print('打印账单') def __take_money(self): print('取款') def withdraw(self): self.__card() self.__auth() self.__input() self.__print_bill() self.__take_money()a = ATM()a.withdraw() 我们自己设置的私有属性并不是不让用,而是为了减少复杂度以及保护数据,在类里面定义的私有属性应该怎么访问呢? 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647# coding: utf-8# @Time : 2018/10/24 6:39 PM# @Author : MUSIBII# @Email : shaozuanzuan@gmail.com# @File : 封装数据属性的真实意图.pyclass People: def __init__(self, name, age, x): self.__name = name self.__age = age self.x = x def tell_info(self): print('name: %s age:%s' % (self.__name, self.__age)) def set_info(self, new_name, new_age): if type(new_name) is not str: print('名字必须是str类型') return if type(new_age) is not int: print('年龄必须是int类型') return self.__name = new_name self.__age = new_age def clear_info(self): del self.__name del self.__ageobj = People('musibii', 18, 13)obj.tell_info()obj.set_info('maffia', 23)print(obj.x)print(obj.__dict__)print(obj._People__name)# 运行结果name: musibii age:1813&#123;'_People__name': 'maffia', '_People__age': 23, 'x': 13&#125;maffia 虽然通过直接访问没用,查看对象的名称空间可以看到,原本的__name变形为了_People__name,那么可以通过这个名字访问到对象中的私有属性,同理函数也是一样的方法访问. 这种变形需要注意的问题是: 这种机制并没有真正意义上限制我们从外部直接访问属性,知道了类名和属性名就可以拼出名字:_类名__属性,然后就可以访问了,如a._A__N,即这种操作并不是严格意义上的限制外部访问,仅仅只是一种语法意义上的变形,主要用来限制外部的直接访问; 变形过程只在类的定义时发生一次,在定义后的赋值操作,不会变形. 在继承中,父类如果不想让子类覆盖自己的方法,可以将方法定义为私有属性. 1234567891011121314151617181920212223242526272829303132# 子类继承父类的非私有属性class A: def fa(self): print('from A') def test(self): self.fa()class B(A): def fa(self): print('from B')b=B()b.test()# 运行结果from B# 子类和父类具有同名的私有属性,那么在父类调用私有属性的话就以父类的为准class A: def __fa(self): #在定义时就变形为_A__fa print('from A') def test(self): self.__fa() #只会与自己所在的类为准,即调用_A__faclass B(A): def __fa(self): print('from B')b = B()b.test()# 运行结果from A 二 封装不是单纯意义的隐藏封装的真谛在于明确的区分内外,封装的属性可以在内部直接使用,而不能被外部直接使用,然而定义的属性的目的终归是要使用的,外部要想用类隐藏的属性,需要内部提供接口,让外部能够间接地用到我们隐藏起来的属性,那这么做的意义何在? 封装数据: 将数据隐藏起来不是目的.隐藏起来然后对外提供操作该数据的接口,然后我们可以在接口附加上对该数据操作的限制,以此完成对数据属性操作的严格控制. 封装方法: 封装方法的目的是隔离复杂度,在编程语言里,对外提供的接口(接口可以理解为一个入口),可以是函数,成为接口函数,这与接口的概念不一样,接口代表一组接口函数的集合体. 了解 python并不会真的阻止你访问私有属性,模块也遵循这种约定,如果模块名以单下划线开头,那么from import 时不能被导入,但是你from module import _private_module依然可以导入. 三 特性属性什么是特性? property是一种特殊的属性,访问它时会执行一段功能(函数)然后返回值.类中可能会有某些函数运行后的值是特定的或者就单纯的计算出某种特定的值,那么这种情况下,可以把该函数变为特性. 为什么要用property? 将一个类的函数定义为特性后,对象再去使用的时候,可以是访问数据属性一样访问,就好像装饰器一样,其实你根本不知道外面做了什么操作,而property也是一个装饰器. 123456789101112131415161718class People: def __init__(self, name, weight, height): self.name = name self.weight = weight self.height = height # @property def bmi(self): return self.weight / (self.height ** 2) obj = People('musibii', 60, 1.73)obj.weight = 65print(obj.bmi())# 运行结果21.71806608974573# 把注释去掉后,调用方法bmi()就可以像访问属性一样进行访问了.print(obj.bmi) 另外一种方法也可以实现这种方法: 12345678910111213141516171819202122class People: def __init__(self, name): self.__name = name def yyy_name(self, new_name): if type(new_name) is not str: print('名字必须是str类型') return self.__name = new_name def zzz_name(self): del self.__name def xxx_name(self): return '&lt;name:%s&gt;' % self.__name name = property(xxx_name, yyy_name, zzz_name)obj = People('musibii')print(obj.name) 这种方法稍显奇怪,其实作用是一样的,但是这种方法有一个需要注意的地方,那就是property类的__init__方法的参数是位置参数,所以严格按照每个方法的位置传值.查看__init__源码可得: 想要对该方法操作的数据属性实现删除,修改,查看是和property装饰器结合起来使用的: 123456789101112131415161718192021222324252627class People: def __init__(self,name): self.__name=name @property def name(self): return '&lt;name:%s&gt;' %self.__name @name.setter def name(self,new_name): if type(new_name) is not str: print('名字必须是str类型') return self.__name=new_name @name.deleter def name(self): del self.__nameobj=People('musibii')print(obj.name)# obj.name=123# print(obj.name)del obj.nameprint(obj.__dict__) 这样才真正实现了在不改变操作数据形式的基础上修改了数据属性的值. 经过本篇博客可知:封装其实是更高层次的一个函数形式,我觉得类同理,开辟自己的名称空间,减少代码的耦合性,更一步说,操作数据就是操作内存中的数据,其实在内存中有什么函数,类和对象吗?以我现在的知识觉得应该没有,内存中就是一堆冷冰冰的数据,那么除了产生新的对象(可变不可变),其实内存中的值得内存地址都没有变,只是一一个指向引用关系,其实python中也有指针概念的,只是没有c那样需要自己维护罢了,python的变量名和变量名指向的对象的关系就是房子和门牌号的关系,有名字便于找到房子,那么没有名字的房子不像现实生活中还可以存在,没有名字对该房子的引用,那么python的内存管理机制就会把该房子摧毁以便建下一个房子. 在python中的类和该类产生的对象是如何保存的呢? 类以及类中的方法在内存中只有一份,而通过类创建的每一个对象都需要在内存中保存一份,那么对象保存的是什么呢?其实就只保存了房子的地址(也就是类对象指针),该值指向当前对象的类. 当通过对象执行方法时,过程如下: 根据当前对象中的类对象指针,找到类中的方法; 将对象当做参数传给方法的第一个参数(self),这个self就是高度封装的一个对象(和类的特性封装不一样),一个self骑士可以容纳万物,只要内存可以装得下. python的面向对象里面的封装思想太厉害了.]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>面向对象</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python的名称空间]]></title>
    <url>%2F2018%2F10%2F23%2Fpython%E7%9A%84%E5%91%BD%E5%90%8D%E7%A9%BA%E9%97%B4%2F</url>
    <content type="text"><![CDATA[最开始对名称空间的了解是在学习函数的时候,那时候知道了作用域的查找顺序,以及全局名称空间和局部名称空间,产生疑惑的时候为学递归的时候,那时候还没有名称空间这个概念,只知道递归有个最大深度,那时候以后递归产生的名称空间是一层套一层的,以及类里面的名称空间,所以产生了深究名称空间的想法,这才诞生了这篇博客,本篇博客借鉴了python的命名空间的内容,本人对里面的例子都试验了并发现了一个错误,在类中定义的列表生成式产生的命名空间也可以访问到类属性. 例子12345678910111213141516171819# a.pylis = ['musibii', 'thales']print('lis1', id(name))class A: def __init__(self): pass def func(self): global lis lis.append('maffia') print('lis', id(lis)) return lis print('lis2', lis)# b.pyfrom a import Aprint('b', A) 执行 b 文件的结果为: 123lis1 4421146632lis2 ['musibii', 'thales']b &lt;class 'a.A'&gt; 可以发现,虽然 b 只是导入了 a 中的 class A, 但导入这个过程执行了整个 a 文件,那么是否能够在 b 中访问 a 中的全局变量 lis 呢? 使用 from a import A 的形式只是把 A 产生的名称空间复制了一份到 b 产生的名称空间中. Python的一些基本概念对象在Python 中一切皆对象,那么对象到底代表什么呢?我的理解是在执行 py 文件时产生的一切变量都称为对象,如果把内存比作一座超大的房子的话,那么对象就是这座房子里的租客,那么这个租客随身携带的东西就是这个对象的一切了,对象都具有唯一的 id( 内存地址),类型( python3中统一了类和类型的概念),以及对象的值,对象一旦建立, id 便不会改变, id 就是对象在内存中的地址. 用常见的对象来类比一下这三个概念: 常量 123456789NAME = 'musibii'print(id(NAME))print(type(NAME))print(globals()) # 查看全局名称空间# 运行结果4374978776&lt;class 'str'&gt;&#123;'__name__': '__main__', '__doc__': None, '__package__': None, '__loader__': &lt;_frozen_importlib_external.SourceFileLoader object at 0x104c45fd0&gt;, '__spec__': None, '__annotations__': &#123;&#125;, '__builtins__': &lt;module 'builtins' (built-in)&gt;, '__file__': '/Users/jingxing/PycharmProjects/python全栈/作业/day27/duixiang.py', '__cached__': None, 'NAME': 'musibii'&#125; 出来的结果分别是 id,类型以及字典里面最后一个键值对对应的就是 NAME 的值. 函数 1234567891011121314151617def func(): name = 'musibii' def inner(): age = 18 print('age', age) inner() print(locals()) # 想要查看函数里面的值,必须在函数内部查看,因为函数执行完成会释放内存资源print(id(func))print(type(func))func()# 运行结果4529634840&lt;class 'function'&gt;age 18&#123;'inner': &lt;function func.&lt;locals&gt;.inner at 0x10e1cac80&gt;, 'name': 'musibii'&#125; id 和类型不必多说,函数对应的属性值里面不包括嵌套函数里面的属性(说明:名称空间是相互独立的) 类 123456789101112131415161718class Cls: school = 'hashangda' def __init__(self, name, age): self.name = name self.age = age def tell_info(self): print('%s : %s' % (self.name, self.age))print(id(Cls))print(type(Cls))print(Cla.__dict__)# 运行结果140390381504248&lt;class 'type'&gt;&#123;'__module__': '__main__', 'school': 'hashangda', '__init__': &lt;function Cls.__init__ at 0x10648eae8&gt;, 'tell_info': &lt;function Cls.tell_info at 0x10648ebf8&gt;, '__dict__': &lt;attribute '__dict__' of 'Cls' objects&gt;, '__weakref__': &lt;attribute '__weakref__' of 'Cls' objects&gt;, '__doc__': None&#125; 类的 id 为内存地址,类型为type类型,在 type 里面 type 就是类型的意思,所以说 python 里所有的类的类型都是类型,而类里面的属性就是类的值了. python 里面所有的对象都具有的并且根确定身份有关的值为 id, 类型和值了.名称不是对象的属性,名称只是指向对象,因为可以多个名称指向同一个对象. 标识符在对象里把变量名叫为名称其实是不准确的,这些名称都有一个共同的名字: identifier(和 id 是两个意思),中文名为’标识符’. 标识符:在 Python中,各类对象的名称,比如函数名,方法名,类名,变量名.常量名都称为标识符. 在 Python 中赋值并不会直接复制数据,而只是将名称绑定到对象,对象本身不需要知道和关心自己的标识符叫什么,一个对象甚至可以指向不同的标识符.真正管理这些标识符的事物是’名称空间’. 名称空间名称空间(NameSpace):名字(标识符)到对象的映射. 简单来说,名称空间可以理解为记录对象和对象名字对应关系的空间,在对象那里查看的对象的值就是名称空间,这是一个字典,一个命名空间就是名字到对象的映射,标识符是键,对象则是值. 作用域与名称空间相对的一个概念就是’作用域’,作用域本质是一块文本区域, Python 通过该文本区域可以直接访问相应的名称空间. Python 中不加 . 的访问为直接访问,反之为属性访问. 因此可以简单的将作用域理解为直接访问名称空间的一种实现,具体而言: 作用域内相应的名称空间可以被直接访问; 只有作用域内的名称空间才可以被直接访问(因此并不是所有的名称空间都可以被直接访问). LEGBLEGB 名称空间这四类名称空间可以简记为 LEGB: 局部名称空间( local): 指的是一个函数或者一个类所定义的名称空间:包括函数的参数,局部变量,类的属性等; 闭包名称空间(enclosing function):闭包函数的名称空间( python3引入); 全局名称空间( global):读入一个模块(也即一个. py 文件)后产生的名称空间; 内建名称空间(builtin):Python 解释器启动时自动载入__builtin__ 模块后形成的名称空间;像 str/list/dict… 等内置对象的名称就处于这里. 举例: 123456789# test.pyv1 = 'global var'def func(v1): v2 = 'local var' def inner(): v3 = v2 + v return v3 return inner 内建的反正每次都一样,在这里的三个名称空间里面的名称为: ‘v1’ 为全局变量 v1 的名字,其所处的名称空间为全局名称空间;需要注意的是全局名称空间包括 ‘func’ 但不包括 func 的参数和内部变量; func 包括 ‘v’, ‘v2’, 和 ‘inner’名称的局部名称空间; 执行 func 后, func 的作用域释放,并返回绑定了 v 和 v2变量的闭包函数 inner, 此时闭包函数的名称空间即为闭包名称空间,因此局部名称空间和闭包名称空间是相对而言的,对于父函数 func 而言,两者具有产生时间上的差异. LEGB 访问规则通过上面的例子,发现 LEGB 四类名称空间本身具有明显的内外层级概念,而这种层级概念正是构建作用域的前提:作用域依据这种层级概念将不同类型的名称空间组织起来并划归到不同层级的作用域,然后定义好不同层级作用域之间的访问规则,从而实现名称空间的直接访问. LEGB 的访问规则:**同样的标识符在各层名称空间可以被重复使用而不会发生冲突,但 Python 寻找一个标识符的过程总是从当前层开始逐层网上找,直到首次找到这个标识符为止. 123456789101112131415# main.pyv1 = 1v2 = 3def func(): v1 = 2 print(v1) print(v2) func()print(v1)# 运行结果231 全局变量和函数 func 都定义了变量 v1,在函数内部会优先选择自己局部名称空间内的变量 v1,对于 func 中未定义的变量 v2,Python 会向上查找全局名称空间,读取全局变量后打印输出. global 和 nonlocal 语句global 和 nonlocal 的作用对于上层名称空间里的变量, python 允许直接读取,但是不可以在内层作用域直接改写上层变量,在这方面很明显的区别就是在闭包函数里. 1234567891011# e.pygv = ['a', 'global', 'var']def func(v): gv = ['gv'] + gv lv = [] def inner(): lv = lv + [v] gv.insert(1, lv[0]) return return inner 实际调用 func 函数后,上面两处对 gv 和 lv 进行赋值的操作都会发生UnboundLocalError:因为 python 在执行函数前,会首先生成各层名称空间和作用域,因此 python 会在执行赋值前将 func 内的 gv 和 lv 写入局部名称空间和闭包名称空间,当 python 执行赋值语句的时候,会发现在局部作用域,闭包作用域内发现局部名称空间和闭包名称空间内已经具有 gv 和 lv 标识符,但是这两个非全局标识符在赋值语句执行之前并没有被赋值,也即没有对象与标识符关联,因此无法参与赋值运算,从而触发在引用之前未赋值的错误;但这段程序的本意是为了让全局变量 gv 和局部变量 lv 参与运算,为了避免类似的情况发生,Python 引入了global和nonlocal语句来说明局部名称空间和闭包名称空间使用的标识符分别来自全局名称空间和局部名称空间,声明之后就可以在 func 和 inner 名称空间里直接改写上层名称空间内的gv和lv的值了. 123456789101112131415# f.pygv = ['a', 'global', 'var']def func(v): global gv gv = ['gv'] + gv lv = [] print(id(lv)) def inner(): nonlocal lv lv = lv + [v] print(id(lv)) gv.insert(1, lv[0]) return return inner 这样就可以正常修改了.原博客说 lv 的 id 都是一样的,在 mac 上版本为3..6.6测试发现不是一样的. 1234# 运行结果44166001364416615624# 确实是使用了上层名称空间的变量,但是重新赋值后, gv 和上层的 gv 已经不是同一个了, lv 也一样,所以内存地址都发生变化了. 借壳那么不用 global 和nonlocal 可以达到上面的目的吗? 12345678910111213# g.pygv = ['a', 'global', 'var']def func(v): gv.insert(0, 'gv') lv = [] print(id(lv)) def inner(): lv.append(v) print(id(lv)) gv.insert(1, lv[0]) return gv return inner 看作者的这个解释为借壳,感觉很形象,这个原因应该用列表式可变类型来解释比较好, insert 和 append 的操作并没有对列表进行赋值操作,而是对列表这个容器里面的东西修改了并不是修改列表,我们都知道电脑内的内存永远都不会改变,他就是个超大的容器,用来装东西的,假如现在有个列表,它的容量和内存一样大,那么是不是好理解点,我们在和内存一样的列表里操作会改变这个列表吗?不会. 在 global 和 nonlocal 的作用就是把上层有的标识符和对象复制一份到下层名称空间 为什么在下层作用域可以使用读取上层作用域的值而不可以使用它的值呢? 这是因为 python 的两个概念不同的原因,作用域和名称空间的区别导致的.标识符的查找顺序是从当前层一层层向外查找的,这是根据作用域来查找的,那么名称空间呢?作用域和名称空间的在执行 py 文件就已经产生了,其实可以理解这是一个东西,其实里面保存的信息(除了某些可能有特殊含义的值不一样外)都一样,不一样的是作用于里面只保存了标识符,而名称空间里不仅保存了标识符还保存了标识符对应的对象.查找值的顺序是根据作用域来的,使用值就只能使用自己名称空间里的值,名称空间里保存的是标识符和标识符对应的对象,只有本层名称空间里有这个标识符和标识符对应的对象才可以使用(读,使用). 那么现在很明白为什么不能直接在下层名称空间直接使用上层名称空间里的名称了. global 和 nonlocal 语句对标识符创建的不同影响需要注意的是: global 语句只是声明该标识符引用的变量来自于全局变量,但并不能直接在当前层创建该标识符;nonlocal 语句则会在子函数名称空间创建与父函数变量同名的标识符. 123456789101112131415# j.pygv = ['a global var']def func(): global lv = 'a local var' print(locals()) def inner(): nonlocal lv global gv print(locals()) return inner# 运行结果&#123;'lv': 'a local var'&#125;&#123;'lv': 'a local var'&#125; 运行 func 函数后 global 语句并未将 ‘ gv ‘变量引入局部名称空间,执行闭包函数后,’ local’语句将父函数变量’lv’引入闭包名称空间. 之所以 nonlocal 和 global 语句的处置不同,在于全局变量的作用域生存期很长,在模块内随时都可以访问,而父类函数的局部作用域在父函数执行完毕后便会直接释放,因此 nonlocal 语句必须将父函数变量的标识符写入闭包名称空间. 名称空间的生命周期创建规则还有一个重要的问题没有解决:’标识符不是一开始就存在名称空间的,名称空间也不是平白无故产生的,那么名称空间是在什么时候被创建?又是什么时候被删除的呢?’ 名称空间产生顺序: 内建名称空间在 Python 解释器启动时创建,之后会一直存在; 模块的全局名称空间在模块定义时被读入创建,通常模块名称空间也会保持到解释器退出; 函数调用时产生新的局部名称空间,函数返回结果,抛出异常时释放名称空间,每一次递归都产生一个名称空间; 标识符产生地点决定标识符所处的名称空间. 类的名称空间首次,函数和类执行时都会产生局部名称空间,但类的执行机制不同于函数; 123456789101112131415# i.pydef a(): print('function')class A(): print(1) class B(): print(2) class C(): print(3) # 运行结果123 如上,类就是一个可执行的代码块,只要该类被加载,就会被执行,这一点不同于函数. 类之所以这样设计的原因在于:类是创建其他实例(声称其他的类或者具体的对象)的对象,因此必须在实例之前被创建,而类又可能涉及到与其他类的继承,重载等一系列问题,故在代码加载时就被创建利于提高效率和降低逻辑复杂度. 其次,与函数不同的是,类的局部名称空间并非作用于; 123456class A(): a = 1 b = [a + i for i in range(3)] # 运行结果NameError: name 'a' is not defined 执行上段代码,可以发现类 A 内列表推导式无法调取 a 的值,但函数可以. 123456def func(): a = 1 b = [a + i for i in range(3)] print(b)func() #[1, 2, 3] 因此, A 中的 a 不同于 func 中的 a 在局部名称空间可以被任意读取,之所以说是’不可以被任意’读取而不是’不可被读取’,原因在于在类 A 的局部名称空间内, a 其实在一定程度上可以被读取的: 123456class A(): a = 1 c = a + 2# 运行结果3 而上例中 b 的赋值操作不能被执行,原因在于列表推导式会创建自己的局部名称空间,因此难以访问到 a??????? 为什么访问不到 a??? 编译与局部名称空间Python 是动态语言,很多行为是动态发生的,但 Python 自身也在不断进步,比如为了提高效率,有些行为会在编译时候完成,局部变量的创建就是如此. 123456def func(): a = 1 def inner(): print(a) # error a = 2 # error inner() 上段程序还未执行,就提示存在语法错误,原因在于 Python 解释器发现 inner 内存在自身的 a 变量,但在声明之前就被 print 了. 总结1、为什么 b.py 只是导入 a.py 中的 class A,却执行了整个 a.py 文件?答：因为 Python 并不知道 class A 在 a.py 文档的何处，为了能够找到 class A，Python 需要执行整个文档。2、为什么 b.py 的导入执行了整个 a.py 文档，却在 b 中难以调用 a 的全局变量 va？答：Python 的全局变量指的是模块全局，因此不可以跨文档，因此 global 语句也是不可以跨文档的。另外， b 只是导入了 a 的 class A，因此并不会导入 a 中所有的标识符，所以 类似a.va 这样的调用也是不起作用的。 关于命名空间：1、赋值、定义类和函数都会产生新的标识符；2、全局变量的标识符不能跨文档；3、各级命名空间相互独立互不影响；4、Python 总是从当前层逐渐向上寻找标识符；5、内层作用域若想直接修改上层变量，需要通过 global nonlocal 语句先声明；6、单纯的 global 语句并不能为所在层级创建相应标识符，但 nonlocal 语句可以在闭包空间中创建相应标识符；7、类的局部命名空间不是作用域。]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>NameSpace</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[类的三大特性之继承]]></title>
    <url>%2F2018%2F10%2F23%2F%E7%B1%BB%E7%9A%84%E4%B8%89%E5%A4%A7%E7%89%B9%E6%80%A7%E4%B9%8B%E7%BB%A7%E6%89%BF%2F</url>
    <content type="text"><![CDATA[一 初识继承一 什么是继承?继承是一种创建新类的方式,新建的类可以继承一个或多个父类(python支持多继承),父类又可成为基类或超类,新建的类称为派生类或子类. 子类会继承父类的属性,从而解决代码重用问题. python中类的继承分为:单继承和多继承 1234567891011class Parent1: passclass Parent2: passclass Sub1(Parent1): # 单继承,基类是Parent1,派生类是Sub passclass Sub2(Parent1,Parent2): # 多继承,用逗号分隔开多个继承的类 pass 查看继承 1print(sub2.__bases__) # __base__只查看继承的第一个子类,__bases__则是查看所有继承的父类 经典类与新式类 只有在python2中才分新式类和经典类,python3统一都是新式类 在python2中,没有显式的继承object类的类,类与该类的子类,都是经典类 在python2中,显式的声明继承object的类,类与该类的子类,都是新式类 在python3中,无论是否继承object,都默认继承object,即python3中所有的类均为新式类 python3中如果没有指定基类,python的类会默认继承object类,object类是所有python类的基类,它内置了一些方法. 二 继承与抽象继承描述的是子类与父类的继承关系,想要找出这种关系,必须先抽象再继承. 抽象:即抽取类似或者相似的部分 继承:是基于抽象的结果,通过编程语言去实现它,肯定是先经历抽象这个过程,才能通过继承的方式去表达出抽象的结构 二 继承的使用场景三 继承与重用性在开发程序的过程中,如果我们首先定义了一个A类,然后又想新建一个B类,但是B类的大部分内容与A类代码相同时,可以通过继承的方法来实现代码重用. B继承A会获得A的所有属性(数据属性与函数属性),所以B中没有而A中具有的属性可以被B用来使用,而B中有的就使用自己的: 12345678910111213141516171819202122232425class A: a = 123 print(a) def func1(self): print('A, func1') def func2(self): print('A, func2') self.func1() class B(A): a = 134 def func1(self): print('B, func1') b = B()print(b.a)b.func2()# 运行结果123 # A为B的父类,在继承的时候会首先执行A类中的代码134A, func2B, func1 四 派生类虽然子类是继承了父类的的属性,但是子类也可以添加自己新的属性或者对子类生成的对象定义自己的属性(不会影响到父类),需要注意的是,一旦重新定义了自己的属性且与父类同名时,那么调用新的属性时以子类的为准. 123456789101112131415161718class A: a = 123 print(a) def func1(self): print('A, func1') def func2(self): print('A, func2') self.func1() class B(A): a = 134 def func1(self): print('B, func1') def func3(self): print('B, func3') B定义了自己新的属性func3,而且该函数和A类没有关系. 五 组合与重用性软件重用的重要方式除了继承之外还有另外一种方式,即:组合 组合指的是,在一个类中以另外一个类的对象作为数据属性,称为类的组合 12345678910111213class Equip: #武器装备类 def fire(self): print('release Fire skill') class Riven: #英雄Riven的类,一个英雄需要有装备,因而需要组合Equip类 camp='Noxus' def __init__(self,nickname): self.nickname=nickname self.equip=Equip() #用Equip类产生一个装备,赋值给实例的equip属性 r1=Riven('锐雯雯')r1.equip.fire() #可以使用组合的类产生的对象所持有的方法# 运行结果release Fire skill 组合与继承都是有效的利用已有类的资源的重要方式.但是二者的概念和使用场景皆不同. 继承的方式 通过继承建立了派生类和父类之间的关系,它是一种从属关系. 当类之间有很多相同的功能,提取这些共同的功能做成基类,用继承比较好 组合的方式 用组合的方式建立了类与组合的类之间的关系,它是一种附带关系. 六 抽象类 什么是抽象类? 与java一样,python也有抽象类的概念但是同样需要借助模块实现,抽象类是一个特殊的类,它的特殊之处在于只能被继承,不能被实例化. 为什么要有抽象类? 如果说类是从一堆对象中抽取相同的内容得来的,那么抽象类就是从一堆类中抽取相同的内容而来的,内容包括数据属性和函数属性. 从设计角度看,抽象类与普通类的不同之处在于:抽象类中只能抽象方法(没有实现功能),该类不能被实例化,只能被继承,且子类必须实现抽象方法. 三 继承实现的原理一 继承顺序在python中可以同时继承多个父类,如A(B,C,D) 如果继承关系为非菱形结构,则会按照先找B这一条分支,然后再找C这一条分支,最后找D这一条分支的顺序直到找到要找的属性,找完了还没有的话会报属性不存在的错误. 如果继承关系为菱形结构,那么属性的查找方式有两种,分别是:深度优先和广度优先. 12345678910111213141516171819202122232425262728293031class A(object): def test(self): print('from A')class B(A): def test(self): print('from B')class C(A): def test(self): print('from C')class D(B): def test(self): print('from D')class E(C): def test(self): print('from E')class F(D,E): # def test(self): # print('from F') passf1=F()f1.test()print(F.__mro__) #只有新式才有这个属性可以查看线性列表，经典类没有这个属性#新式类继承顺序:F-&gt;D-&gt;B-&gt;E-&gt;C-&gt;A#经典类继承顺序:F-&gt;D-&gt;B-&gt;A-&gt;E-&gt;C#python3中统一都是新式类#pyhon2中才分新式类与经典类 二 继承原理python是如何实现继承并查找属性的,对于你定义的每一个类,python会计算出一个方法解析顺序(MRO)列表,这个MRO列表就是一个简单的所有基类的线性顺序列表. 为了实现继承,python会在MRO列表中从左到右开始查找基类,直到找到第一个匹配这个属性的类为止.而这个MRO列表的构造是通过一个C3线性化算法来实现的.它实际上就是合并所有父类的MRO列表并遵循如下三条准则: 子类会先于父类被检查 多个父类会根据它们在列表中的顺序被检查 如果对下一个类存在两个合法的选择,选择第一个父类 查找属性时,即使没有直接继承关系,也会按照MRO列表继续往后查找,当使用super()函数时,python会在MRO列表上继续搜索下一个类.只要每个重定义的方法统一使用super()并只调用它一次,那么控制流最终会遍历完整个MRO列表,每个方法也只会被调用一次 注意:使用super调用的所有属性,都是从MRO列表当前的位置往后找,不要在意继承关系,看MRO列表就好 三 super的使用BaseTher类的创建 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455# coding: utf-8# @Time : 2018/10/23 11:40 PM# @Author : MUSIBII# @Email : shaozuanzuan@gmail.com# @File : father_type.pyimport os, sysimport pickleimport hashlibsys.path.append(os.path.dirname(os.path.dirname(__file__)))import db_file''' 11、抽象老师类与学生类得到父类，用继承的方式减少代码冗余'''import timeclass BaseTher: def __init__(self, name, age, gender): self.name = name self.age = age self.gender = gender self.time = time.time() # self.id_hash = self.create_id() # 创建唯一的id def create_id(self): # timenow = str(time.time()).split('.')[0] key = self.name + str(self.age) + self.gender + str(self.time) m = hashlib.md5(key.encode('utf-8')) self.id_hash = m.hexdigest() # print(m.hexdigest()) # return m.hexdigest() def tell_info(self): data = self.get_obj_by_id() for item in data: print('%-10s: %-20s' % (item, data[item])) # print(data) # 将信息序列化后保存到文件 def save(self): user_data = &#123;'name': self.name, 'age': self.age, 'gender': self.gender, 'id_hash': self.id_hash&#125; with open('db_file/%s' % self.id_hash, 'wb') as f: pickle.dump(user_data, f) # 通过id反序列化信息 def get_obj_by_id(self): with open('db_file/%s' % self.id_hash, 'rb') as f: return pickle.load(f) 子类通过super().init(*args)使用父类的init方法 1234567891011121314151617181920212223242526272829303132class Teacher(BaseTher): def __init__(self, name, age, gender, level, salary): super().__init__(name, age, gender) self.level = level self.salary = salary # self.id_hash = self.create_id() # 创建唯一的id def create_id(self): # timenow = str(time.time()).split('.')[0] key = self.name + str(self.age) + self.gender + str(self.level) + str(self.salary) m = hashlib.md5(key.encode('utf-8')) self.id_hash = m.hexdigest() # print(m.hexdigest()) # return m.hexdigest() # def tell_info(self): # data = self.get_obj_by_id() # for item in data: # print('%-10s: %-20s' % (item, data[item])) # # print(data) # 将老师信息序列化后保存到文件 def save(self): user_data = &#123;'name': self.name, 'age': self.age, 'gender': self.gender, 'level': self.level, 'salary': self.salary, 'id_hash': self.id_hash&#125; with open('db_file/%s'%self.id_hash, 'wb') as f: pickle.dump(user_data, f) # # 通过id反序列化老师信息 # def get_obj_by_id(self): # with open('db_file/%s'%self.id_hash, 'rb') as f: # return pickle.load(f) 在Python3中,super()括号里面可以为空,不过也可以写成super(本类的名字,self) 像上面的super().init(name, age, gender), 可以写成super(Teacher,self).init(name, age, gender) 四 组合的使用 什么是组合? 一个对象的属性是来自另外一个类的对象,称之为组合 为何用组合? 组合也是用来解决类与类代码冗余的问题 组合的用法如下代码: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051# coding: utf-8# @Time : 2018/10/24 10:27 AM# @Author : MUSIBII# @Email : shaozuanzuan@gmail.com# @File : zuhe.pyclass OldboyPeople: school = 'Oldboy' def __init__(self, name, age, gender): self.name = name self.age = age self.gender = genderclass OldboyStudent(OldboyPeople): def __init__(self, name, age, gender): super().__init__(name, age, gender) def choose_course(self): print('%s is choosing course' % self.name)class OldboyTeacher(OldboyPeople): def __init__(self, name, age, gender, level, salary): OldboyPeople.__init__(self, name, age, gender) self.level = level self.salary = salary def score(self, stu, num): stu.num = num print('老师%s给学生%s打分%s' % (self.name, stu.name, num))class Course: def __init__(self, course_name, course_price, course_period): self.course_name = course_name self.course_price = course_price self.course_period = course_period def tell_course(self): print('课程名:&lt;%s&gt; 价钱:[%s] 周期:[%s]' % (self.course_name, self.course_price, self.course_period))course = Course('python', 3000, '5months')stu1 = OldboyStudent('musibii', 18, 'male')stu1.course = courseprint(stu1)]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>面向对象</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python数据类型与类的总结]]></title>
    <url>%2F2018%2F10%2F23%2Fpython%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B%E4%B8%8E%E7%B1%BB%E7%9A%84%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>面向对象</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[面向对象编程]]></title>
    <url>%2F2018%2F10%2F22%2F%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E7%BC%96%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[一 面向对象编程与面向过程编程1 面向过程编程思想该思想核心是过程，指的是解决问题的步骤，即先干什么然后干什么，就像流水线一样，必须一步一步来，基于面向过程编程的是一种机械化的思维方式。 优点： 复杂问题流程化，简单化； 缺点：可扩展性较差。 应用场景：一旦完成几乎不会改变，像Linux内核、git以及Apache HTTP Server等 2 面向对象编程思想随着硬件的快速发展，业务需求越来越复杂，以及编程应用领域越来越广泛，面向过程编程已经不能满足需求了，于是另一种编程思想开始兴起，就是面向对象编程。 该思想核心是对象，对象是特征与技能的结合体，基于面向对象设计程序就好比自己是造物主一样，想要创造什么就创造什么，与面向过程机械式的思维方式形成鲜明对比，面向对象更加注重对现实世界的抽象化。 优点：解决了程序的扩展性。对某一个对象单独修改，会立刻反应到整个体系中。 缺点：1. 编程的复杂度高于面向过程编程，不了解面向对象而立即上手基于对象设计程序，容易出现过度设计的问题。一些扩展性要求低的场景使用面向对象会增加编程难度。 无法向面向过程的程序设计流水式的可以很精准的预测问题的处理流程与结果，面向对象的程序一旦开始就由对象之间的交互解决问题。 应用场景：需求经常变化的软件，一般需求的变化都集中在用户层，互联网应用，企业内部软件，游戏等 面向对象的程序设计并不是全部。对于一个软件质量来说，面向对象的程序设计只是用来解决扩展性。 一个好的应用软件应包括的特性： 二 类与对象一 类的定义类即类别、种类，是面向对象设计最重要的概念，对象是特征与技能的结合体，而类则是一系列具有相似特征与技能的抽象概念。 在现实中是先出现对象，然后根据一系列具有相同特征的对象定义不同的类，对象是具体的存在，而类仅仅只是一个概念，并不真实存在。 在程序中是先定义类，然后根据类产生对象，这与函数的使用是类似的，先定义函数，类同理，在程序中需要先定义类，后调用类，与函数不一样的是，调用函数会执行函数体代码返回的是函数的执行结果，而调用类会产生并返回一个对象。 在程序中，务必保证，先定义类，后使用对象。 在程序中特征使用变量标识，技能使用函数标识。 因而类中最常见的是：变量和函数的定义。 1234567891011# 定义一个类class something: school = 'hashangda' def learn(self): print('something is learning') def eat(self): print('something is eating') def sleep(self): print('something is sleeping') 注意: 类中可以为任意python代码,这些代码在类定义阶段便会执行; 因而会产生新的名称空间,用来存放类的变量名与函数名,可以通过something.dict查看; 对于经典类来说可以通过该字典操作类名称空间的名字(新式类有限制),但python为我们提供了专门的语法进行访问; 点事访问属性的语法,类中定义的名字,都是类的属性(变量和函数). 二 程序中类的用法在程序中用.来访问类的属性,本质操作为dict 1234something.school # 等于经典类 something.__dict__['school']something.school = 'oldboy' # 等于经典类 something.__dict__['school'] = 'oldboy'something.name = 'musibii' # 等于经典类 something.__dict__['name'] = 'musibii'del something.name # 等于经典类 something.__dict__.pop('name') 在程序中调用类(实例化对象),产生并返回一个对象,产生的对象会具有类里面的属性,并且可以通过句点法进行访问. 总结: 类本质是一个名称空间,或者说是一个用来存放变量与函数的容器; 类的用途之一就是当做名称空间从其内部取出名字来使用; 类的主要用途是调用类产生对象. 三 对象的使用通过调用类产生的对象成为类的实例化,调用类的返回值称之为类的一个对象/实例. 123some = something() # 产生一个实例对象,对象可以通过句点法访问类中的属性()print(some.school)# 结果 hashangda 类中定义的属性是由该类产生的所有对象共有的属性,那么每个对象自己特有的属性应该怎么定义的? 1234567class something: school = 'hashangda' def __init__(self, name, age, gender): self.name = name self.age = age self.gender = gender 类中的init方法是用来初始化一个实例对象的,并且会执行下面的代码,所以这时候要实例化对象是需要传入后面的参数. 123some1 = something('musibii', 18, 'male')some2 = something('thales', 20, 'female')some3 = something('maffia', 22, 'male') 这样实例化出来的对象除了school属性值一样,其他都是自己独有的属性值. 调用类产生了 先产生一个空对象some1,然后返回; 触发类中函数init的执行,将对象联通调用类括号内指定的参数一同传入init. 总结:init的功能,在实例化时为对象初始化自己独有的特征(不能有返回值) 四 属性查找属性查找和之前学的名称空间查找顺序逻辑一样,首先在对象的名称空间里面查找,没有的话去类名称空间查找,但是不会去全局名称空间查找对象的属性. 类中定义的变量是所有对象共享的,对象可以使用,类也可以使用,类一旦改变自己的属性的值,所有的对象也会随之改变. 五 绑定方法类中定义的变量是类的数据属性,类和对象都可以使用,并且属性的值都指向一个内存地址; 类中定义的函数是类的函数属性,类和对象都可以调用,类来调用的就是一个普通的函数,但类中定义的函数都是用来给对象用的,而且是绑定给对象的. 类的函数:该传几个参数就传几个 绑定方法,指向类的函数:特殊之处是绑定给哪个对象就应该由哪个对象来调用,调用的时候就会把对象本身当做第一个参数自动传入. 六 一切皆对象在python3中统一了类和类型的概念,就是说一个类等于一种类型,比如python中的数据类型,我们也可以定义属于自己的类 12345class muSibii: passmusibii = muSibii()print(type(musibii))# 结果 &lt;class '__main__.muSibii'&gt;]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>面向对象</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一首沉下来特别好听的歌]]></title>
    <url>%2F2018%2F10%2F19%2F%E4%B8%80%E9%A6%96%E6%B2%89%E4%B8%8B%E6%9D%A5%E7%89%B9%E5%88%AB%E5%A5%BD%E5%90%AC%E7%9A%84%E6%AD%8C%2F</url>
    <content type="text"><![CDATA[最近一直在单曲循环 腰乐队的《一个短篇》 《一个短篇》 作词：刘弢 作曲：杨绍昆 旋转 跳跃喔 他感到每条路都在头痛 新鲜的帕特里克满脑子 都是开拓的自慰器 那些男人爱的男人爱市政 市政爱市民 市民爱流连 旋转 跳跃喔 他感到飞鸟们也在头痛 冒牌的帕特里克满脑子 都是稳妥的独角戏 那些男孩爱的男人爱机器 机器爱法律 法律是你 深夜里辛蒂蕾拉们倒下的地方 促成整片血红的高楼 在搞与不搞之间泛起淡淡的哀伤 他的来头已经腐朽 别担心没有哪一首歌能够 把这个现实唱到地狱去 当你还能享有这种静默我的老爷 这烂摊就不会收场 旋转 跳跃吧 他感到连晚风也在头痛 狗娘养的帕特里克满脑子 关于体态的滑翔机 他说过那些女人爱的男人爱萝莉 萝莉爱包包 包包爱货币 他在高级堡垒的方针里走出 带来大会的消息 在幼犬和地皮商的征程里 他是发达的肯定句 等他和他们 他们和所有人之间 都搞不来信任的时候 只要冬和她的姨妈 从没有熄灯的窗口 无声眺望 这夜派对 就要散场 这夜派对 就要散场 这夜派对 就要散场 这夜派对 就要散场 幽暗的最高频道还在 为全城遮盖下一百年的昂贵谜底 他倚靠在令人害羞的礼品堆里 冉冉睡去 幽暗的最高频道还在 为全城遮盖下一百年的昂贵谜底 他依靠在令人害羞的礼品堆里 冉冉睡去 幽暗的最高频道还在 为全城遮盖下一百年的昂贵谜底 他依靠在令人害羞的礼品堆里 冉冉睡去]]></content>
      <categories>
        <category>Music</category>
      </categories>
      <tags>
        <tag>呐喊</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[计算机硬件基础]]></title>
    <url>%2F2018%2F10%2F19%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A1%AC%E4%BB%B6%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[一 计算机基本组成目前市面上的计算机几乎都是冯诺依曼体系计算机，冯·诺依曼计算机使用冯诺依曼体系机构的电子数字计算机。1945年6月，冯·诺依曼提出了在数字计算机内部的存储器中存放程序的概念，这是所有现代电子计算机的末班，被称为“冯·诺依曼结构”，按照这种结构构造的电脑称为存储程序计算机，又称为通用计算机。 冯·诺依曼体系的计算机的特点是：程序以二进制代码的形式存放在存储器中；所有的指令都是由操作码和地址码组成；指令在其存储过程中按照执行的顺序进行存储；以运算器和控制器作为计算机结构的中心等。冯诺依曼计算机广泛应用于数据的处理和控制方面。 冯诺依曼理论的要点是：数字计算机的数制采用二进制；计算机应该按照程序顺序执行。 根据冯诺依曼体系结构组成的计算机，必须具有如下功能： 把需要的程序和数据送至计算机中。 必须具有长期记忆程序、数据、中间结果及最终运算结果的能力。 能够完成各种算术、逻辑运算和数据传送等数据加工处理的能力。 能够根据需要控制程序走向，并能根据指令控制机器的各部件协调操作。 能够按照要求将处理结果输出给用户。 为了完成以上功能，计算机必须具备以下五大基本组成部件： 控制器：计算机的指挥系统。控制器通过数据地址来访问存储器，从存储器中取出指令，经过编译器编译或解释器解释后，根据结果得出相应的操作信号并作用于其他部件，使得各部件在控制器的严格控制下互相协调的工作。 运算器：实现算术运算和逻辑运算的部件。 存储器：计算机用来存储所有数据和程序的记忆部件。它的基本功能是按照指定的存储地址存（写）入或取（读）出数据。 输入设备：是向计算机中输入信息（程序、数据、声音、文字、图形、图像等）的设备。常见的输入设备有：键盘、鼠标、图形扫描仪、触摸屏等。 输出设备：主要有显示器、打印机和绘图仪等。 现代计算机将上述五大部分分为三大核心部件： CPU（控制单元+算数逻辑单元） 主存储器 输入输出设备 这几个部件的相关性如下： 二 编程与计算机硬件的关系为了使计算机能够理解人的意图，人类就必须将需要解决的问题的思路、方法和手段通过计算机能够理解的形式告诉计算机，使得计算机能够根据人的指令一步一步去工作，完成某种特定的任务。这种人与计算机体系之间交流的过程就是编程。 编写的程序经过译码器分析后得到的是一大堆的二进制指令，这些指令通过CPU读取从而产生相应的操作控制信号作用于其他的硬件上，从而完成相应的功能。 三 内存容量单位的换算1Byte=8bit 1KB=1024Bytes 1MB=1024KB 1GB=1024MB 有的生产厂家的换算单位为1000。 四 CPU位数关系现在市面上的计算机主要分为32位和64位两种规格，他们之间的区别主要为以下四点： 处理数据能力不同 支持的内存不同（寻址不同） 架构不同 对配置的要求不同 五 操作系统基础 操作系统是什么？ 操作系统（Operating System，简称OS）是管理和控制计算机硬件与软件资源的计算机程序，是直接运行在‘裸机’上的最基本的系统软件，任何其他软件都必须在操作系统的支持下才能运行。操作系统是一个协调\管理\控制计算机硬件资源与软件资源的一个控制程序。 为什么要有操作系统？ 操作系统是用户和计算机硬件的接口，同时也是计算机硬件和其他软件的接口。操作系统的功能包括管理计算机系统的硬件、软件及数据资源，控制程序运行，改善人机界面，为其他应用软件提供支持，让计算机系统所有资源最大限度的发挥作用，提供各种形式的用户界面，使用户有一个好的工作环境，为其他软件的开发提供必要的服务和相应的接口等。实际上，用户是不用接触操作系统的，操作系统管理着计算机的硬件资源，同时按照应用程序的资源请求来分配资源，如：划分CPU时间、内存空间的开辟、调用打印机等。 操作系统就是为了让使用者更加方便的使用计算机硬件资源和软件资源的一个工具。]]></content>
      <categories>
        <category>Computer Basics</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[python模块之re]]></title>
    <url>%2F2018%2F10%2F19%2Fpython%E6%A8%A1%E5%9D%97%E4%B9%8Bre%2F</url>
    <content type="text"><![CDATA[re 模块在 Python 中，我们可以使用内置的 re 模块来使用正则表达式。 有一点需要特别注意的是，正则表达式使用 \ 对特殊字符进行转义，比如，为了匹配字符串 ‘python.org’，我们需要使用正则表达式 &#39;python\.org&#39;，而 Python 的字符串本身也用 \ 转义，所以上面的正则表达式在 Python 中应该写成 &#39;python\\.org&#39;，这会很容易陷入 \ 的困扰中，因此，我们建议使用 Python 的原始字符串，只需加一个 r 前缀，上面的正则表达式可以写成： 1r&apos;python\.org&apos; re 模块提供了不少有用的函数，用以匹配字符串，比如： compile 函数 match 函数 search 函数 findall 函数 finditer 函数 split 函数 sub 函数 subn 函数 re 模块的一般使用步骤如下： 使用 compile 函数将正则表达式的字符串形式编译为一个 Pattern 对象 通过 Pattern 对象提供的一系列方法对文本进行匹配查找，获得匹配结果（一个 Match 对象） 最后使用 Match 对象提供的属性和方法获得信息，根据需要进行其他的操作 compile 函数compile 函数用于编译正则表达式，生成一个 Pattern 对象，它的一般使用形式如下： 1re.compile(pattern[, flag]) 其中，pattern 是一个字符串形式的正则表达式，flag 是一个可选参数，表示匹配模式，比如忽略大小写，多行模式等。 下面，让我们看看例子。 1234import re# 将正则表达式编译成 Pattern 对象 pattern = re.compile(r'\d+') 在上面，我们已将一个正则表达式编译成 Pattern 对象，接下来，我们就可以利用 pattern 的一系列方法对文本进行匹配查找了。Pattern 对象的一些常用方法主要有： match 方法 search 方法 findall 方法 finditer 方法 split 方法 sub 方法 subn 方法 match 方法match 方法用于查找字符串的头部（也可以指定起始位置），它是一次匹配，只要找到了一个匹配的结果就返回，而不是查找所有匹配的结果。它的一般使用形式如下： 1match(string[, pos[, endpos]]) 其中，string 是待匹配的字符串，pos 和 endpos 是可选参数，指定字符串的起始和终点位置，默认值分别是 0 和 len (字符串长度)。因此，当你不指定 pos 和 endpos 时，match 方法默认匹配字符串的头部。 当匹配成功时，返回一个 Match 对象，如果没有匹配上，则返回 None。 看看例子。 12345678910111213141516171819&gt;&gt;&gt; import re&gt;&gt;&gt; pattern = re.compile(r'\d+') # 用于匹配至少一个数字&gt;&gt;&gt; m = pattern.match('one12twothree34four') # 查找头部，没有匹配&gt;&gt;&gt; print mNone&gt;&gt;&gt; m = pattern.match('one12twothree34four', 2, 10) # 从'e'的位置开始匹配，没有匹配&gt;&gt;&gt; print mNone&gt;&gt;&gt; m = pattern.match('one12twothree34four', 3, 10) # 从'1'的位置开始匹配，正好匹配&gt;&gt;&gt; print m # 返回一个 Match 对象&lt;_sre.SRE_Match object at 0x10a42aac0&gt;&gt;&gt;&gt; m.group(0) # 可省略 0'12'&gt;&gt;&gt; m.start(0) # 可省略 03&gt;&gt;&gt; m.end(0) # 可省略 05&gt;&gt;&gt; m.span(0) # 可省略 0(3, 5) 在上面，当匹配成功时返回一个 Match 对象，其中： group([group1, …]) 方法用于获得一个或多个分组匹配的字符串，当要获得整个匹配的子串时，可直接使用 group() 或 group(0)； start([group]) 方法用于获取分组匹配的子串在整个字符串中的起始位置（子串第一个字符的索引），参数默认值为 0； end([group]) 方法用于获取分组匹配的子串在整个字符串中的结束位置（子串最后一个字符的索引+1），参数默认值为 0； span([group]) 方法返回 (start(group), end(group))。 再看看一个例子： 1234567891011121314151617181920212223&gt;&gt;&gt; import re&gt;&gt;&gt; pattern = re.compile(r'([a-z]+) ([a-z]+)', re.I) # re.I 表示忽略大小写&gt;&gt;&gt; m = pattern.match('Hello World Wide Web')&gt;&gt;&gt; print m # 匹配成功，返回一个 Match 对象&lt;_sre.SRE_Match object at 0x10bea83e8&gt;&gt;&gt;&gt; m.group(0) # 返回匹配成功的整个子串'Hello World'&gt;&gt;&gt; m.span(0) # 返回匹配成功的整个子串的索引(0, 11)&gt;&gt;&gt; m.group(1) # 返回第一个分组匹配成功的子串'Hello'&gt;&gt;&gt; m.span(1) # 返回第一个分组匹配成功的子串的索引(0, 5)&gt;&gt;&gt; m.group(2) # 返回第二个分组匹配成功的子串'World'&gt;&gt;&gt; m.span(2) # 返回第二个分组匹配成功的子串(6, 11)&gt;&gt;&gt; m.groups() # 等价于 (m.group(1), m.group(2), ...)('Hello', 'World')&gt;&gt;&gt; m.group(3) # 不存在第三个分组Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt;IndexError: no such group search 方法search 方法用于查找字符串的任何位置，它也是一次匹配，只要找到了一个匹配的结果就返回，而不是查找所有匹配的结果，它的一般使用形式如下： 1search(string[, pos[, endpos]]) 其中，string 是待匹配的字符串，pos 和 endpos 是可选参数，指定字符串的起始和终点位置，默认值分别是 0 和 len (字符串长度)。 当匹配成功时，返回一个 Match 对象，如果没有匹配上，则返回 None。 让我们看看例子： 1234567891011121314&gt;&gt;&gt; import re&gt;&gt;&gt; pattern = re.compile('\d+')&gt;&gt;&gt; m = pattern.search('one12twothree34four') # 这里如果使用 match 方法则不匹配&gt;&gt;&gt; m&lt;_sre.SRE_Match object at 0x10cc03ac0&gt;&gt;&gt;&gt; m.group()'12'&gt;&gt;&gt; m = pattern.search('one12twothree34four', 10, 30) # 指定字符串区间&gt;&gt;&gt; m&lt;_sre.SRE_Match object at 0x10cc03b28&gt;&gt;&gt;&gt; m.group()'34'&gt;&gt;&gt; m.span()(13, 15) 再来看一个例子： 123456789101112131415# -*- coding: utf-8 -*-import re# 将正则表达式编译成 Pattern 对象pattern = re.compile(r'\d+') # 使用 search() 查找匹配的子串，不存在匹配的子串时将返回 None # 这里使用 match() 无法成功匹配 m = pattern.search('hello 123456 789') if m: # 使用 Match 获得分组信息 print 'matching string:',m.group() print 'position:',m.span() 执行结果： 12matching string: 123456position: (6, 12) findall 方法上面的 match 和 search 方法都是一次匹配，只要找到了一个匹配的结果就返回。然而，在大多数时候，我们需要搜索整个字符串，获得所有匹配的结果。 findall 方法的使用形式如下： 1findall(string[, pos[, endpos]]) 其中，string 是待匹配的字符串，pos 和 endpos 是可选参数，指定字符串的起始和终点位置，默认值分别是 0 和 len (字符串长度)。 findall 以列表形式返回全部能匹配的子串，如果没有匹配，则返回一个空列表。 看看例子： 12345678import repattern = re.compile(r'\d+') # 查找数字result1 = pattern.findall('hello 123456 789')result2 = pattern.findall('one1two2three3four4', 0, 10)print result1print result2 执行结果： 12[&apos;123456&apos;, &apos;789&apos;][&apos;1&apos;, &apos;2&apos;] finditer 方法finditer 方法的行为跟 findall 的行为类似，也是搜索整个字符串，获得所有匹配的结果。但它返回一个顺序访问每一个匹配结果（Match 对象）的迭代器。 看看例子： 12345678910111213141516171819# -*- coding: utf-8 -*-import repattern = re.compile(r'\d+')result_iter1 = pattern.finditer('hello 123456 789')result_iter2 = pattern.finditer('one1two2three3four4', 0, 10)print type(result_iter1)print type(result_iter2)print 'result1...'for m1 in result_iter1: # m1 是 Match 对象 print 'matching string: &#123;&#125;, position: &#123;&#125;'.format(m1.group(), m1.span())print 'result2...'for m2 in result_iter2: print 'matching string: &#123;&#125;, position: &#123;&#125;'.format(m2.group(), m2.span()) 执行结果： 12345678&lt;type &apos;callable-iterator&apos;&gt;&lt;type &apos;callable-iterator&apos;&gt;result1...matching string: 123456, position: (6, 12)matching string: 789, position: (13, 16)result2...matching string: 1, position: (3, 4)matching string: 2, position: (7, 8) split 方法split 方法按照能够匹配的子串将字符串分割后返回列表，它的使用形式如下： 1split(string[, maxsplit]) 其中，maxsplit 用于指定最大分割次数，不指定将全部分割。 看看例子： 1234import rep = re.compile(r'[\s\,\;]+')print p.split('a,b;; c d') 执行结果： 1[&apos;a&apos;, &apos;b&apos;, &apos;c&apos;, &apos;d&apos;] sub 方法sub 方法用于替换。它的使用形式如下： 1sub(repl, string[, count]) 其中，repl 可以是字符串也可以是一个函数： 如果 repl 是字符串，则会使用 repl 去替换字符串每一个匹配的子串，并返回替换后的字符串，另外，repl 还可以使用 \id 的形式来引用分组，但不能使用编号 0； 如果 repl 是函数，这个方法应当只接受一个参数（Match 对象），并返回一个字符串用于替换（返回的字符串中不能再引用分组）。 count 用于指定最多替换次数，不指定时全部替换。 看看例子： 123456789101112import rep = re.compile(r'(\w+) (\w+)')s = 'hello 123, hello 456'def func(m): return 'hi' + ' ' + m.group(2)print p.sub(r'hello world', s) # 使用 'hello world' 替换 'hello 123' 和 'hello 456'print p.sub(r'\2 \1', s) # 引用分组print p.sub(func, s)print p.sub(func, s, 1) # 最多替换一次 执行结果： 1234hello world, hello world123 hello, 456 hellohi 123, hi 456hi 123, hello 456 subn 方法subn 方法跟 sub 方法的行为类似，也用于替换。它的使用形式如下： 1subn(repl, string[, count]) 它返回一个元组： 1(sub(repl, string[, count]), 替换次数) 元组有两个元素，第一个元素是使用 sub 方法的结果，第二个元素返回原字符串被替换的次数。 看看例子： 123456789101112import rep = re.compile(r&apos;(\w+) (\w+)&apos;)s = &apos;hello 123, hello 456&apos;def func(m): return &apos;hi&apos; + &apos; &apos; + m.group(2)print p.subn(r&apos;hello world&apos;, s)print p.subn(r&apos;\2 \1&apos;, s)print p.subn(func, s)print p.subn(func, s, 1) 执行结果： 1234(&apos;hello world, hello world&apos;, 2)(&apos;123 hello, 456 hello&apos;, 2)(&apos;hi 123, hi 456&apos;, 2)(&apos;hi 123, hello 456&apos;, 1) 其他函数事实上，使用 compile 函数生成的 Pattern 对象的一系列方法跟 re 模块的多数函数是对应的，但在使用上有细微差别。 match 函数match 函数的使用形式如下： 1re.match(pattern, string[, flags]): 其中，pattern 是正则表达式的字符串形式，比如 \d+, [a-z]+。 而 Pattern 对象的 match 方法使用形式是： 1match(string[, pos[, endpos]]) 可以看到，match 函数不能指定字符串的区间，它只能搜索头部，看看例子： 12345678910111213import rem1 = re.match(r'\d+', 'One12twothree34four')if m1: print 'matching string:',m1.group()else: print 'm1 is:',m1m2 = re.match(r'\d+', '12twothree34four')if m2: print 'matching string:', m2.group()else: print 'm2 is:',m2 执行结果： 12m1 is: Nonematching string: 12 search 函数search 函数的使用形式如下： 1re.search(pattern, string[, flags]) search 函数不能指定字符串的搜索区间，用法跟 Pattern 对象的 search 方法类似。 findall 函数findall 函数的使用形式如下： 1re.findall(pattern, string[, flags]) findall 函数不能指定字符串的搜索区间，用法跟 Pattern 对象的 findall 方法类似。 看看例子： 123456import reprint re.findall(r'\d+', 'hello 12345 789')# 输出['12345', '789'] finditer 函数finditer 函数的使用方法跟 Pattern 的 finditer 方法类似，形式如下： 1re.finditer(pattern, string[, flags]) split 函数split 函数的使用形式如下： 1re.split(pattern, string[, maxsplit]) sub 函数sub 函数的使用形式如下： 1re.sub(pattern, repl, string[, count]) subn 函数subn 函数的使用形式如下： 1re.subn(pattern, repl, string[, count]) 到底用哪种方式从上文可以看到，使用 re 模块有两种方式： 使用 re.compile 函数生成一个 Pattern 对象，然后使用 Pattern 对象的一系列方法对文本进行匹配查找； 直接使用 re.match, re.search 和 re.findall 等函数直接对文本匹配查找； 下面，我们用一个例子展示这两种方法。 先看第 1 种用法： 12345678import re# 将正则表达式先编译成 Pattern 对象pattern = re.compile(r'\d+')print pattern.match('123, 123')print pattern.search('234, 234')print pattern.findall('345, 345') 再看第 2 种用法： 12345import reprint re.match(r'\d+', '123, 123')print re.search(r'\d+', '234, 234')print re.findall(r'\d+', '345, 345') 如果一个正则表达式需要用到多次（比如上面的 \d+），在多种场合经常需要被用到，出于效率的考虑，我们应该预先编译该正则表达式，生成一个 Pattern 对象，再使用该对象的一系列方法对需要匹配的文件进行匹配；而如果直接使用 re.match, re.search 等函数，每次传入一个正则表达式，它都会被编译一次，效率就会大打折扣。 因此，我们推荐使用第 1 种用法。 匹配中文在某些情况下，我们想匹配文本中的汉字，有一点需要注意的是，中文的 unicode 编码范围 主要在 [\u4e00-\u9fa5]，这里说主要是因为这个范围并不完整，比如没有包括全角（中文）标点，不过，在大部分情况下，应该是够用的。 假设现在想把字符串 title = u&#39;你好，hello，世界&#39; 中的中文提取出来，可以这么做： 123456789# -*- coding: utf-8 -*-import retitle = u'你好，hello，世界'pattern = re.compile(ur'[\u4e00-\u9fa5]+')result = pattern.findall(title)print result 注意到，我们在正则表达式前面加上了两个前缀 ur，其中 r 表示使用原始字符串，u 表示是 unicode 字符串。 执行结果: 1[u&apos;\u4f60\u597d&apos;, u&apos;\u4e16\u754c&apos;] 贪婪匹配在 Python 中，正则匹配默认是贪婪匹配（在少数语言中可能是非贪婪），也就是匹配尽可能多的字符。 比如，我们想找出字符串中的所有 div 块： 1234567import recontent = 'aa&lt;div&gt;test1&lt;/div&gt;bb&lt;div&gt;test2&lt;/div&gt;cc'pattern = re.compile(r'&lt;div&gt;.*&lt;/div&gt;')result = pattern.findall(content)print result 执行结果： 1[&apos;&lt;div&gt;test1&lt;/div&gt;bb&lt;div&gt;test2&lt;/div&gt;&apos;] 由于正则匹配是贪婪匹配，也就是尽可能多的匹配，因此，在成功匹配到第一个 &lt;/div&gt; 时，它还会向右尝试匹配，查看是否还有更长的可以成功匹配的子串。 如果我们想非贪婪匹配，可以加一个 ?，如下： 1234567import recontent = 'aa&lt;div&gt;test1&lt;/div&gt;bb&lt;div&gt;test2&lt;/div&gt;cc'pattern = re.compile(r'&lt;div&gt;.*?&lt;/div&gt;') # 加上 ?result = pattern.findall(content)print result 结果： 1[&apos;&lt;div&gt;test1&lt;/div&gt;&apos;, &apos;&lt;div&gt;test2&lt;/div&gt;&apos;] 小结 re 模块的一般使用步骤如下： 使用 compile 函数将正则表达式的字符串形式编译为一个 Pattern 对象； 通过 Pattern 对象提供的一系列方法对文本进行匹配查找，获得匹配结果（一个 Match 对象）； 最后使用 Match 对象提供的属性和方法获得信息，根据需要进行其他的操作； Python 的正则匹配默认是贪婪匹配。 参考资料 re模块]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>模块</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python模块之hashlib]]></title>
    <url>%2F2018%2F10%2F19%2Fpython%E6%A8%A1%E5%9D%97%E4%B9%8Bhashlib%2F</url>
    <content type="text"><![CDATA[一 什么是hashlib模块？hashlib模块是python用来加密的一个模块，hash是一种算法，可以提供SHA1、SHA224、SHA256、SHA384、SHA512、MD%算法，该算法接收传入的内容，经过运算得到一串hash值。 hash是一种算法，是将一个任意长度的数据，根据计算，得到一个固定长度的hash值。 经过hash算法会得到一串hash值，hash值得特点如下： 只要传入的内容一样，得到的hash值必然一样 —》》要用明文传输密码文件完整性校验 按理来说不能有hash值返解回原内容，但是破解md5使用撞库原理也变得不安全起来 只要使用的hash算法不变，无论校验的内容有多大，得到的hash值长度是固定的 hash算法就像一座工厂，工厂接收你送来的原材料，（可以使用m.update()为工厂增加材料），经过加工返回的产品就是hash值。 二 使用场景 密码验证 校验数据包 提升密码的复杂度 三 hashlib模块的使用 md5使用 123import hashlibm = hashlib.md5('musibii'.encode('utf-8'))print(m.hexdigest()) 12# 运行结果02797a3eebd7ef3054cd5c0e3a8c3199 其他几种加密 12345678910import hashlibh1 = hashlib.sha512("musibii".encode("utf-8"))h2 = hashlib.sha3_512("musibii".encode("utf-8"))# print(len(h.hexdigest()))print(h1.hexdigest())print(h2.hexdigest())# 运行结果458c46307cbe022bcd948462b2160c33f0821ea7c1d4ad0a9eb473a6448a850879c23075d6898f86f0093531ee33bde7565f0321ad516894071b73a5dc77626abfb5d77e45e99c5280bc1167113fe1e3666e350c6eac9475e66edb91c247e56fb014475c92f8140e601c2238f165a5cc14d5192ae5147acee4185476b65f613e 加盐 123456import hashlibm = hashlib.md5('musibii'.encode('utf-8'))m.update('thales'.encode('utf-8'))print(m.hexdigest())# 运行结果b2bb467965df30aaa14f677c3b3358d1 hmac加密 和MD5等算法没什么区别,主要的区别是必须加盐. 123456import hmach = hmac.new('musibii'.encode('utf-8'))h.update('thales'.encode('utf-8'))print(h.hexdigest())# 运行结果e26b77208fb858f7f8f78965f8ea4f47]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>模块</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python模块之logging]]></title>
    <url>%2F2018%2F10%2F19%2Fpython%E6%A8%A1%E5%9D%97%E4%B9%8Blogging%2F</url>
    <content type="text"><![CDATA[一 日志记录的重要性​ 在开发过程中，如果程序运行出现了问题，通常可以经过debug来检测到底是哪一步出现了问题，如果出现了问题的话，是比较容易排查出问题的。但是程序开发完成之后，部署到生产环境中去，这时候代码相当于是在一个黑盒环境下运行的，我们只能看到其运行的效果，是不能直接看到代码运行过程中的每一步状态的。在生产环境既不能通过debug来排查问题，更不能将生产环境下线来排查问题，所以这时候记录日志就很重要了。 ​ 如果我们现在只能得知当前问题的现象，而没有其他任何信息的话，如果想要解决掉这个问题的话，只能通过问题出现的形式来尝试重现bug，然后在一步一步的调试，这恐怕是难的，这样很大的概率是无法精准的复现这个问题的，而且debug的过程中也会耗费巨多的时间，这样如果在生产环境上出现了问题的话，修复bug就会变得非常棘手。但是如果有日志记录的话，不论是正常运行还是报错，都有相关的时间记录、状态记录、错误记录等，那么这样我们就可以方便的追踪到在当时的运行过程中出现了怎样的状况，从而可以快速的排查问题。 ​ 因此，作为开发者记录生产环境中代码运行的日志是很有必要的，因此学好怎么记录日志过程是一门必修课。 二 日志记录的流程框架在python中，怎样才能算做一个比较标准的日志记录呢？像我之前都是使用控制台查看结果或者debug查看运行状态的，对于一个小项目来说，debug已经足够了，但是对于一个大项目来说一步一步调试费时费力，而且得到的消息也不一定全面，如果自己可以定义输出的调试信息那么对于调试来讲是件很节省时间的事。 在python中专门有一个用来记录日志的模块logging，可以用它来进行标注的日志记录，利用它我们可以更方便的进行日志记录，同时还可以做更方便的级别区分以及一些额外的日志信息的记录，如时间、运行模块信息等。 那么完整的日志记录流程框架是什么样呢？ 如图所示，整个日志记录的框架可以分为这么几个部分： Logger：即Logger Main Class，是我们进行日志记录是创建的对象，可以调用Logger的方法传入日志模板和信息，来生成一条条日志记录，称作Log Record。 Log Record：就代指生成的一条条日志记录。 Handler：即用来处理日志记录的类，它可以将Log Record输出到我们指定的日志位置和存储形式等，如我们可以指定输入到具体的文件、或者可以指定将日志通过FTP协议记录到远程的服务器上，Handler就会帮我们完成这些事情。 Formatter：实际上生成的Log Record也是一个个对象，那么我们想要把它们保存成一条条我们想要的日志文本的话，就需要有一个格式化的过程，那么这个过程就有Formatter来完成，返回的就是日志字符串，然后传回给Handler来处理。 Filter：另外保存日志的时候我们可能不需要全部保存，只需要保存我们想要的部分就可以了，所以在保存的时候需要进一步过滤，留下想要的日志信息，如只保存某个级别的日志，那么这个过滤过程就可以交给Filter来完成。 Parent Handler：Handler之间可以存在分层关系，以使得不同Handler之间共享想通功能的代码。 这些就是整个logging模块的基本架构和对象功能。 三 日志记录的相关用法logging模块有如下几个优点： 可以在logging模块中设置日志等级，在不同的版本（如开发环境、生产环境）上通过设置不同的输出等级来记录相应的日志。 logging模块不仅可以把输出信息输出到控制台，还可以设置输出到任意位置，如写入文件、写入远程服务器等。 logging模块具有灵活的配置和格式化功能，如配置输出当前模块信息、运行时间等，相比print的字符串格式化更加方便易用。 四 日志记录的相关用法一 日志级别日志级别分为五个级别： 等级 数值 CRITICAL 50 FATAL 50 ERROR 40 WARNING 30 WARN 30 INFO 20 DEBUG 10 NOTSET 0 这里最高的等级是 CRITICAL 和 FATAL，两个对应的数值都是 50，另外对于 WARNING 还提供了简写形式 WARN，两个对应的数值都是 30。 我们设置了输出 level，系统便只会输出 level 数值大于或等于该 level 的的日志结果，例如我们设置了输出日志 level 为 INFO，那么输出级别大于等于 INFO 的日志，如 WARNING、ERROR 等，DEBUG 和 NOSET 级别的不会输出。 在logging模块中有对应的常量用来标识级别，默认情况下，默认的log级别是warning（30），默认输出到控制台。 二 自定义日志的配置12345678# test.pyimport logginglogging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')logger = logging.getLogger(__name__)logger.info('log info')logger.debug('log debug')logger.warning('log warning')logger.critical('log critical') 在这里首先导入logging模块，然后进行了一下基本的配置，通过basicConfig配置了level级别和format格式化信息，level配置为INFO级别，只输出大于等于INFO级别的信息，format格式的字符串，包括asctime、name、levelname、message四个内容，分别代表运行时间、模块名称、日志级别、日志内容，这样输出内容便为这四个内容的信息了，这就是logging全局配置。 接下来声明了一个Logger对象，是日志输出的主类，调用对象的info()方法可以输出INFO级别的日志信息，调用debug()方法就可以输出DEBUG级别的日志信息，其他级别的日志信息同理可以输出。初始化logger时传入了name来代替传入模块的名称，如果直接运行该脚本则值为main,如果作为模块被import的话，则就是被导入模块的名称为test.py，因为在不同的模块中该值不同，所以直接使用name代替，然后输出了四条日志信息，其中有一条INFO信息，一条DEBUG信息，一条WARNING信息，一条CRITICAL信息，因为设置的level为INFO，所以低于INFO的级别日志会被过滤，所以DEBUG日志信息会被过滤。 三 basicConfig的具体参数basicConfig是用作全局的日志配置，basicConfig的参数有： filename：日志输出的文件名，如果指定了这个信息之后，不会使用默认的StreamHandler，会使用FileHandler来将日志信息输入到指定的文件中。 filemode：该参数为指定日志文件的写入方式，有两种形式，一种为w，一种为a，分别代表覆盖写入和追加写入。 format：指定日志信息的输出格式，即上文示例所示的参数，部分参数如下： %(levelno)s：打印日志级别的值； %(levelname)s：打印日志级别的名称； %(pathname)s：打印当前执行程序的路径，其实就是sys.argv[0]； %(filenam)s：打印当前执行程序名； %(funcName)s：打印日志的当前函数； %(lineno)s：打印日志的当前行号； %(asctime)s：打印日志的时间； %(thread)s：打印线程id； %(threadName)s：打印线程名称； %(process)s：打印进程id； %(processName)s：打印进程名称； %(module)s：打印模块名称； %(message)s：打印日志信息。 datefmt：指定时间的输出格式。 style：如果format参数制定了，这个参数就可以指定格式化时的占位符风格，如%、{、$等。 level：指定日志输出的类别，程序会输出大于等于此级别的信息。 stream：在没有指定filename的时候会默认使用StreamHandler，这时stream可以指定初始化的文件流。 handlers：可以指定日志处理时所使用的Handlers，必须是可迭代的。 四 Formatter配置在进行日志格式化输出的时候，我们可以不借助于basicConfig来全局配置格式化输出内容，可以借助Formatter来完成 Formatter用法： 123456789101112131415import logginglogger = logging.getLogger(__name__)logger.setLevel(level=logging.WARN)formatter = logging.Formatter(fmt='%(asctime)s - %(name)s - %(levelname)s - %(message)s', datefmt='%Y/%m/%d %H:%M:%S')handler = logging.StreamHandler()handler.setFormatter(formatter)logger.addHandler(handler)#loglogger.debug('debug')logger.critical('critical')logger.error('error')logger.warning('warning')logger.info('info') 在这里指定了一个Formatter，并传入fmt和datefmt参数，这样就指定了日志结果的输出格式和时间格式，然后Handler通过setFormatter()方法设置此Formatter对象即可，输出结果如下： 1232018/10/20 00:26:25 - __main__ - CRITICAL - critical2018/10/20 00:26:25 - __main__ - ERROR - error2018/10/20 00:26:25 - __main__ - WARNING - warning 这样可以为每个Handler单独配置输出的格式。 五 捕获Tracback异常信息遇到错误的时候，希望报错时出现详细的Tracback信息，便于我们调试，利用logging模块可以非常方便的实现这种需求。 1234567891011121314151617181920212223import logginglogger = logging.getLogger(__name__)logger.serLevel(level=logging.DEBUG)formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')file_handler = logging.FileHandler('test.log')file_handler.setFormatter(formatter)logger.addHandler(file_handler)stream_handler = logging.StreamHandler()stream_handler.setFormatter(formatter)logger.addHandler(stream_handler)logger.info('INFO')logger.warning('WARNING')try: num = 1/0except Exception: logger.error('something wrong', exc_info=True) logger.info('end') 这里在error()方法中添加了一个参数，将exc_info设置为True，这样就可以输出执行过程中的信息了，即可以输出完整的Tracback信息。 运行结果如下： 123456782018-10-20 00:36:38,007 - __main__ - INFO - INFO2018-10-20 00:36:38,007 - __main__ - WARNING - WARNING2018-10-20 00:36:38,007 - __main__ - ERROR - something wrongTraceback (most recent call last): File "/Users/jingxing/PycharmProjects/python全栈/day22/log_test.py", line 58, in &lt;module&gt; num = 1 / 0ZeroDivisionError: division by zero2018-10-20 00:36:38,007 - __main__ - INFO - end 这样可以详细的记录报错的信息，一旦出现了错误，可以及时的定位到出现问题的代码。 六 配置共享在写项目的时候，肯定会有许多的配置信息，如果每个文件都来配置logging的话非常麻烦，而且几乎很多地方的配置几乎差不多的，因为此原因，logging模块提供了父子模块共享配置的机制，会根据Logger的名称来自动加载父模块的配置。 定义一个main.py文件： 12345678910111213141516# main.pyimport loggingimport corelogger = logging.getLogger('main')logger.setLevel(level=logging.DEBUG)handler = logging.FileHandler('test.log')handler.setLevel(logging.INFO)formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - % (message)s')handler.setFormatter(formatter)logger.addHandler(handler)logging.info('main info')logging.debug('main debug')logging.error('main error')core.run() 在执行文件配置了日志的输出格式和文件路径，同时定义了Logger的名称为main，然后引入了另外一个模块core，最后调用了core的run()方法。 接下来定义core.py，内容如下： 12345678import logginglogger = logging.getLogger('main.core')def run(): logger.info('core info') logger.debug('core debug') logger.error('core error') 在core.py文件里定义了Logger的名称为main.core，因为之前在main.py文件里定义的Logger名称为main，所以core.py里面的Logger就会复用main.py里面的Logger配置，而不用重新为core配置日志了。 运行之后test.log结果如下： 1234562018-10-20 10:15:37,575 - main - INFO 2018-10-20 10:15:37,575 - main - DEBUG 2018-10-20 10:15:37,575 - main - ERROR 2018-10-20 10:15:37,575 - main.core - INFO 2018-10-20 10:15:37,575 - main.core - DEBUG 2018-10-20 10:15:37,575 - main.core - ERROR 可以看出main和core模块都是用了同样的输出配置。所以只要在入口文件里定义好logging模块的输出配置，子模块只需要在定义Logger对象时使用父模块的名称开头就可以共享配置，实际上直接使用父模块的名字就可以，但是为了增加辨识度，可以在父模块名字后加上后缀。 查看getLogger源码可得，后面的名字可以自定义，然后getLogger里面会自动帮你创建以该名字命名的日志生成器，具体解释如下： 1获取具有指定名称（通道名称）的记录器，如果它尚不存在则创建它。 此名称是以点分隔的分层名称，例如“a”，“a.b”，“a.b.c”或类似名称。如果指定名称存在PlaceHolder [即 loggerdid不存在，但它的子节点已经存在]，用createdlogger替换它，并修复指向占位符的父/子引用，现在指向记录器。 七 文件配置虽然可以再入口文件中定义好配置信息，然后子模块也可以使用很方便，但是因为配置文件大部分都是不需要更改的，只是某些需要更改，像这种信息可以把配置写入配置文件里，然后运行时读取配置文件里面的配置，这样更易维护和使用。 项目结构如下： 123456789# bin/start.pyimport os,syssys.path.append(os.path.dirname(os.path.dirname(__file__)))import core.shopdef run(): print("welcome to here") core.shop.shopping()run() 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647# conf/settingsstandard_format = "%(name)s %(asctime)s %(levelname)s %(module)s %(funcName)s %(lineno)s %(message)s"simple_format = "%(name)s %(asctime)s %(module)s %(message)s"complete_format = "%(asctime)s %(levelname)s %(funcName)s %(lineno)s %(thread)s %(process)s %(message)s"logfile_path = r"/Users/jingxing/PycharmProjects/python全栈/day23/log/d.log"LOGGING_DIC = &#123; 'version': 1, 'formatters': &#123; 'standard': &#123; 'format': standard_format &#125;, 'simple': &#123; 'format': simple_format &#125;, "complete":&#123; "format": complete_format &#125; &#125;, 'filters': &#123;&#125;, 'handlers': &#123; 'console': &#123; 'level': 'DEBUG', 'class': 'logging.StreamHandler', 'formatter': 'simple' &#125;, 'default': &#123; 'level': 'DEBUG', 'class': 'logging.handlers.RotatingFileHandler', 'formatter': 'standard', 'filename': logfile_path, # 'maxBytes': 1024 * 1024 * 5, # 日志文件的最大大小为5M 超出后 换文件 'backupCount': 5, # 最多留五个日志文件 'encoding': 'utf-8', &#125;, &#125;, 'loggers': &#123; # 在getLogger的时候 如果指定的名称 不存在 或者不给名称 用的就是默认的 # 在这里如果key为空 它就是默认的 # 你可以自己定义生成器的名称 并且他们还能使用相同的默认配置 '': &#123; 'handlers': ['default', 'console'], 'level': 'DEBUG', 'propagate': False, &#125;, &#125;,&#125; 1234567# core/shop.pyimport lib.commonlogger = lib.common.get_logger()def shopping(): print("开始购物") logger.debug("购物成功") 1234567# lib/common.pyimport conf.settingsimport logging.configdef get_logger(): logging.config.dictConfig(conf.settings.LOGGING_DIC) return logging.getLogger("main") 在代码运行后，在shop.py模块中导入了lib.common模块，在common.py模块中导入了conf.settings模块，来获取具体的日志配置，因为getLogger(‘main’)里面的main在settings里面没有，所以使用默认的日志配置，如下： 123456789'loggers': &#123; # 在getLogger的时候 如果指定的名称 不存在 或者不给名称 用的就是默认的 # 在这里如果key为空 它就是默认的 # 你可以自己定义生成器的名称 并且他们还能使用相同的默认配置 '': &#123; 'handlers': ['default', 'console'], 'level': 'DEBUG', 'propagate': False, &#125; 然后首先进行level=’DEBUG’的过滤，因为shopping中的日志信息级别为debug，所以会通过进入handlers里面进行第二次过滤，在handlers里面有两个配置，一个为default配置，一个味console配置，在default配置中，具体配置如下： 123456789'default': &#123; 'level': 'DEBUG', 'class': 'logging.handlers.RotatingFileHandler', 'formatter': 'standard', 'filename': logfile_path, # 'maxBytes': 1024 * 1024 * 5, # 日志文件的最大大小为5M 超出后 换文件 'backupCount': 5, # 最多留五个日志文件 'encoding': 'utf-8', &#125; 发现日志级别为DEBUG，所以仍然不会过滤，接下来就是格式化输出到指定文件了，formatter为standard模式，filename之前都已经定义好了，同理console同理输出到控制台。]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>模块</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python模块之xml]]></title>
    <url>%2F2018%2F10%2F18%2Fpython%E6%A8%A1%E5%9D%97%E4%B9%8Bxml%2F</url>
    <content type="text"><![CDATA[xml模块 xml结构 xml是种实现不同语言或程序之间进行数据交换的协议，跟json差不多，但没json使用简单。但是因为历史遗留问题，至今很多行业依然使用xml这种数据格式。 xml的格式如下，是通过&lt;&gt;节点来区别数据结构的。 12345678910111213141516171819&lt;?xml version="1.0" encoding="utf-8"?&gt;&lt;friendsinfo&gt; &lt;frd age="22" name="任盼晨"&gt; &lt;info qq="1114893928" wechat="Dmgwood" /&gt; &lt;/frd&gt; &lt;frd age="22" name="袁靖"&gt; &lt;info qq="2410152779" wechat="wxid_2vykc0sjoiie21" /&gt; &lt;/frd&gt; &lt;frd age="22" name="卫一帆"&gt; &lt;info qq="97280940" wechat="oOC" /&gt; &lt;/frd&gt; &lt;frd age="22" name="胡文涛"&gt; &lt;info qq="2522864970" wechat="hu2522864970" /&gt; &lt;/frd&gt;&lt;/friendsinfo&gt; 语法结构 任何的起始标签都必须有一个结束标签。 &lt;&gt; &lt;/&gt; 可以采用另一种简化语法，可以在一个标签中同时表示起始和结束标签。这种语法是在大于号之前紧跟一个斜杠(/)，例如，解析器会将其翻译成 标签必须按合适的顺序进行嵌套，所以结束标签必须按镜像顺序匹配起始标签。这好比将起始和结束标签看作是数学中的左右罗浩：在没有关闭所有的内部括号之前，是不能关闭外面括号的。 所有的特性都必须有值。 所有的特性都必须在值得周围加上双引号。 一个标签的组成部分包括：标签名、属性名以及属性值、还有文本内容（可以没有） 双标签的写法： 1&lt;tagename '属性名称'="属性值"&gt;文本内容&lt;/tagname&gt; 单标签的写法： 1&lt;tagename 属性名称="属性值"/&gt; 总结：xml也是一种中间格式，也属于序列化方式之一，与json比较，同样的数据json会更小，效率更高；xml需要根据文档结构手动解析，而json直接可以转为python数据对象。 xml模块用法 1234567891011121314151617181920212223# d.xml&lt;?xml version="1.0" encoding="utf-8"?&gt;&lt;studentinfo&gt; &lt;stu age="20" name="张三"&gt; &lt;girlfriend age="19" name="张三的女朋友" /&gt; &lt;/stu&gt; &lt;stu age="20" name="李四"&gt; &lt;girlfriend age="19" name="李四的女朋友" /&gt; &lt;/stu&gt; &lt;age num="1"&gt; &lt;age num="2"&gt; &lt;age num="3"&gt; &lt;/age&gt; &lt;/age&gt; &lt;/age&gt; &lt;age&gt; &lt;/age&gt;&lt;/studentinfo&gt; 1234567891011121314151617181920212223242526import xml.etree.ElementTree as ElementTreetree = ElementTree.parse('d.xml')rootTree = tree.getroot()# 三种获取标签的方式# 1. 获取所有人的年龄，iter用于在全文范围获取标签for item in rootTree.iter('age'): # 一个标签三个组成部分 print(item.tag) # 标签名称 print(item.attrib) # 标签的属性 print(item.text) # 文本内容# 2. 从当前标签的子标签中找到一个名称为age的标签，如果有多个，找到的是第一个print(rootTree.find('age').attrib)# 3. 从当前标签的子标签中找到所有名称为age的标签print(rootTree.findall('age'))# 获取单个属性stu = rootTree.find('stu')print(stu.get("age"))print(stu.get("name"))# 删除子标签rootTree.remove(stu)# 添加子标签newTag = ElementTree.Element('这是新标签', &#123;'一个属性': '值'&#125;)rootTree.append(newTag)# 写入文件tree.write('f.xml', encoding='utf-8')]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>模块</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python模块之configparser模块]]></title>
    <url>%2F2018%2F10%2F18%2Fpython%E4%B9%8Bconfigparser%E6%A8%A1%E5%9D%97%2F</url>
    <content type="text"><![CDATA[一 什么是configparser？configparser是用于解析配置文件的模块。什么是配置文件呢？包含配置程序信息的文件就称为配置文件。什么样的数据应该作为配置信息呢？需要修改但是不经常改的信息就可以作为配置信息，比如数据文件的路径。 二 什么是配置文件？配置文件中只有两种内容： section，分区 option，选项，是键值对的形式 三 configparser的使用wiki12345678910# useinfo.cfg[user]name1 = musibiiname2 = thalesname3 = ddd[password]password1 = woshinibabapassword2 = 123456password3 = 123 1234567891011121314151617181920212223242526import configparser# 创建一个解析器config = configparser.ConfigParser()# 读取并解析cfg文件config.read('useinfo.cfg', encoding='utf-8')# 获取所有sectionprint(config.sections())# 获取某个分区下所有optionprint(config.options('user'))# 获取某个选项具体的值print(config.get('user', 'name1'))# get返回的都是字符串类型，如果需要转换类型，直接使用get+对应的类型(bool，int，float)print(config.getint('password', 'password1'))# 是否有某个选项，返回布尔值config.has_option()# 是否有某个分区config.has_section()# 不常用的一些方法# 添加分区(必须先添加分区才可以修改分区下面的值)config.add_section('server')config.set('server', 'usr', '192.168.1.1')# 删除选项config.remove_option('user', 'name1')# 写入文件with open('useinfo.cfg', 'wt', encoding='ust-8') as f: config.write(f) 使用例子: 1234# admin.cfg[admin]name=maffiapassword=woshinibaba 1234567891011121314# test.pyimport configparserconfig = configparser.ConfigParser()# 获取账号和密码信息def load_admin(): admin_info = [] config.read(admin.cfg, encoding='utf-8') sections = config.sections() for item in sections: user_dic = &#123;'name': config.get(item, 'name'), 'password': config.get(item, 'password')&#125; admin_info.append(user_dic) return admin_info]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>模块</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python模块之pickle、shelve、json]]></title>
    <url>%2F2018%2F10%2F17%2Fpython%E5%BA%8F%E5%88%97%E5%8C%96%E6%95%B0%E6%8D%AE%E6%A8%A1%E5%9D%97%2F</url>
    <content type="text"><![CDATA[一 什么是序列化序列化指的是将内存中的数据结构转化为一种中间格式，并存储到硬盘上。 （反序列化：将硬盘上存储的中间格式数据再还原为内存中的数据结构） 二 为什么要序列化 持久保持状态 需知一个软件/程序的运行就是处理一系列状态的变化，在编程语言中，‘状态‘会以各种有结构的数据类型(也可以称之为变量)的形式保存在内存中。 内存是无法永久保存数据的，当程序运行了一段时间，我们断电或者重启程序，内存中关于这个程序之前一段时间的数据都会被清空。 在断电或重启程序之前将程序当前运行的数据保存下来，便于下次程序执行能够从文件中载入之前的数据，然后继续执行，这就是序列化。 数据跨平台交互 序列化数据之后，不仅可以把序列化后的内容写入硬盘，还可以通过网络传输到别的机器上，如果收发的双方约定都使用一种序列化的格式，那么便打破了平台和语言带来的限制，实现了跨平台交互。 反过来，把变量内从从序列化的对象重新读到内存里称之为反序列化，即unpicking。 三 序列化数据的三个模块一 pickle模块pickle模块时python内置的用来序列化python数据格式的模块，支持序列化python中所有的数据类型，主要方法有四个； dumps 12345678import picklename = 'musibii'age = 18height = 1.7user = &#123;'name': name, 'age': age, 'height': height&#125;with open('userinfo.pkl', 'ab') as f: userbytes = pickle.dumps(user) f.write(userbytes) loads 12345import picklewith open('userinfo.pkl', 'rb') as f: userbytes = f.read() user = pickle.loads(userbytes) print(user) 与dumps和loads对应的两个方法更简单。 dump 123import picklewith open('userinfo.pkl', 'ab') as f: pickle.dump(user, f) load 1234import picklewith open('userinfo.pkl', 'rb') as f: user = pickle.load(f) print(user) 二 shelve模块shevlve模块也用于序列化，它和pickle模块不同的地方在于，不需要关心文件模式，直接把数据当成字典来看待。而且shelve模块可以直接对数据进行修改，而不用覆盖之前的数据，但pickle要想修改的话只能使用wb模式覆盖 shelve只有一个方法open，所以使用起来也很方便。同样的，shelve也支持python中所有的数据格式。 12345import shelveuser = &#123;'name': 'musibii'&#125;s = shelve.open('userdb.shv')s['user'] = users.close() 三 json模块1 json是什么JSON是Java script object notation的缩写，翻译过来就是js对象标识法。 对于开发者而言，json是一种通用的数据格式，任何语言都能解析，所以每种语言都会有处理json格式数据的需求。 json语法 js 中的数据类型 python数据类型 的对应关系 {} 字典 [] list string “” str int/float int/float true/false True/False null None json格式的语法规范 最外层通常是一个字典或列表 {}or[]，如果想定义json格式的数据，那么最外层直接写{}，而且json中的字符串必须是双引号，json理论上可以嵌套任意多的层次。 2 为什么用json虽然之前的pickle和shelve都很强大，而且使用也非常方便，那么为什么还出来json呢？这是因为pickle和shevle序列化之后的数据只有python才能解析出来，而通常在实际生产开发中，都是需要数据可以跨平台使用的。 3 json的使用json模块的核心方法 dump dumps load loads 不带s的直接封装了write和read方法。 dump 1234567891011121314import jsonjsontext = """&#123; "users": [&#123; "name": "musibii", "age": 18 &#125;, &#123; "name": "thales", "age": 23 &#125; ]&#125;"""with open('a.json', 'wt', encoding='utf-8') as f: json.dump(jsontext, f) dumps 1234567891011121314import jsonjsontext = """&#123; "users": [&#123; "name": "musibii", "age": 18 &#125;, &#123; "name": "thales", "age": 23 &#125; ]&#125;"""with open('a.json', 'wt', encoding='utf-8') as f: f.write(json.dumps(jsontext)) load 123import jsonwith open('a.json', 'rt', encoding='utf-8') as f: print(json.load(f)) loads 1234import jsonwith open('a.json', 'rt', encoding='utf-8') as f: res = json.loads(f.read()) print(res)]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>模块</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python模块之shutil]]></title>
    <url>%2F2018%2F10%2F17%2Fpython%E6%A8%A1%E5%9D%97%E4%B9%8Bshutil%2F</url>
    <content type="text"><![CDATA[shutil是一个用于简化文件操作的模块。 复制文件（传入源文件对象和目标文件对象） 1234import shutilf1 = open(r'/Users/jingxing/PycharmProjects/day20/test.py', 'rb')f2 = open(r'/Users/jingxing/PycharmProjects/day20/test_test.py', 'rb')shutil.copyfileobj(f1, f2) 压缩文件 123import shutilshutil.make_archive('myzip', 'zip', r'/Users/jingxing/PycharmProjects/day20')shutil.make_archive('mytar', 'tar', r'/Users/jingxing/PycharmProjects/day20') 解压文件 123import shutilshutil.unpack_archive(r'/Users/jingxing/PycharmProjects/day20/myzip.zip')shutil.unpack_archive(r'/Users/jingxing/PycharmProjects/day20/mytar.tar') 其他两个用于解压的模块 zipfile从名字可以看出来是解压zip压缩文件的模块。 解压 1234import zipfilez = zipfile.ZipFile(r'/Users/jingxing/PycharmProjects/day20/myzip.zip', 'r')z.extractall(path=r'/Users/jingxing/PycharmProjects/day20')z.close() 往压缩包中添加文件 12345import zipfilez = zipfile.ZipFile(r"/Users/jingxing/PycharmProjects/python全栈/day20/代码/my压缩.tar","w")z.write("1.昨日回顾")z.write("2.今日内容")z.close() tarfile 解压 1234import tarfilet = tarfile.open(r"/Users/jingxing/PycharmProjects/python全栈/day20/代码/my压缩.tar","w")t.extractall(r"/Users/jingxing/PycharmProjects/python全栈/day19")t.close() 往压缩包中添加文件 12345port tarfilet = tarfile.open(r"/Users/jingxing/PycharmProjects/python全栈/day20/代码/my压缩.tar","w")t.add("1.昨日回顾")t.add("2.今日内容")t.close()]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>模块</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python模块之random]]></title>
    <url>%2F2018%2F10%2F17%2Fpython%E6%A8%A1%E5%9D%97%E4%B9%8Brandom%2F</url>
    <content type="text"><![CDATA[python的随机数模块为random模块，可以产生随机的整数或浮点数。但是这是伪随机数，python解释器会维护一些种子数，然后根据算法算出随机数。linux维护了一个熵池，这个熵池收集噪音的信息，更接近真随机数。 random 随机产生0-1的浮点数，不包括1 123import randomprint(random.random())# 运行结果 0.8517652068795716 随机产生a-b的整数，包括a和b 12345import randoma = 1b = 10print(random.randint(a, b))# 运行结果 4 随机产生a-b，不包括a和b的整数 12345import randoma = 1b = 10print(random.randrange(a, b))# 运行结果 7 指定一个范围并指定需要产生的随机个数 123import randomprint(random.sample(['aa', ['a', 'b'], 3, 4, 5], 2))# 运行结果 [['a', 'b'], 5] 打乱列表的顺序（返回None） 12345import randomls = [1, 2, 3, 4, 5, 9, 11]random.shuffle(ls)print(ls)# 运行结果 [1, 9, 2, 5, 4, 11, 3] 从给定的序列中随机选一个 123import randomprint(random.choice([1,2,3,4,5,6]))# 运行结果 2 从给定的序列中随机选多个（包括1个，返回一个列表） 123import randomprint(random.choices((1,2,3,4,5,6,7), k=3))# 运行结果 [6, 5, 5] 制作随机验证码 12345678910import randomdef get_verifycode(length): res = '' for i in range(length): a = random.randint(0, 9) b = chr(random.randint(65, 90)) c = chr(random.randint(97, 122)) s = random.choice([a, b, c]) res += s return res]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>模块</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python模块之sys与os]]></title>
    <url>%2F2018%2F10%2F17%2FPython%E5%B8%B8%E7%94%A8%E6%A8%A1%E5%9D%97%E4%B9%8Bsys%E4%B8%8Eos%2F</url>
    <content type="text"><![CDATA[python常用模块系列（二）：sys模块与os模块 sys模块是python解释器和环境有关的一个模块； os是python用来和操作系统进行交互的一个模块。 一 sys 查看当前环境变量 查看已经加载的模块 可以看出sys.modules是一个字典，key为加载模块的名字，values为加载模块的路径。 获取终端调用时的参数 终端输入的参数为argv[1]，默认当前文件名为第一个参数。 获取解释器的版本信息 获取当前运行平台名称（windows为nt，macOS为darwin） 退出信号 123import syssys.exit(0) # 正常退出sys.exit(1) # 错误退出 接口版本 123import sysprint(sys.api_version)# 运行结果 1013 了解 123456import sysprint(sys.maxsize)print(sys.maxunicode)# 运行结果# 9223372036854775807# 1114111 二 os 获取当前的工作目录 123import osprint(os.getcwd())# 运行结果 /Users/jingxing/PycharmProjects/python全栈/day20/代码 切换工作目录 1234import osprint(os.chdir('/Users/jingxing/PycharmProjects/python全栈'))print(os.getcwd())# 运行结果 /Users/jingxing/PycharmProjects/python全栈 获取当前目录 123import osprint(os.curdir)# 运行结果 . 获取上级目录 123import os print(os.pardir)# 运行结果 .. 获取系统的环境变量 123import osprint(os.environ)# environ(&#123;'PATH': '/Users/jingxing/.nvm/versions/node/v4.9.1/bin:/Library/Frameworks/Python.framework/Versions/3.6/bin:/python_study/mongodb/bin://Volumes/python_study/mongodb/bin:/Library/Frameworks/Python.framework/Versions/3.6/bin:/usr/local/bin:/usr/bin:/bin:/usr/sbin:/sbin:/Applications/VMware Fusion.app/Contents/Public:/python_study/Applications/mongodb-osx-x86_64-3.6.3/bin::/usr/local/mysql/bin', 'COMMAND_MODE': 'unix2003', 'VERSIONER_PYTHON_VERSION': '2.7', 'LS_OPTIONS': '--color=auto', 'LOGNAME': 'jingxing', 'XPC_SERVICE_NAME': 'com.apple.xpc.launchd.oneshot.0x10000004.pycharm', 'PWD': '/Users/jingxing/PycharmProjects/python全栈/day20/代码', 'PYCHARM_HOSTED': '1', 'NODE_PATH': '/Users/jingxing/.nvm/versions/node/v4.9.1/lib/node_modules', 'PYCHARM_MATPLOTLIB_PORT': '49379', 'PYTHONPATH': '/Applications/PyCharm.app/Contents/helpers/pycharm_matplotlib_backend:/Users/jingxing/PycharmProjects/python全栈', 'NVM_CD_FLAGS': '', 'NVM_DIR': '/Users/jingxing/.nvm', 'SHELL': '/bin/bash', 'LSCOLORS': 'CxfxcxdxbxegedabagGxGx', 'PYTHONIOENCODING': 'UTF-8', 'SECURITYSESSIONID': '186a7', 'VERSIONER_PYTHON_PREFER_32_BIT': 'no', 'USER': 'jingxing', 'CLICOLOR': 'Yes', 'TMPDIR': '/var/folders/yl/3drd7wf93f90sfkgpc2zg9cr0000gn/T/', 'SSH_AUTH_SOCK': '/private/tmp/com.apple.launchd.bIB1b2eyOD/Listeners', 'XPC_FLAGS': '0x0', 'PYTHONUNBUFFERED': '1', '__CF_USER_TEXT_ENCODING': '0x1F5:0x19:0x34', 'Apple_PubSub_Socket_Render': '/private/tmp/com.apple.launchd.bHuC64fYdd/Render', 'LC_CTYPE': 'zh_CN.UTF-8', 'NVM_BIN': '/Users/jingxing/.nvm/versions/node/v4.9.1/bin', 'HOME': '/Users/jingxing', '__PYVENV_LAUNCHER__': '/Library/Frameworks/Python.framework/Versions/3.6/bin/python3'&#125;) 创建多级目录 123import osos.makedirs('a/b/c')# 会在当前文件路径创建多级目录 创建一个目录 123import osos.mkdir('aa')# 能且仅能创建一个目录 递归删除 123import osos.removedirs('a/b/c')# 递归删除，只能删除空目录 删除一个目录 123import osos.rmdir('aa')# 删除一个目录 删除文件 123import osos.remove(r'/Users/jingxing/PycharmProjects/python全栈')# 删除文件 列出当前目录所有的文件及文件夹 12import osprint(os.listdir(r'/Users/jingxing/PycharmProjects/python全栈')) 获取当前平台路径分隔符 123import osprint(os.seq)# 运行结果 / 获取当前平台换行符 12import osprint(os.lineseq, end='') 三 os下的path模块 返回绝对路径 123from os import pathprint(path.abspath('a/b/c'))# 运行结果 /Users/jingxing/PycharmProjects/python全栈/day20/代码/a/b/c 将路径拆分为文件夹路径和文件名（返回元祖） 123from os import pathprint(path.split('/Users/jingxing/PycharmProjects/python全栈/day20/代码/5.os下path模块.py'))# 运行结果 ('/Users/jingxing/PycharmProjects/python全栈/day20/代码', '5.os下path模块.py') 获取路径中的上一级 123from os import pathprint(path.dirname(__file__))# 运行结果 /Users/jingxing/PycharmProjects/python全栈/day20/代码 获取路径的最后一级名称 123from os import pathprint(path.basename(r'/Users/jingxing/PycharmProjects/python全栈/day20/代码/5.os下path模块.py'))# 运行结果 5.os下path模块.py 判断路径是否存在（返回布尔值） 123from os import pathprint path.exists(r'/Users/jingxing/PycharmProjects/python全栈/day20/代码/5.os下path模块.py')# 运行结果 True 判断是否为绝对路径（返回布尔值） 123from os import pathprint(path.isabs(r'/Users/jingxing/PycharmProjects/python全栈/day20/代码/5.os下path模块.py'))# 运行结果 True 路径拼接 123from os import pathprint(path.join('/Users/jingxing/PycharmProjects/', 'day20'))# 运行结果 /Users/jingxing/PycharmProjects/day20 获取文件的大小 12from os import pathprint(path.getsize(r'/Users/jingxing/PycharmProjects/python全栈')) 大写变小写，斜杠根据当前平台修改 123from os import pathprint(path.normcase(r'a/\b/\c'))# 运行结果 a/\b/\c 斜杠会修改为当前平台的分隔符，执行..来返回上一级 123from os import pathprint(path.normpath('a/b/c/../c'))# 运行结果 a/b/c]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>模块</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python模块之time与datetime]]></title>
    <url>%2F2018%2F10%2F16%2FPython%E5%B8%B8%E7%94%A8%E6%A8%A1%E5%9D%97%E4%B9%8Btime%E4%B8%8Edatetime%2F</url>
    <content type="text"><![CDATA[python常用模块系列（一）：time模块与datetime time模块是python内置查看当前时间戳的一个模块； datetime模块是用来对日期和时间进行操作的一个模块。 一 time1 获得时间戳时间戳：通常来说，时间戳表示的是从1970年1月1日00:00:00开始按秒计算的偏移量。我们运行‘’type(time.time())‘’，返回的是float类型。 123import timeprint(time.time())# 运行结果 1539678307.779871 2 结构化时间字符串123import timeprint(time.localtime()) # 返回一个元祖对象，里面是每个时间的值(东八区)# 运行结果 time.struct_time(tm_year=2018, tm_mon=10, tm_mday=16, tm_hour=16, tm_min=48, tm_sec=4, tm_wday=1, tm_yday=289, tm_isdst=0) 123import timeprint(time.localtime().tm_year) # 单独获取某个时间属性# 运行结果 2018 123import timeprint(time.gmtime()) # 世界统一时间，比北京时间晚8小时# 运行结果 time.struct_time(tm_year=2018, tm_mon=10, tm_mday=16, tm_hour=8, tm_min=51, tm_sec=16, tm_wday=1, tm_yday=289, tm_isdst=0) 3 格式化的字符串时间123456import time print(time.strftime('%Y-%m-%d %H:%M:%S %p'))print(time.strftime('%Y-%m-%d %X %p'))# 运行结果 # 2018-10-16 16:54:56 PM# 2018-10-16 16:54:56 PM 4 三种格式之间的相互转换 时间戳转为结构化 123import timeprint(time.localtime(time.time()))# 运行结果 time.struct_time(tm_year=2018, tm_mon=10, tm_mday=16, tm_hour=16, tm_min=57, tm_sec=18, tm_wday=1, tm_yday=289, tm_isdst=0) 结构化转字符串 123import timeprint(time.strftime("%Y-%m-%d",time.localtime(time.time())))# 运行结果 2018-10-16 字符串转结构化 123import timeprint(time.strftime('2018-10-16', '%Y-%m-%d'))# 运行结果 time.struct_time(tm_year=2018, tm_mon=10, tm_mday=15, tm_hour=0, tm_min=0, tm_sec=0, tm_wday=0, tm_yday=288, tm_isdst=-1) 结构化转时间戳 123import timeprint(time.mktime(time.strptime('2018-10-15', '%Y-%m-%d')))# 运行结果 1539532800.0 格林威治时间 123456import timeprint(time.asctime(time.localtime()))print(time.ctime())# 运行结果# Tue Oct 16 17:12:34 2018# Fri Jan 2 08:00:00 1970 二 datetimedatetime是一个包，里面包含对时间的处理和日期的处理 获取当前详细时间 123import datetimeprint(datetime.datetime.now())# 运行结果 2018-10-16 17:25:16.186114 获取时间的某一部分 123import datetimeprint(datetime.datetime.now().hour) # 分钟、年份等同理# 运行结果 17 替换时间的某一部分 12345import datetimet1 = date.datetime.now()t1 = t1.replace(year=2019)print(t1)# 运行结果 2019-10-16 18:36:42.166986 时间差对象 12345import datetimet2 = datetime.timedelta(weeks=1)t3 = datetime.datetime.now()print(t2 + t3)# 运行结果 2018-10-23 18:40:10.481854]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>内置模块</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[文件目录规范]]></title>
    <url>%2F2018%2F10%2F15%2F%E6%96%87%E4%BB%B6%E7%9B%AE%E5%BD%95%E8%A7%84%E8%8C%83%2F</url>
    <content type="text"><![CDATA[随着功能的增多，代码逻辑也会越来越多，导致代码逻辑混乱不便于管理项目。为了解决这个问题，可以将相同功能的代码集合在一个文件夹，设置一个入口函数，一些设置文件放在一个文件，主要逻辑代码放一个文件夹。。。 这样对于整个业务有很好的可读性和扩展性。 对于之前的ATM+购物车项目最开始所有的逻辑代码都在一个文件，当我们需要修改某些函数时，遇到了一点困难，就是整个项目有600+行代码，而且什么都在里面，对于想快速具体的找到想修改的地方确实需要花费一些时间，效率低下。所以重新修改后，将具体功能代码放在一起，很明显逻辑清晰了，而且看的也很舒服。 如下为我的项目结构中的bin文件夹： bin目录下的start.py文件为启动函数，首先在启动函数里面导入os和sys模块，目的是为了将当前项目的根路径加入环境变量，接着导入相关函数和变量。该py文件仅仅作为程序的入口，里面没有逻辑代码。 如下为conf文件夹： conf是configuration的缩写，为配置的意思，里面只有settings文件，可以看出里面都是定义的一些变量，（在这里的变量其实应该使用大写的） 接下来是主要业务逻辑代码文件夹core（核心）： 里面有三个py文件，因为项目有三个主要功能，分别是ATM、SHOPP、USER，所以分了三个，里面的代码大同小异。 接下来是记录用户消费流水的文件夹，（db）里面也包括了用户信息，比如账号名、密码、余额、状态等信息。 这些信息文件在每一个账户登录时，会根据登录名创建一个文件，模式为追加，当退出时将数据刷入文件并关闭文件。 接下来为lib，lib是library的缩写，表示库的意思。里面只有common文件（里面可以放共用的一些功能代码或者第三方库） common文件里面是几个通用的功能函数，比如日志装饰器、读取用户所有信息的函数、、、 接下来为log文件夹，记录日志，哪个用户登陆了，做了什么事情都会记录下来（仔细想来，生活中我们在某些应用中做的事情是不是也会记录下来？答案是肯定的） 最后一个是README.md文件，通常是用来给用户看的，说明程序怎么使用，叫做帮助文档。]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>包、文件</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[模块与包]]></title>
    <url>%2F2018%2F10%2F11%2F%E6%A8%A1%E5%9D%97%E4%B8%8E%E5%8C%85%2F</url>
    <content type="text"><![CDATA[一 什么是模块模块就是一组功能的集合体，可以通过导入模块来复用模块的功能。 比如我在同一个文件夹定义两个.py文件，分别命名为A.py和B.py，那么可以通过在A文件里通过import B来使用B文件里的名称空间。 python中，模块的使用方式都是一样的，可以分为四个通用类别： 使用python编写的.py文件 已被编译为共享库或DLL的C或C++扩展 把一系列模块组织到一起的文件夹（注：文件夹下有一个init.py文件，该文件夹称之为包） 使用C编写并链接到python解释器的内置模块 二 为何要使用模块 从文件级别组织程序，便于管理 随着需求的增多，功能也会越来越多，为了方便管理，通常将程序分成多个文件，这样项目的结构会更加清晰，方便管理。这时不仅仅可以把这些文件当做脚本去执行，还可以把他们当做模块来导入到其他的模块中，实现功能复用。 使用别人写好的模块，提高开发效率 使用别人已经写好的轮子，在自己的项目中使用，可以极大地提高开发效率。 注意：当退出python解释器的时候，重新进入那么之前定义的函数和变量都会丢失，因此通常将程序写到文件中以便永久保存，需要时可以在命令行通过python *.py方法执行。 1234567891011121314# test1.pyprint('from test1')money = 10def func1(): print('test1模块:', money) def func2(): print('test1模块') func1() def change(): global money money = 100 123# test2.pyimport test1test1.func1() 123# 运行结果from test1test1模块: 10 当在tes2t导入的时候会执行test1中的代码，所以首先会打印from test1接着执行test1中的func1函数。 三 使用模块之import1 import的使用模块可以包含可执行的语句和函数的定义，这些语句的目的是初始化模块，它们只在模块名第一次导入时才会执行（import语句可以在程序中的任意位置使用的，且针对同一个模块可以import多次，python为了防止重复导入，当第一次导入模块时就将模块的名称空间加载到内存了，后续的import语句仅是对已经加载到内存中的模块对象增加了一次引用，并不会重复执行模块内的语句） 12# test3print('from test3') 12345# test4import test3import test3import test3import test3 12# 运行结果from test3 ps:可以导入sys模块，调用sys.module查看当前加载到内存中的模块，sys.module是一个字典，内部包含模块名和模块名路径的对应关系。该字典决定了导入模块时是否需要重新导入。 2 导入模块时发生了什么运行py文件导入一个模块时，解释器做了三件事： 在执行文件中为被导入文件创建新的名称空间，在被导入模块中定义的函数和方法若是使用到了global时访问的就是这个名称空间。 在新创建的名称空间中执行模块中的包含的代码。函数定义也是‘’被执行‘’的语句，模块级别函数定义的执行将函数名放入模块全局名称空间表，可以用globals()可以查看。 在执行文件的名称空间创建被导入模块的名称来引用该名称空间。 这个名字和变量名没什么区别，都是‘’第一类‘’的，且使用句点表示法可以访问被导入模块的名称空间，导入的模块与被导入的模块是独立的两个名称空间。 3 被导入模块有独立的名称空间每个模块都是一个独立的名称空间，定义在这个模块中的函数，把这个模块的名称空间当做全局名称空间，这样就不用担心定义在不同的模块中全局变量在导入时与使用者的全局变量冲突。 测试1 1234# test5.pyimport test1money = 100print(test1.money) 123# 运行结果from test110 测试2 123456# test6import test1def func1(): print('from test6 func1')test1.func1()func1() 12345# 运行结果from test1test1模块: 10from test6 func1# 这说明 test6中的函数和test1中的函数不冲突 测试3 12345# test7import test1money = 1test1.change()print(money) 12345# 运行结果from test1test1模块: 101# 这说明test1中的change函数只是修改了test1中的全局变量，对test7中的变量没有操作权限 四 使用模块之from…import…1 from…import…与import …的区别区别就是：使用from…import…是将被导入模块中的名字直接导入到当前的名称空间中，所以在当前名称空间中，直接使用名字就可以了，不需要在前面加上模块名前缀。 from…import…导入方式的优缺点： 好处：使用方便 坏处：容易与当前执行文件的名字冲突 2 验证 验证1：当前位置直接使用test1中的函数名，执行时仍然以test1.py文件为全局名称空间 12345# 导入的函数func1，执行时仍然回到test1.py中寻找全局变量money# test8from test1 import func1money = 50func1() 123# 运行结果from test1test1模块: 10 123456# 导入的函数func2，执行时需要调用func1，仍然回到test1.py中找func1#test9.pyfrom test1 import func2def func1(): print('-----')func2() 1234# 运行结果from test1test1模块test1模块: 10 验证2：如果当前名称空间和被导入的模块中的名字重合，那么会覆盖掉前面的名字 123456# 导入的函数fun1,被当前位置定义的func1覆盖掉了# test10from test1 import func1def func1(): print('======')func1() 1234# 运行结果from test1======# 这说明func1把被导入名字func1覆盖掉了 123456# 当前位置定义的func1导入func1# test11def func1(): print('======')from test1 import func1func1() 1234# 运行结果from test1test1模块: 10# 这说明在后面导入的话会覆盖掉前面的 验证3：被导入的方法执行时，始终以源文件为准 12345# test12from test1 import money,func1money=100 #将当前位置的名字money绑定到了100print(money) #打印当前的名字func1() #读取spam.py中的名字money,仍然为1000 12345# 运行结果from the test100test1模块: 10# 可以看出运行func1的时候依然从原名称空间查找的 3 from … import *from … import * 是把被导入文件中所有不是以下划线(_)开头的名字都导入到当前名称空间。 大部分情况下不应该以这种导入方式，因为不知道被导入包中的名字是否会和当前名称空间中的名字重合造成名字覆盖。 解决方法是在被导入文件中使用all = []来控制被导入的名字，只有在all里面的才会被导入。 4 模块循环导入问题模块循环/嵌套导入抛出异常的根本原因是由于在python中模块被导入一次之后，就不会重新导入。 1234# test1.pyprint('正在导入1')from test2 import yx = '1' 1234# test2.pyprint('正在导入2')from test1 import xy = '2' 12# run.pyimport test1 1234567891011# 运行结果正在导入1正在导入2Traceback (most recent call last): File "/Users/jingxing/PycharmProjects/python全栈/day18/pack/run.py", line 6, in &lt;module&gt; import test1 File "/Users/jingxing/PycharmProjects/python全栈/day18/pack/test1.py", line 7, in &lt;module&gt; from test2 import y File "/Users/jingxing/PycharmProjects/python全栈/day18/pack/test2.py", line 8, in &lt;module&gt; from test1 import xImportError: cannot import name 'x' 分析：在run文件中执行导入test1，运行test1的代码，打印并且从test2中导入y，回到test2，打印并且从test1中导入，因为已经导入test1了（没导入完全，因为代码没执行完），所以直接找’x’，但因为在test1中的代码执行不下去，所以报错。执行文件不等于就完全导入文件了。 解决方法1：导入语句放在最后 解决方法2：导入语句放在函数中（因为在导入模块时，函数内的代码并不会执行，只会判断语法错误，所以这时候导入模块可以完全导入） 5 模块的重载考虑到性能的原因，每个模块只被导入一次，放入字典sys.module中，如果你改变了模块的内容，必须重启程序（python不支持重新加载或卸载之前导入的模块） 就算在修改已经导入的模块里面的代码对运行结果也没影响。 6 py文件区分两种用途：模块与脚本 脚本，一个文件就是整个程序，用来被执行 模块，文件中存放着一堆功能，用来被导入使用 python内置了全局变量name, 当文件被当做脚本执行时：name等于’main‘ 当文件被当做模块导入时：name等于模块名 作用：用来控制.py文件在不同的应用场景下执行不同的逻辑 12if __name__ == '__main__': pass 7 模块搜索路径模块的查找顺序是：内存中已经加载的模块–》内置模块–》sys.path路径中包含的模块 详细：在第一次导入某个模块式，会先检查该模块是否已经被加载到内存中（当前执行文件的名称空对应的内存），如果有则直接引用； ps:python解释器会在启动时自动加载一些模块到内存中，可以使用sys.module查看。 如果在内存中没有，解释器会查找同名的内建模块； 如果还没有则去sys.path给出的目录列表中查找。 了解：sys.path的初始化的值来自于： The directory containing the input script (or the current diretory whrn no files is specified). PYTHONPATH (a list of directory names, with the same syntax as the shell variable PATH). The installation-dependent default. 在初始化后，python程序可以修改sys.path，路径放在前面的优于标准库被加载。 搜索时按照sys.path中从左到右的顺序查找，位于前面的优先被查找，sys.path中还可能包含.zip归档文件和.egg文件，python会把.zip归档文件当成一个目录去处理。 .egg文件是setuptools创建的包，这是按照第三方python库和扩展时使用的一种常见格式，.egg文件实际上只是添加了额外元数据（如版本号，依赖项等）的.zip文件。 只能从.zip文件中导入.py，.pyc等文件。使用C编写的共享库和扩展块无法直接从.zip文件中加载（此时setuptools等打包系统有时能提供一种规避方法），且从.zip中加载文件不会创建.pyc或者.pyo文件，因此一定要事先创建他们，来避免加载模块是性能下降。 8 编译python文件为了提高加载模块的速度，强调强调强调：提高的是加载速度而绝非运行速度。python解释器会在pycache目录中下缓存每个模块编译后的版本，格式为：module.version.pyc。通常会包含python的版本号。例如，在CPython3.3版本下，spam.py模块会被缓存成pycache/spam.cpython-33.pyc。这种命名规范保证了编译后的结果多版本共存。 Python检查源文件的修改时间与编译的版本进行对比，如果过期就需要重新编译。这是完全自动的过程。并且编译的模块是平台独立的，所以相同的库可以在不同的架构的系统之间共享，即pyc使一种跨平台的字节码，类似于JAVA火.NET,是由python虚拟机来执行的，但是pyc的内容跟python的版本相关，不同的版本编译后的pyc文件不同，2.5编译的pyc文件不能到3.5上执行，并且pyc文件是可以反编译的，因而它的出现仅仅是用来提升模块的加载速度的，不是用来加密的。 五 包1 什么是包？包是一种通过’.模块名’来组织python模块名称的方式。 具体的：包就是一个包含有init.py文件的文件夹，所以其实我们创建包的目的就是为了用文件夹将文件/模块组织起来。 2 为何使用包？包的本质就是一个文件夹，文件夹的功能就是将同类型的文件组织起来。 其实使用包的原因和使用模块的原因是一样的，都是为了提高程序的结构性和可维护性。 3 注意事项 关于包相关的导入语句也分为import和from … import …两种，但是无论哪种，无论在什么位置，在导入时都必须遵循一个原则：凡是在导入时带点的，点的左边都必须是一个包，否则非法。可以带有一连串的点，但都必须遵循这个原则。但对于导入后，在使用时就没有这种限制了，点的左边可以是包,模块，函数，类(它们都可以用点的方式调用自己的属性)。 import导入文件时，产生名称空间中的名字来源于文件，import 包，产生的名称空间的名字同样来源于文件，即包下的init.py，导入包本质就是在导入该文件 包A和包B下如果有同名模块也不会冲突，因为他们的名称空间是独立的。 4 绝对导入和相对导入包是写给别人用的，然而在包的内部也会有彼此之间互相导入的需求，这时候就有绝对导入和相对导入两种方式： 绝对导入：以包作为起点 相对导入：以.或..的方式作为起点（只能在一个包中使用，不能用于不同目录内） **包以及包所包含的模块都是用来被导入的，而不是直接执行的。而环境变量都是以执行文件为准。 5 绝对导入与相对导入总结12345678910111213绝对导入与相对导入# 绝对导入: 以执行文件的sys.path为起始点开始导入,称之为绝对导入# 优点: 执行文件与被导入的模块中都可以使用# 缺点: 所有导入都是以sys.path为起始点,导入麻烦# 相对导入: 参照当前所在文件的文件夹为起始开始查找,称之为相对导入# 符号: .代表当前所在文件的文件加,..代表上一级文件夹,...代表上一级的上一级文件夹# 优点: 导入更加简单# 缺点: 只能在导入包中的模块时才能使用 #注意: 1. 相对导入只能用于包内部模块之间的相互导入,导入者与被导入者都必须存在于一个包内 2. attempted relative import beyond top-level package # 试图在顶级包之外使用相对导入是错误的,言外之意,必须在顶级包内使用相对导入,每增加一个.代表跳到上一级文件夹,而上一级不应该超出顶级包]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[匿名函数python内置高阶函数以及递归]]></title>
    <url>%2F2018%2F10%2F10%2F%E5%8C%BF%E5%90%8D%E5%87%BD%E6%95%B0python%E5%86%85%E7%BD%AE%E9%AB%98%E9%98%B6%E5%87%BD%E6%95%B0%E4%BB%A5%E5%8F%8A%E9%80%92%E5%BD%92%2F</url>
    <content type="text"><![CDATA[匿名函数python定义一个函数通常使用def关键词，后面跟函数名，然后是注释、代码块等。 123def func(): '''注释''' print('from func') 这样就在全局命名空间定义了一个叫func的函数，func表示函数体的内存地址，因为func指向函数体内存地址，所以可以通过func来调用函数。 那么匿名函数呢？从名字就可看出，匿名。想想就有点像以前小时候的佚名一样，带点说不清楚的神秘色彩，现在想来之所以感觉神秘可能是因为那时候不认识‘’佚‘’这个字。。。 1234强调: 匿名函数的定义就相当于只产生一个变量在值,而没有绑定任何名字, 所以会在定义完之后就被回收,无法重复使用,只能在定义时使用一次应用:当某一个功能仅使用一次就没有再重复使用的必要了,就应该定义成匿名函数 言归正传，匿名和佚名一样没有名字或者不需要知道名字，对就是这么酷。 定义一个匿名函数使用lambda关键词，和def比较的话会发现其实定义逻辑很像。 1lambda x: x**2 定义的匿名函数的意思是参数为x，返回x的平方，返回？怎么没看到return？因为lambd引号后面的值默认返回，所以没必要加return了，但是我一定要加呢？就是这么不讲道理。那么解释器只好报错了，因为你不认同我的语法，那我也没必要惯着你了。就是这么拽。 匿名函数的使用场景通常为使用一次就结束了，不会频繁的使用。而且匿名函数通常和python里面自带的高阶函数结合使用，在某些应用场景下会达到事倍功半的效果哦。 高阶函数mapmap的意思是地图的意思，由此引申出映射表示一一对应。 翻译过来的意思是：创建一个迭代器，使用每个迭代的参数计算函数。 当最短的可迭代用尽时停止。 map函数有两个参数，第一个为某种规则的函数，第二个位多个可迭代对象。 12345def func(x): return x * 2lis = [1, 2, 3, 4, 5, 6]print(type(map(func, lis)))print(list(map(func, lis))) map函数把可迭代对象中的元素自动传给func，通过func的加工，得到一个生成器对象，通过list函数转化为一个列表。 当然，map函数可以接收多个可迭代对象，比如 123456def func(x, y): return x + ylis1 = [1,2,3,4,5,6]lis2 = [2,3,4,5,6,7,8,9,10,11]print(list(map(func, lis1,lis2)))# 结果为[3, 5, 7, 9, 11, 13] map函数会把后面迭代器对象中的元素迭代出来经过func加工，当最短的可迭代用尽是停止，所以只进行到6+7就结束了。 reducereduce是减少、合并的意思，会把可迭代对象中的元素经过函数的加工进而产生新的结果。 翻译过来就是：从左到右累加两个参数的函数到序列的项目，以便将序列减少为单个值。例如，reduce（lambda x，y：x + y，[1,2,3] ，4,5]计算（（（（（1 + 2）+3）+4）+5）。如果存在初始值，则将其放置在计算中序列的项之前，并在序列为空时用作默认值。 reduce函数有三个参数，函数和序列都是必须参数，初始值为可选参数。 应用：比如求1-100的和 12345from functools import reducedef func(x, y): return x+yprint(reduce(func, [i for i in range(1,101)]))# 结果为 5050 filterfilter的意思为过滤，通过函数的返回值对序列进行过滤。 翻译过来：返回一个迭代器，产生函数（item）为真的迭代项。 如果函数为None，则返回结果为真的项。 12345def func(x): return x.isdigit()lis = ['12', 'ad', '34', 'bc', '46']print(list(filter(func, lis)))# 结果为 ['12', '34', '46'] filter过滤结果为真的值放进迭代器中。 高阶函数和匿名函数map和匿名函数在之前map函数中的func参数都是定义了一个有名参数，然后用函数名传入map函数的，有了匿名函数就不用这么麻烦了。 123lis = [1, 2, 3, 4, 5, 6]print(list(map(lambda x: x*2, lis)))# 结果为 [2, 4, 6, 8, 10, 12] reduce和匿名函数12print(reduce(lambda x, y: x + y, [i for i in range(101)], 100))# 输出结果为 5050 filter和匿名函数12345678sala = &#123; 'MAC': 30000, 'iPhone': 9000, 'lenovo': 10000, 'xiaomi': 3000&#125;print(list(filter(lambda x: sala[x] &gt; 5000, sala)))# 输出结果为 [‘iPhone', 'lenovo'] 匿名函数的使用场景较为单一，一次性使用，随用随时定义。在某些场景下和高阶函数结合会提升效率，同时使代码更加简洁。 递归一 递归调用的定义递归调用时函数嵌套调用的一种特殊形式，函数在调用时，直接或间接地调用了自身，就是递归调用。 1234567891011121314151617181920# 直接调用自身def f1(): print('from f1') f1()f1()# 间接调用自身def f1(): print('from f1') f2()def f2(): print('from f1') f1()f2()# 调用函数会产生局部的名称空间，占用内存，因为上述这种调用会无限调用自身，python解释器的内存管理机制为了防止无限占用内存，对函数的递归调用做了层级限制，可以通过代码修改最大层级限制。import syssys.setrecursionlimit(100000) 二 递归调用的两个阶段递归调用包含两个明确的阶段：回溯，递推 回溯就是从外向里一层一层递归调用下去，回溯阶段必须要有一个明确的结束条件（不然会成为死循环），每进入下一次递归时，问题的规模都应该有所减少。 递推就是从里向外一层层结束递归。 递归效率不高，递归层次过多会导致栈溢出（在计算机中，函数调用是通过栈实现的，每当进入一个函数调用，在栈下面会加一层栈帧，每当函数返回，栈就会减一层栈帧。由于栈的大小不是无限的，所以递归调用次数过多，会导致栈溢出） 三 二分法从一个排序的数字列表中找到指定的数字，使用遍历的效率太低，使用二分法可以极大地缩小问题规模。 实现in的效果 123456789101112131415nums = [1,5,12,23,34,46,59,99,443]def fucn(num, nums): if len(nums) == 0: return mid_index = len(nums) // 2 if num &gt; nums[mid_index]: nums = nums[mid_index+1:] fucn(num, nums) elif num &lt; nums[mid_index]: nums = nums[:mid_index] fucn(num,nums) else: print('not exis') 实现index的效果 1234567891011121314151617181920212223nums = [1, 13, 15, 23, 27, 31, 33, 57, 73, 81, 93, 94, 97, 101] # 从小到大排列的数字列表def binary_search(find_num,nums): print(nums) if len(nums) == 0: print('not exists') return # 功能 mid_index = len(nums) // 2 if find_num &gt; nums[mid_index]: # in the right nums=nums[mid_index+1:] # 重新运行功能,传入新列表 binary_search(find_num,nums) elif find_num &lt; nums[mid_index]: # in the left nums=nums[:mid_index] # 重新运行功能,传入新列表 binary_search(find_num,nums) else: print('find it') binary_search(95,nums)]]></content>
      <categories>
        <category>Python</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[字符编码]]></title>
    <url>%2F2018%2F10%2F08%2F%E5%AD%97%E7%AC%A6%E7%BC%96%E7%A0%81%2F</url>
    <content type="text"><![CDATA[本来都以为自己完全弄懂字符编码了，昨天一个小问题给难倒了，思考了很久才得出答案，惭愧 字符编码的简介字符编码可以说每一种编程语言都会遇到的问题，为什么会有这么多的问题呢，就是因为计算机发展速度太快了，不仅计算机的诞生国要使用，第三世界国家也要使用，所以人和计算机的交流方式就变得复杂起来。像英语国家最简单，直接用一个字节也就是7bit，总共128种状态就可以满足交流需求；但是像中国等不以英语为第一母语的国家就会出很多问题了，但中文就有60000+个，那么很显然，7bit满足不了需求，所以为了满足需求，中国出了gb2312编码，不过gb2312也不能满足需求，所以又出来了gbk编码，可以表示60000+汉子。 虽然可以通过自己国家去规定本国的字符编码方式，可是这么多国家，每个国家都有自己的编码方式，那么跨过交流会变得困难起来。为了解决这种问题，在1990年开始起草unicode码，简称万国码。里面是一张超级大的对照表，包含了所有的编码集，比如：utf-8、shiftjis、gbk、iso-8859-1。既然包含这么多的对照表，那么每个国家都继续用自己的编码操作文件，但是在内存中都用unicode码，存的时候又根据unicode对照映射成自己国家的编码方式存储不就可以解决跨国交流的问题了嘛。 文本编辑器打开文件文本编辑器打开文件通常分为三步： 首先启动文本编辑器 文本编辑器将存储在硬盘中的文件读入内存 文本编辑器识别内存中文件的编码方式进而解码 第一步不用多解释了，重要在第二步和第三步。 硬盘中的文件会有一种编码方式，如下图 可以看出来有ASCII和UTF-8两种编码方式，所以当文本编辑器将它们读入内存中时，需要按照ASCII和UTF-8分别解码成unicode码（内存中默认编码都为unicode），第三步需要在显示屏上显示出来，那么需要将内存中的unicode码解码出来，那么这时候按照什么解码方式呢？如果我们没指定的话按照当前环境的编码方式，比如windows系统默认编码方式为gbk，类linux系统默认编码方式为utf-8。所以这就会出现问题了，假如在windows系统中读取utf-8编码方式的文件时 在windows下使用python2进行试验，定义了一个变量，并且是unicode编码的，当我分别是用utf-8和gbk对unicode编码时，然后打印发现utf-8码乱码了，这就说明在打印的时候会根据当前环境的编码方式进行解码，这和windows默认编码为gbk是相符的。 python中的编码在python中有两种编码：分别为文件编码以及运行代码时定义字符串的编码 第一种在前面解释了，总的来说一个文本编辑器从硬盘中读入文件时，第一步按照文件存储的编码解码为unicode码存入内存，然后根据文件头声明的编码解码（如果有文件头声明编码方式的话），否则就按照环境默认编码进行解码。 而python2和python3有很大的不同，python2默认编码为ascii，python3默认编码为utf-8，即python2编写的文件默认为ASCII编码，python3编写的文件默认为utf-8编码，但是读入内存中都需要解码为unicode。 第二种的话，在上幅图中为了演示，把字符串定义为unicode码，那么字符串前面不加’u’呢？ 按照我们之前的认识，ASCII识别不了中文，所以在print(a)时应该会报错才对啊，为什么不报错呢？这个应该是python2做的改变，当识别不了中文时，使用当前系统默认编码进行编码和解码，来证明一下，我使用linux做个试验就知道了。 真相大白了，python2这个改进不得不说挺机智的，因为历史遗留问题才导致python2的编码问题经过这样算是一种比较完美的解决方式。而完美的python3会有这种问题吗？怎么可能。python3是完美的。]]></content>
      <categories>
        <category>Computer Basics</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[ssh免钥登陆github]]></title>
    <url>%2F2018%2F10%2F01%2Fgit-ssh%E9%85%8D%E7%BD%AE%E5%92%8C%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[设置Git的user name和emai：（如果是第一次的话）$ git config --global user.name &#39;musibii&#39;$ git config --global user.email &#39;shaozuanzuan@gmail.com&#39; 生成秘钥$ ssh-keygen -t rsa -C &#39;shaozuanzuan@gmail.com&#39;从图上可以看到生成秘钥保存的地址，通常都会默认保存在家目录下面的.ssh下，前面加点表示是个隐藏目录。 添加秘钥到ssh-agentssh-agent是一个帮助程序，用于跟踪用户的身份密钥及其密码。 然后，代理可以使用密钥登录其他服务器，而无需用户再次键入密码或密码.运行ssh-agent之后，使用ssh-agent将私钥交给ssh-agent保管，其他程序需要身份验证的时候就可以将验证申请交给ssh-agent来完成整个认证过程。添加生成的ssh key到ssh-agent$ ssh-add ~/.ssh/id_rsa 登录github，添加ssh秘钥可以看到我有两个密钥，一个是macOS的，一个是Ubuntu的。 测试是否成功$ ssh -T git@github.com万万没想到，报错了。。。报错原因居然是没联网。。。靠北！！！重新联网成功了。。]]></content>
      <categories>
        <category>GitHub</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[mac下配置github个人博客]]></title>
    <url>%2F2018%2F09%2F29%2FMac%E4%BD%BF%E7%94%A8Hexo%E9%85%8D%E7%BD%AEGItHub%E5%8D%9A%E5%AE%A2%2F</url>
    <content type="text"><![CDATA[一 前言本来一直用博客园写博客的，奈何博客园界面惨不忍睹，而且自带的markdown编辑器更是烂的可以，于是在室友makeupstories的建议下开始尝试搭建自己的github博客，真是一路心酸啊！不过成就感也是大大滴。 二 准备工作创建Github域名和放博客的库 首先需要注册一个Github账号。 注册之后需要新建一个库(repository)来存储网站，点击首页任意位置出现的New repository按钮创建仓库，注意这个仓库名不能随便写。例如我的Github账号为musibii，那么库名为musibii.github.io。 安装Git、Nodejs和HexoHexo可以说是最流行的博客框架了，基于Nodejs，想要搭建好，需要安装Git、Nodejs和Hexo。 安装Git可以直接在命令行使用brew来安装Git$ brew install git 因为我之前已经安装了Git，所以这次给我安装了两个扩展包。 安装Nodejs为了便于管理Nodejs版本，首先安装nvm，这是Nodejs版本管理器，可以实现Nodejs多版本切换。$ curl -o- [https://raw.githubusercontent.com/creationix/nvm/v0.33.11/install.sh](https://raw.githubusercontent.com/creationix/nvm/v0.33.11/install.sh) | bash安装完成后，重启终端并执行下列命令即可安装Node.js$ nvm install \d后面跟的是Node.js的版本，今天就是被这个给坑了，应该安装较新的版本，之前安装的为 4，然后一直报错。$ nvm install 8安装后在终端输入$ nvm use node就会使用最新的nodejs版本了。 安装Hexo$ sudo npm install hexo-cli -g注意需要sudo权限，不然会出错 配置博客接下来需要使用Hexo来初始化一个博客，然后根据自己的需求更改一些自定义配置，比如字体、动画效果、主题等等。 创建博客为自己的博客创建一个文件夹，然后cd 文件夹，并执行下面的代码。$ hexo init username.github.io 更改主题 基础配置然后需要的就是在_config.yml里面修改个人信息，比如博客的主题、作者还有语言以及修改的主题名，最重要的是要和你的github仓库关联起来。其他的可以根据自己的需求酌情更改，比如我就增加了页面的动画效果Next主题动画效果 你的第一篇博客 $ hexo new &#39;你的博客名字&#39;执行完后会在‘username.github.io/source/_posts/‘目录下出现你的博客名字 博客使用markdown格式，编写完后执行$ hexo server如果出现下面的页面 在浏览器页面输入http://localhost:4000我的界面会和你们的不一样，出现了 Hello就说明成功了。 安装hexo-deployer-git –save自动部署发布工具$ npm install hexo-deployer-git --save 发布博客$ hexo deploy结束后进入博客就可以看见了！]]></content>
      <categories>
        <category>Python</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2018%2F09%2F29%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub.Hello,my name is musibii! Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
  </entry>
</search>
